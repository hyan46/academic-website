
@report{acemogluOptimal2020,
  title = {Optimal {{Targeted Lockdowns}} in a {{Multi}}-{{Group SIR Model}}},
  author = {Acemoglu, Daron and Chernozhukov, Victor and Werning, Iván and Whinston, Michael},
  date = {2020-05},
  pages = {w27102},
  institution = {{National Bureau of Economic Research}},
  location = {{Cambridge, MA}},
  doi = {10.3386/w27102},
  url = {http://www.nber.org/papers/w27102.pdf},
  urldate = {2020-08-07},
  file = {/Users/hyan46/Dropbox (ASU)/ZoteroData/Acemoglu et al_2020_Optimal Targeted Lockdowns in a Multi-Group SIR Model.pdf},
  langid = {english},
  number = {w27102}
}

@article{Adaptive2021,
  title = {Adaptive {{Reverse Graph Learning}} for {{Robust Subspace Learning}}},
  date = {2021},
  file = {/home/admin/Dropbox (ASU)/TabletPDF/Adaptive Reverse Graph Learning for Robust Subspace Learning.pdf}
}

@article{agrawalPrediction2005,
  ids = {agrawalPrediction2005a},
  title = {Prediction of Molecular-Dynamics Simulation Results Using Feedforward Neural Networks: {{Reaction}} of a {{C}}-2 Dimer with an Activated Diamond(100) Surface},
  author = {Agrawal, P. M. and Samadh, A. N. A. and Raff, L. M. and Hagan, M. T. and Bukkapatnam, Satish and Komanduri, R.},
  date = {2005-12-08},
  journaltitle = {Journal of Chemical Physics},
  shortjournal = {J Chem Phys J Chem Phys},
  volume = {123},
  issn = {0021-9606},
  url = {://WOS:000234120800042},
  abstract = {A new approach involving neural networks combined with molecular dynamics has been used for the determination of reaction probabilities as a function of various input parameters for the reactions associated with the chemical-vapor deposition of carbon dimers on a diamond (100) surface. The data generated by the simulations have been used to train and test neural networks. The probabilities of chemisorption, scattering, and desorption as a function of input parameters, such as rotational energy, translational energy, and direction of the incident velocity vector of the carbon dimer, have been considered. The very good agreement obtained between the predictions of neural networks and those provided by molecular dynamics and the fact that, after training the network, the determination of the interpolated probabilities as a function of various input parameters involves only the evaluation of simple analytical expressions rather than computationally intensive algorithms show that neural networks are extremely powerful tools for interpolating the probabilities and rates of chemical reactions. We also find that a neural network fits the underlying trends in the data rather than the statistical variations present in the molecular-dynamics results. Consequently, neural networks can also provide a computationally convenient means of averaging the statistical variations inherent in molecular-dynamics calculations. In the present case the application of this method is found to reduce the statistical uncertainty in the molecular-dynamics results by about a factor of 3.5. (c) 2005 American Institute of Physics.},
  keywords = {desorption,dissociative chemisorption,hydrogen,mediated growth,monte-carlo,nanocrystalline diamond,potential-energy surfaces,recombination,representation,theoretical-analysis},
  langid = {english},
  number = {22}
}

@inproceedings{akataEvaluation2015,
  title = {Evaluation of Output Embeddings for Fine-Grained Image Classification},
  booktitle = {2015 {{IEEE Conference}} on {{Computer Vision}} and {{Pattern Recognition}} ({{CVPR}})},
  author = {Akata, Zeynep and Reed, Scott and Walter, Daniel and {Honglak Lee} and Schiele, Bernt},
  date = {2015-06},
  pages = {2927--2936},
  publisher = {{IEEE}},
  location = {{Boston, MA, USA}},
  doi = {10.1109/CVPR.2015.7298911},
  url = {http://ieeexplore.ieee.org/document/7298911/},
  urldate = {2021-06-02},
  abstract = {Image classification has advanced significantly in recent years with the availability of large-scale image sets. However, fine-grained classification remains a major challenge due to the annotation cost of large numbers of finegrained categories. This project shows that compelling classification performance can be achieved on such categories even without labeled training data. Given image and class embeddings, we learn a compatibility function such that matching embeddings are assigned a higher score than mismatching ones; zero-shot classification of an image proceeds by finding the label yielding the highest joint compatibility score. We use state-of-the-art image features and focus on different supervised attributes and unsupervised output embeddings either derived from hierarchies or learned from unlabeled text corpora. We establish a substantially improved state-of-the-art on the Animals with Attributes and Caltech-UCSD Birds datasets. Most encouragingly, we demonstrate that purely unsupervised output embeddings (learned from Wikipedia and improved with finegrained text) achieve compelling results, even outperforming the previous supervised state-of-the-art. By combining different output embeddings, we further improve results.},
  eventtitle = {2015 {{IEEE Conference}} on {{Computer Vision}} and {{Pattern Recognition}} ({{CVPR}})},
  file = {/Users/hyan46/Dropbox (ASU)/ZoteroData/Akata et al_2015_Evaluation of output embeddings for fine-grained image classification.pdf},
  isbn = {978-1-4673-6964-0},
  langid = {english}
}

@article{akataLabelEmbedding2016,
  title = {Label-{{Embedding}} for {{Image Classification}}},
  author = {Akata, Zeynep and Perronnin, Florent and Harchaoui, Zaid and Schmid, Cordelia},
  date = {2016-07-01},
  journaltitle = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
  shortjournal = {IEEE Trans. Pattern Anal. Mach. Intell.},
  volume = {38},
  pages = {1425--1438},
  issn = {0162-8828, 2160-9292},
  doi = {10.1109/TPAMI.2015.2487986},
  url = {http://ieeexplore.ieee.org/document/7293699/},
  urldate = {2021-06-04},
  abstract = {Attributes act as intermediate representations that enable parameter sharing between classes, a must when training data is scarce. We propose to view attribute-based image classification as a label-embedding problem: each class is embedded in the space of attribute vectors. We introduce a function that measures the compatibility between an image and a label embedding. The parameters of this function are learned on a training set of labeled samples to ensure that, given an image, the correct classes rank higher than the incorrect ones. Results on the Animals With Attributes and Caltech-UCSD-Birds datasets show that the proposed framework outperforms the standard Direct Attribute Prediction baseline in a zero-shot learning scenario. Label embedding enjoys a built-in ability to leverage alternative sources of information instead of or in addition to attributes, such as, e.g., class hierarchies or textual descriptions. Moreover, label embedding encompasses the whole range of learning settings from zero-shot learning to regular learning with a large number of labeled examples.},
  file = {/Users/hyan46/Dropbox (ASU)/ZoteroData/Akata et al_2016_Label-Embedding for Image Classification.pdf},
  langid = {english},
  number = {7}
}

@online{akcayGANomaly2018,
  title = {{{GANomaly}}: {{Semi}}-{{Supervised Anomaly Detection}} via {{Adversarial Training}}},
  shorttitle = {{{GANomaly}}},
  author = {Akcay, Samet and Atapour-Abarghouei, Amir and Breckon, Toby P.},
  date = {2018-11-13},
  url = {http://arxiv.org/abs/1805.06725},
  urldate = {2020-05-25},
  abstract = {Anomaly detection is a classical problem in computer vision, namely the determination of the normal from the abnormal when datasets are highly biased towards one class (normal) due to the insufficient sample size of the other class (abnormal). While this can be addressed as a supervised learning problem, a significantly more challenging problem is that of detecting the unknown/unseen anomaly case that takes us instead into the space of a one-class, semi-supervised learning paradigm. We introduce such a novel anomaly detection model, by using a conditional generative adversarial network that jointly learns the generation of high-dimensional image space and the inference of latent space. Employing encoder-decoder-encoder sub-networks in the generator network enables the model to map the input image to a lower dimension vector, which is then used to reconstruct the generated output image. The use of the additional encoder network maps this generated image to its latent representation. Minimizing the distance between these images and the latent vectors during training aids in learning the data distribution for the normal samples. As a result, a larger distance metric from this learned data distribution at inference time is indicative of an outlier from that distribution - an anomaly. Experimentation over several benchmark datasets, from varying domains, shows the model efficacy and superiority over previous state-of-the-art approaches.},
  archiveprefix = {arXiv},
  eprint = {1805.06725},
  eprinttype = {arxiv},
  file = {/Users/hyan46/Zotero/storage/STVE5VV5/1805.html},
  keywords = {Computer Science - Computer Vision and Pattern Recognition,semianomaly},
  primaryclass = {cs}
}

@inproceedings{al-halahHow2015,
  title = {How to {{Transfer}}? {{Zero}}-{{Shot Object Recognition}} via {{Hierarchical Transfer}} of {{Semantic Attributes}}},
  shorttitle = {How to {{Transfer}}?},
  booktitle = {2015 {{IEEE Winter Conference}} on {{Applications}} of {{Computer Vision}}},
  author = {Al-Halah, Ziad and Stiefelhagen, Rainer},
  date = {2015-01},
  pages = {837--843},
  publisher = {{IEEE}},
  location = {{Waikoloa, HI, USA}},
  doi = {10.1109/WACV.2015.116},
  url = {http://ieeexplore.ieee.org/document/7045970/},
  urldate = {2021-06-02},
  abstract = {Attribute based knowledge transfer has proven very successful in visual object analysis and learning previously unseen classes. However, the common approach learns and transfers attributes without taking into consideration the embedded structure between the categories in the source set. Such information provides important cues on the intraattribute variations. We propose to capture these variations in a hierarchical model that expands the knowledge source with additional abstraction levels of attributes. We also provide a novel transfer approach that can choose the appropriate attributes to be shared with an unseen class. We evaluate our approach on three public datasets: aPascal, Animals with Attributes and CUB-200-2011 Birds. The experiments demonstrate the effectiveness of our model with significant improvement over state-of-the-art.},
  eventtitle = {2015 {{IEEE Winter Conference}} on {{Applications}} of {{Computer Vision}} ({{WACV}})},
  file = {/Users/hyan46/Dropbox (ASU)/ZoteroData/Al-Halah_Stiefelhagen_2015_How to Transfer.pdf},
  isbn = {978-1-4799-6683-7},
  langid = {english}
}

@inproceedings{al-halahRecovering2016,
  title = {Recovering the {{Missing Link}}: {{Predicting Class}}-{{Attribute Associations}} for {{Unsupervised Zero}}-{{Shot Learning}}},
  shorttitle = {Recovering the {{Missing Link}}},
  booktitle = {2016 {{IEEE Conference}} on {{Computer Vision}} and {{Pattern Recognition}} ({{CVPR}})},
  author = {Al-Halah, Ziad and Tapaswi, Makarand and Stiefelhagen, Rainer},
  date = {2016-06},
  pages = {5975--5984},
  publisher = {{IEEE}},
  location = {{Las Vegas, NV, USA}},
  doi = {10.1109/CVPR.2016.643},
  url = {http://ieeexplore.ieee.org/document/7781012/},
  urldate = {2021-06-02},
  eventtitle = {2016 {{IEEE Conference}} on {{Computer Vision}} and {{Pattern Recognition}} ({{CVPR}})},
  file = {/Users/hyan46/Dropbox (ASU)/ZoteroData/Al-Halah et al_2016_Recovering the Missing Link.pdf},
  isbn = {978-1-4673-8851-1},
  langid = {english}
}

@online{alaaAutoPrognosis2018,
  title = {{{AutoPrognosis}}: {{Automated Clinical Prognostic Modeling}} via {{Bayesian Optimization}} with {{Structured Kernel Learning}}},
  shorttitle = {{{AutoPrognosis}}},
  author = {Alaa, Ahmed M. and van der Schaar, Mihaela},
  date = {2018-02-20},
  url = {http://arxiv.org/abs/1802.07207},
  urldate = {2020-05-24},
  abstract = {Clinical prognostic models derived from largescale healthcare data can inform critical diagnostic and therapeutic decisions. To enable off-theshelf usage of machine learning (ML) in prognostic research, we developed AUTOPROGNOSIS: a system for automating the design of predictive modeling pipelines tailored for clinical prognosis. AUTOPROGNOSIS optimizes ensembles of pipeline configurations efficiently using a novel batched Bayesian optimization (BO) algorithm that learns a low-dimensional decomposition of the pipelines high-dimensional hyperparameter space in concurrence with the BO procedure. This is achieved by modeling the pipelines performances as a black-box function with a Gaussian process prior, and modeling the similarities between the pipelines baseline algorithms via a sparse additive kernel with a Dirichlet prior. Meta-learning is used to warmstart BO with external data from similar patient cohorts by calibrating the priors using an algorithm that mimics the empirical Bayes method. The system automatically explains its predictions by presenting the clinicians with logical association rules that link patients features to predicted risk strata. We demonstrate the utility of AUTOPROGNOSIS using 10 major patient cohorts representing various aspects of cardiovascular patient care.},
  archiveprefix = {arXiv},
  eprint = {1802.07207},
  eprinttype = {arxiv},
  file = {/Users/hyan46/Zotero/storage/HRNSTJAP/1802.html},
  keywords = {Application: Additive Manufacturing,Application: Manufacturing,automl,Bayesian Optimization,Computer Science - Machine Learning,metalearning,Statistics - Machine Learning},
  options = {useprefix=true},
  primaryclass = {cs, stat}
}

@inproceedings{amato2015scalable,
  title = {Scalable Planning and Learning for Multiagent {{POMDPs}}},
  booktitle = {Proceedings of the {{AAAI}} Conference on Artificial Intelligence},
  author = {Amato, Christopher and Oliehoek, Frans},
  date = {2015},
  volume = {29},
  file = {/Users/hyan46/Dropbox (ASU)/ZoteroData/Amato_Oliehoek_2015_Scalable planning and learning for multiagent POMDPs.pdf},
  number = {1}
}

@book{anderssonStochastic2012,
  title = {Stochastic Epidemic Models and Their Statistical Analysis},
  author = {Andersson, Hakan and Britton, Tom},
  date = {2012},
  volume = {151},
  publisher = {{Springer Science \textbackslash\& Business Media}},
  file = {/Users/hyan46/Dropbox (ASU)/ZoteroData/Andersson_Britton_2012_Stochastic epidemic models and their statistical analysis.pdf}
}

@article{anomalousCoupledInReview,
  title = {Coupled {{Support Tensor Machine}} for {{Multimodal Neuroimaging Data}}},
  author = {Anomalous, Anomalous},
  year = {InReview},
  file = {/Users/hyan46/Dropbox (ASU)/ZoteroData/Anomalous_InReview_Coupled Support Tensor Machine for Multimodal Neuroimaging Data.PDF}
}

@article{Approach,
  title = {An Approach for Tool Wear Predict Using Customized {{DenseNet}} and {{GRU}} Integrated Model Based on Multi-Sensor Feature Fusion},
  file = {/Users/hyan46/Dropbox (ASU)/ZoteroData/An approach for tool wear predict using customized DenseNet and GRU integrated.pdf}
}

@unpublished{arnesonSherlock2018,
  title = {Sherlock {{Data Warehouse}}},
  author = {Arneson, Heather M.},
  date = {2018-06-01},
  url = {https://ntrs.nasa.gov/search.jsp?R=20180004248},
  urldate = {2020-06-17},
  abstract = {Overview of NASA Ames Aviation Systems Division's Sherlock data warehouse.},
  file = {/Users/hyan46/Zotero/storage/8GYRUEDZ/search.html},
  keywords = {air traffic control,data bases,data structures}
}

@article{awasthiAdversarially,
  title = {Adversarially {{Robust Low Dimensional Representations}}},
  author = {Awasthi, Pranjal and Chatziafratis, Vaggos and Vijayaraghavan, Aravindan and Chen, Xue},
  pages = {68},
  abstract = {Adversarial or test time robustness measures the susceptibility of a machine learning system to small perturbations made to the input at test time. It is now well known that even when trained on high quality training data, many machine learning systems perform poorly under imperceptible adversarial perturbations to the test inputs [SZS+13]. There is a large body of work proposing practical methods to make classifiers adversarially robust. On the other hand, our theoretical understanding of the phenomenon of adversarial robustness is limited, and has mostly focused on supervised learning tasks such as binary classification.},
  file = {/Users/hyan46/Dropbox (ASU)/ZoteroData/Awasthi et al_Adversarially Robust Low Dimensional Representations.pdf},
  langid = {english}
}

@article{aydemirImageBased2020,
  title = {Image-{{Based Prognostics Using Deep Learning Approach}}},
  author = {Aydemir, Gurkan and Paynabar, Kamran},
  date = {2020-09},
  journaltitle = {IEEE Transactions on Industrial Informatics},
  shortjournal = {IEEE Trans. Ind. Inf.},
  volume = {16},
  pages = {5956--5964},
  issn = {1551-3203, 1941-0050},
  doi = {10.1109/TII.2019.2956220},
  url = {https://ieeexplore.ieee.org/document/8915753/},
  urldate = {2020-07-07},
  abstract = {This article proposes two methods based on deep learning for estimating time-to-failure (TTF) of an industrial system using its degradation image. This provides an effective tool for predictive maintenance practitioners toward digitization of maintenance processes in Industry 4.0 transformation. Both methods utilize the long shortterm memory (LSTM) networks for capturing temporal information. First methodology consists of two convolutional layers preceding a single LSTM layer to extract compact information from the individual images and rescue LSTM network from curse of dimensionality. Then, an LSTM layer estimates the TTF value from the extracted features. In the second approach, the dimension of the individual images are decreased by a fully connected neural network, which is trained as an autoencoder. A separate LSTM network is trained and run over this lower dimensional space. The strength of suggested architectures is shown using simulation data and a dataset of infrared image streams collected from rotating machinery. The performance comparison of proposed methods and other methods is also provided.},
  file = {/Users/hyan46/Dropbox (ASU)/ZoteroData/Aydemir_Paynabar_2020_Image-Based Prognostics Using Deep Learning Approach.pdf},
  langid = {english},
  number = {9}
}

@article{babuSpatioTemporal2019,
  title = {Spatio-{{Temporal Adaptive Sampling}} for Effective Coverage Measurement Planning during Quality Inspection of Free Form Surfaces Using Robotic {{3D}} Optical Scanner},
  author = {Babu, Manoj and Franciosa, Pasquale and Ceglarek, Dariusz},
  date = {2019-10-01},
  journaltitle = {Journal of Manufacturing Systems},
  shortjournal = {Journal of Manufacturing Systems},
  volume = {53},
  pages = {93--108},
  issn = {0278-6125},
  doi = {10.1016/j.jmsy.2019.08.003},
  url = {http://www.sciencedirect.com/science/article/pii/S0278612519300718},
  urldate = {2020-07-03},
  abstract = {In-line dimensional inspection of free form surfaces using robotic 3D-optical scanners provide an opportunity to reduce the mean-time-to-detection of product quality defects and has thus emerged as a critical enabler in Industry 4.0 to achieve near-zero defects. However, the time needed to inspect large industrial size sheet metal parts by 3D-optical scanners frequently exceeds the production cycle time (CT), consequently, limiting the application of in-line measurement systems for high production volume manufacturing processes such as those used in the automotive industry. This paper addresses the aforementioned challenge by developing the Spatio-Temporal Adaptive Sampling (STAS) methodology which has the capability for (i) estimation of whole part deviations based on partial measurement of a free form surface; and, (ii) adaptive selection of the next region to be measured in order to satisfy pre-defined measurement criterion. This is achieved by first, modelling spatio-temporal correlations in the high dimensional Cloud-of-Points measurement data by using a dimension reduced space-time Kalman filter; then, dynamically updating the model parameters during the inspection process by incorporating partial measurement data to predict entire part deviations and adaptively choose the next critical region of the part to be measured. The developed STAS methodology enhances the current free form surface inspection models, which are mostly based on spatial analysis; into spatio-temporal model, which uses (i) the spatial analysis to model part deformation; and, (ii) temporal analysis to model autoregressive behaviour of the manufacturing process for prediction of next part deviations. This provides capability to predict the whole part deviation based on partial measurement information and consequently reduces measurement cycle time. The industrial case study using a robotic 3D-optical scanner for the measurement of an automotive door inner part demonstrates the STAS methodology, which resulted in (i) a 3 Sigma error of prediction of whole part deviations within 0.27 mm based on measurement of 33\% of the part surface; and, (ii) a corresponding CT reduction of 42.2\% from 510.5 s required by current best practice to measure the whole part to 295.18 s required to partially measure the part.},
  file = {/Users/hyan46/Dropbox (ASU)/ZoteroData/Babu et al_2019_Spatio-Temporal Adaptive Sampling for effective coverage measurement planning2.pdf},
  keywords = {Application: Manufacturing,Application: Surface Scanning,Data: Point Cloud,Method: Adaptive Sampling,Method: Spatio-temporal,People: Cerek},
  langid = {english}
}

@report{baiNonstationary2020,
  title = {Non-Stationary {{Spatio}}-{{Temporal Modeling}} of {{COVID}}-19 {{Progression}} in {{The U}}.{{S}}.},
  author = {Bai, Yue and Safikhani, Abolfazl and Michailidis, George},
  date = {2020-09-18},
  institution = {{Health Informatics}},
  doi = {10.1101/2020.09.14.20194548},
  url = {http://medrxiv.org/lookup/doi/10.1101/2020.09.14.20194548},
  urldate = {2020-12-19},
  abstract = {The fast transmission rate of COVID-19 worldwide has made this virus the most important challenge of year 2020. Many mitigation policies have been imposed by the governments at different regional levels (country, state, county, and city) to stop the spread of this virus. Quantifying the effect of such mitigation strategies on the transmission and recovery rates, and predicting the rate of new daily cases are two crucial tasks. In this paper, we propose a modeling framework which not only accounts for such policies but also utilizes the spatial and temporal information to characterize the pattern of COVID-19 progression. Specifically, a piecewise susceptible-infected-recovered (SIR) model is developed while the dates at which the transmission/recover rates change significantly are defined as “break points” in this model. A novel and data-driven algorithm is designed to locate the break points using ideas from fused lasso and thresholding. In order to enhance the forecasting power and to describe additional temporal dependence among the daily number of cases, this model is further coupled with spatial smoothing covariates and vector auto-regressive (VAR) model. The proposed model is applied to several U.S. states and counties, and the results confirm the effect of “stay-at-home orders” and some states’ early “re-openings” by detecting break points close to such events. Further, the model performed satisfactorily short-term forecasts of the number of new daily cases at regional levels by utilizing the estimated spatio-temporal covariance structures. Finally, some theoretical results and empirical performance of the proposed methodology on synthetic data are reported which justify the good performance of the proposed method.},
  file = {/Users/hyan46/Zotero/storage/XNGVNYB6/Bai et al. - 2020 - Non-stationary Spatio-Temporal Modeling of COVID-1.pdf},
  langid = {english},
  type = {preprint}
}

@article{baoRobust2016,
  title = {Robust {{Parameter Design}} for {{Profile Quality Control}}},
  author = {Bao, Lulu and Huang, Qiang and Wang, Kaibo},
  date = {2016-04},
  journaltitle = {Quality and Reliability Engineering International},
  shortjournal = {Qual. Reliab. Engng. Int.},
  volume = {32},
  pages = {1059--1070},
  issn = {07488017},
  doi = {10.1002/qre.1814},
  url = {http://doi.wiley.com/10.1002/qre.1814},
  urldate = {2020-07-04},
  file = {/Users/hyan46/Dropbox (ASU)/ZoteroData/Bao et al_2016_Robust Parameter Design for Profile Quality Control.pdf},
  keywords = {Application: Semiconductor,Data: Profiles,Method: Functional,People: Kaibo Wang,People: Qiang Huang},
  langid = {english},
  number = {3}
}

@article{barazandehRobust2018,
  title = {Robust {{Sparse Representation}}-{{Based Classification Using Online Sensor Data}} for {{Monitoring Manual Material Handling Tasks}}},
  author = {Barazandeh, Babak and Bastani, Kaveh and Rafieisakhaei, Mohammadhussein and Kim, Sunwook and Kong, Zhenyu and Nussbaum, Maury A.},
  date = {2018-10},
  journaltitle = {IEEE Transactions on Automation Science and Engineering},
  shortjournal = {IEEE Trans. Automat. Sci. Eng.},
  volume = {15},
  pages = {1573--1584},
  issn = {1545-5955, 1558-3783},
  doi = {10.1109/TASE.2017.2729583},
  url = {https://ieeexplore.ieee.org/document/8010356/},
  urldate = {2020-07-04},
  abstract = {Sensor-based online process monitoring has extensive applications, such as in manufacturing and service industries. In real environments, though, sensor data are often contaminated with noise, leading to severe challenges in accurate data analysis. In the existing literature, noise is generally modeled as Gaussian to analyze sensor data for various applications, for example in fault detection and diagnostics. However, in some applications, such as due to challenging field conditions, sensor data may be disturbed by high levels of outliers such that the Gaussian assumption of sensor noise is inadequate, thus leading to large estimation errors. This paper focuses on online classification applications. A robust sparse representation classification method is proposed, which considers non-Gaussian noise, and thus can effectively analyze sensor data with higher levels of outliers. Case studies were completed, based on both numerically simulated sensor data and actual wearable sensor data from occupational manual material handling process monitoring. The proposed classification method could effectively analyze sensor data with non-Gaussian noise, and outperformed commonly used methods in the literature. Thus, this new method may be advantageous for solving classification problems in challenging field conditions, to address the difficulties of high levels of sensor outliers.},
  file = {/Users/hyan46/Dropbox (ASU)/ZoteroData/Barazandeh et al_2018_Robust Sparse Representation-Based Classification Using Online Sensor Data for.pdf},
  keywords = {Application: Material Handling,Method: Classification,Method: Regularization,Method: Sparse,People: James Kong,Problem: Classification,Problem: Process Monitoring},
  langid = {english},
  number = {4}
}

@online{barUnsupervised2019,
  title = {Unsupervised {{Deep Learning Algorithm}} for {{PDE}}-Based {{Forward}} and {{Inverse Problems}}},
  author = {Bar, Leah and Sochen, Nir},
  date = {2019-04-10},
  url = {http://arxiv.org/abs/1904.05417},
  urldate = {2020-09-15},
  abstract = {We propose a neural network-based algorithm for solving forward and inverse problems for partial differential equations in unsupervised fashion. The solution is approximated by a deep neural network which is the minimizer of a cost function, and satisfies the PDE, boundary conditions, and additional regularizations. The method is mesh free and can be easily applied to an arbitrary regular domain. We focus on 2D second order elliptical system with non-constant coefficients, with application to Electrical Impedance Tomography.},
  archiveprefix = {arXiv},
  eprint = {1904.05417},
  eprinttype = {arxiv},
  file = {/Users/hyan46/Zotero/storage/NP5H82IE/Bar and Sochen - 2019 - Unsupervised Deep Learning Algorithm for PDE-based.pdf},
  keywords = {3504,Computer Science - Machine Learning,Statistics - Machine Learning},
  langid = {english},
  primaryclass = {cs, stat}
}

@inproceedings{bassMultisensor1999,
  title = {Multisensor {{Data Fusion}} for {{Next Generation Distributed Intrusion Detection Systems}}},
  booktitle = {Proceedings of the {{IRIS National Symposium}} on {{Sensor}} and {{Data Fusion}}},
  author = {Bass, Tim and International, ERIM and Arbor, Ann},
  date = {1999},
  volume = {24},
  pages = {24--27},
  file = {/Users/hyan46/Dropbox (ASU)/ZoteroData/Bass et al_1999_Multisensor Data Fusion for Next Generation Distributed Intrusion Detection.pdf},
  langid = {english}
}

@article{beckConvergence2013,
  title = {On the {{Convergence}} of {{Block Coordinate Descent Type Methods}}},
  author = {Beck, Amir and Tetruashvili, Luba},
  date = {2013-01-01},
  journaltitle = {SIAM Journal on Optimization},
  shortjournal = {SIAM J. Optim.},
  volume = {23},
  pages = {2037--2060},
  publisher = {{Society for Industrial and Applied Mathematics}},
  issn = {1052-6234},
  doi = {10.1137/120887679},
  url = {https://epubs.siam.org/doi/abs/10.1137/120887679},
  urldate = {2020-06-03},
  abstract = {In this paper we study smooth convex programming problems where the decision variables vector is split into several blocks of variables.  We analyze the block coordinate gradient projection method in which each iteration consists of performing a gradient projection step with respect to a certain block taken in a cyclic order. Global sublinear rate of convergence of this method is established and it is shown that it can be accelerated when the problem is unconstrained. In the unconstrained setting we also prove a sublinear rate of convergence result for the so-called alternating minimization method when the number of blocks is two. When the objective function is also assumed to be strongly convex, linear rate of convergence is established.},
  file = {/Users/hyan46/Dropbox (ASU)/ZoteroData/Beck_Tetruashvili_2013_On the Convergence of Block Coordinate Descent Type Methods.pdf},
  number = {4}
}

@article{ben-davidTheory2010,
  title = {A Theory of Learning from Different Domains},
  author = {Ben-David, Shai and Blitzer, John and Crammer, Koby and Kulesza, Alex and Pereira, Fernando and Vaughan, Jennifer Wortman},
  date = {2010-05-01},
  journaltitle = {Machine Learning},
  shortjournal = {Mach Learn},
  volume = {79},
  pages = {151--175},
  issn = {1573-0565},
  doi = {10.1007/s10994-009-5152-4},
  url = {https://doi.org/10.1007/s10994-009-5152-4},
  urldate = {2020-05-22},
  abstract = {Discriminative learning methods for classification perform well when training and test data are drawn from the same distribution. Often, however, we have plentiful labeled training data from a source domain but wish to learn a classifier which performs well on a target domain with a different distribution and little or no labeled training data. In this work we investigate two questions. First, under what conditions can a classifier trained from source data be expected to perform well on target data? Second, given a small amount of labeled target data, how should we combine it during training with the large amount of labeled source data to achieve the lowest target error at test time?},
  file = {/Users/hyan46/Dropbox (ASU)/ZoteroData/Ben-David et al_2010_A theory of learning from different domains.pdf},
  keywords = {Domain Adaptation Learning,Method: Classification,Problem: Classification},
  langid = {english},
  number = {1}
}

@article{bendaleOpen,
  title = {Towards {{Open Set Deep Networks}}},
  author = {Bendale, Abhijit and Boult, Terrance E},
  pages = {10},
  abstract = {Deep networks have produced significant gains for various visual recognition problems, leading to high impact academic and commercial applications. Recent work in deep networks highlighted that it is easy to generate images that humans would never classify as a particular object class, yet networks classify such images high confidence as that given class – deep network are easily fooled with images humans do not consider meaningful. The closed set nature of deep networks forces them to choose from one of the known classes leading to such artifacts. Recognition in the real world is open set, i.e. the recognition system should reject unknown/unseen classes at test time. We present a methodology to adapt deep networks for open set recognition, by introducing a new model layer, OpenMax, which estimates the probability of an input being from an unknown class. A key element of estimating the unknown probability is adapting Meta-Recognition concepts to the activation patterns in the penultimate layer of the network. OpenMax allows rejection of “fooling” and unrelated open set images presented to the system; OpenMax greatly reduces the number of obvious errors made by a deep network. We prove that the OpenMax concept provides bounded open space risk, thereby formally providing an open set recognition solution. We evaluate the resulting open set deep networks using pre-trained networks from the Caffe Model-zoo on ImageNet 2012 validation data, and thousands of fooling and open set images. The proposed OpenMax model significantly outperforms open set recognition accuracy of basic deep networks as well as deep networks with thresholding of SoftMax probabilities.},
  file = {/Users/hyan46/Dropbox (ASU)/ZoteroData/Bendale_Boult_Towards Open Set Deep Networks.pdf},
  langid = {english}
}

@online{bertozziChallenges2020,
  title = {The Challenges of Modeling and Forecasting the Spread of {{COVID}}-19},
  author = {Bertozzi, Andrea L. and Franco, Elisa and Mohler, George and Short, Martin B. and Sledge, Daniel},
  date = {2020-04-09},
  url = {http://arxiv.org/abs/2004.04741},
  urldate = {2020-08-08},
  abstract = {We present three data driven model-types for COVID-19 with a minimal number of parameters to provide insights into the spread of the disease that may be used for developing policy responses. The first is exponential growth, widely studied in analysis of early-time data. The second is a self-exciting branching process model which includes a delay in transmission and recovery. It allows for meaningful fit to early time stochastic data. The third is the well-known SusceptibleInfected-Resistant (SIR) model and its cousin, SEIR, with an ”Exposed” component. All three models are related quantitatively, and the SIR model is used to illustrate the potential effects of short-term distancing measures in the United States.},
  archiveprefix = {arXiv},
  eprint = {2004.04741},
  eprinttype = {arxiv},
  file = {/Users/hyan46/Dropbox (ASU)/ZoteroData/Bertozzi et al_2020_The challenges of modeling and forecasting the spread of COVID-19.pdf},
  keywords = {Quantitative Biology - Populations and Evolution},
  langid = {english},
  primaryclass = {q-bio}
}

@article{Beruvides:2018il,
  title = {Fault Pattern Identification in Multi-Stage Assembly Processes with Non-Ideal Sheet-Metal Parts Based on Reinforcement Learning Architecture},
  author = {Beruvides, Gerardo and Villalonga, Alberto and Franciosa, Pasquale and Ceglarek, Dariusz and Haber, Rodolfo E},
  date = {2018-01},
  journaltitle = {Procedia CIRP},
  volume = {67},
  pages = {601--606},
  publisher = {{Elsevier}},
  doi = {10.1016/j.procir.2017.12.268},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S2212827117312143},
  abstract = {A reinforcement learning-based architecture to address the fault detection on body in white assembly processes is introduced in this paper. During the…},
  date-added = {2020-07-03T19:19:32GMT},
  date-modified = {2020-07-04T00:26:51GMT},
  file = {/Users/hyan46/Dropbox (ASU)/ZoteroData/Beruvides et al_2018_Fault pattern identification in multi-stage assembly processes with non-ideal2.pdf},
  keywords = {Application: Assembly,Application: Manufacturing,Method: Adaptive Sampling,People: Cerek,Problem: Supervised Learning},
  langid = {english},
  local-url = {file://localhost/Users/hyan46/Dropbox\%20(ASU)/PapersSync/Files/2B/2B67E216-F310-4761-9D90-4C6563F79C68.pdf},
  rating = {0},
  read = {Yes},
  uri = {papers3://publication/doi/10.1016/j.procir.2017.12.268}
}

@article{bettiPredictive2017,
  title = {Predictive {{Maintenance}} in {{Photovoltaic Plants}} with a {{Big Data Approach}}},
  author = {Betti, Alessandro and Trovato, Maria Luisa Lo and Leonardi, Fabio Salvatore and Leotta, Giuseppe and Ruffini, Fabrizio and Lanzetta, Ciro},
  date = {2017},
  journaltitle = {33rd European Photovoltaic Solar Energy Conference and Exhibition; 1895-1900},
  pages = {6 pages, 11894 kb},
  doi = {10.4229/EUPVSEC20172017-6DP.2.4},
  url = {http://arxiv.org/abs/1901.10855},
  urldate = {2020-06-09},
  abstract = {This paper presents a novel and flexible solution for fault prediction based on data collected from SCADA system. Fault prediction is offered at two different levels based on a data-driven approach: (a) generic fault/status prediction and (b) specific fault class prediction, implemented by means of two different machine learning based modules built on an unsupervised clustering algorithm and a Pattern Recognition Neural Network, respectively. Model has been assessed on a park of six photovoltaic (PV) plants up to 10 MW and on more than one hundred inverter modules of three different technology brands. The results indicate that the proposed method is effective in (a) predicting incipient generic faults up to 7 days in advance with sensitivity up to 95\% and (b) anticipating damage of specific fault classes with times ranging from few hours up to 7 days. The model is easily deployable for on-line monitoring of anomalies on new PV plants and technologies, requiring only the availability of historical SCADA and fault data, fault taxonomy and inverter electrical datasheet. Keywords: Data Mining, Fault Prediction, Inverter Module, Key Performance Indicator, Lost Production},
  archiveprefix = {arXiv},
  eprint = {1901.10855},
  eprinttype = {arxiv},
  file = {/Users/hyan46/Dropbox (ASU)/ZoteroData/Betti et al_2017_Predictive Maintenance in Photovoltaic Plants with a Big Data Approach3.pdf},
  keywords = {Application: Solar,Computer Science - Machine Learning,Electrical Engineering and Systems Science - Systems and Control,I.2.6,Statistics - Machine Learning}
}

@article{beycaHeterogeneous2015,
  ids = {beycaHeterogeneous2016},
  title = {Heterogeneous Sensor Data Fusion Approach for Real-Time Monitoring in Ultraprecision Machining ({{UPM}}) Process Using Non-Parametric {{Bayesian}} Clustering and Evidence Theory},
  author = {Beyca, Omer F and Rao, Prahalad K and Kong, Zhenyu and Bukkapatnam, Satish and Komanduri, Ranga},
  date = {2015},
  journaltitle = {IEEE Transactions on Automation Science and Engineering},
  volume = {13},
  pages = {1033--1044},
  issn = {1545-5955},
  keywords = {Aerospace,Bayesian,Change detection,dirichlet process modeling,evidence theory,fault-diagnosis,information fusion,Machining,multisensor,process monitoring,sensor fusion,Supervised learning,system,tool wear,Ultraprecision,ultraprecision machining},
  number = {2}
}

@article{bhattacharyaReinforcement2020,
  title = {Reinforcement {{Learning}} for {{POMDP}}: {{Partitioned Rollout}} and {{Policy Iteration}} with {{Application}} to {{Autonomous Sequential Repair Problems}}},
  author = {Bhattacharya, Sushmita and Badyal, Sahil and Wheeler, Thomas and Gil, Stephanie and Bertsekas, Dimitri},
  date = {2020},
  journaltitle = {IEEE Robotics and Automation Letters},
  volume = {5},
  pages = {3967--3974},
  publisher = {{IEEE}},
  isbn = {2377-3766},
  keywords = {maintenance},
  number = {3}
}

@article{boydDistributed2011,
  title = {Distributed {{Optimization}} and {{Statistical Learning}} via the {{Alternating Direction Method}} of {{Multipliers}}},
  author = {Boyd, Stephen and Parikh, Neal and Chu, Eric and Peleato, Borja and Eckstein, Jonathan},
  date = {2011-01-01},
  journaltitle = {Foundations and Trends® in Machine Learning},
  shortjournal = {Found. Trends Mach. Learn.},
  volume = {3},
  pages = {1--122},
  issn = {1935-8237},
  doi = {10.1561/2200000016},
  url = {https://doi.org/10.1561/2200000016},
  urldate = {2020-06-03},
  abstract = {Many problems of recent interest in statistics and machine learning can be posed in the framework of convex optimization. Due to the explosion in size and complexity of modern datasets, it is increasingly important to be able to solve problems with a very large number of features or training examples. As a result, both the decentralized collection or storage of these datasets as well as accompanying distributed solution methods are either necessary or at least highly desirable. In this review, we argue that the alternating direction method of multipliers is well suited to distributed convex optimization, and in particular to large-scale problems arising in statistics, machine learning, and related areas. The method was developed in the 1970s, with roots in the 1950s, and is equivalent or closely related to many other algorithms, such as dual decomposition, the method of multipliers, Douglas–Rachford splitting, Spingarn's method of partial inverses, Dykstra's alternating projections, Bregman iterative algorithms for ℓ1 problems, proximal methods, and others. After briefly surveying the theory and history of the algorithm, we discuss applications to a wide variety of statistical and machine learning problems of recent interest, including the lasso, sparse logistic regression, basis pursuit, covariance selection, support vector machines, and many others. We also discuss general distributed optimization, extensions to the nonconvex setting, and efficient implementation, including some details on distributed MPI and Hadoop MapReduce implementations.},
  number = {1}
}

@inproceedings{bui-thanhExtremescale2012,
  title = {Extreme-Scale {{UQ}} for {{Bayesian}} Inverse Problems Governed by {{PDEs}}},
  booktitle = {2012 {{International Conference}} for {{High Performance Computing}}, {{Networking}}, {{Storage}} and {{Analysis}}},
  author = {Bui-Thanh, Tan and Burstedde, Carsten and Ghattas, Omar and Martin, James and Stadler, Georg and Wilcox, Lucas C.},
  date = {2012-11},
  pages = {1--11},
  publisher = {{IEEE}},
  location = {{Salt Lake City, UT}},
  doi = {10.1109/SC.2012.56},
  url = {http://ieeexplore.ieee.org/document/6468442/},
  urldate = {2020-09-15},
  abstract = {Quantifying uncertainties in large-scale simulations has emerged as the central challenge facing CS\&E. When the simulations require supercomputers, and uncertain parameter dimensions are large, conventional UQ methods fail. Here we address uncertainty quantification for large-scale inverse problems in a Bayesian inference framework: given data and model uncertainties, find the pdf describing parameter uncertainties. To overcome the curse of dimensionality of conventional methods, we exploit the fact that the data are typically informative about low-dimensional manifolds of parameter space to construct low rank approximations of the covariance matrix of the posterior pdf via a matrix-free randomized method. We obtain a method that scales independently of the forward problem dimension, the uncertain parameter dimension, the data dimension, and the number of cores. We apply the method to the Bayesian solution of an inverse problem in 3D global seismic wave propagation with over one million uncertain earth model parameters, 630 million wave propagation unknowns, on up to 262K cores, for which we obtain a factor of over 2000 reduction in problem dimension. This makes UQ tractable for the inverse problem.},
  eventtitle = {2012 {{SC}} - {{International Conference}} for {{High Performance Computing}}, {{Networking}}, {{Storage}} and {{Analysis}}},
  file = {/Users/hyan46/Zotero/storage/QUAVFJE5/Bui-Thanh et al. - 2012 - Extreme-scale UQ for Bayesian inverse problems gov.pdf},
  isbn = {978-1-4673-0805-2 978-1-4673-0806-9},
  langid = {english}
}

@article{bui-thanhSolving2014,
  title = {Solving Large-Scale {{PDE}}-Constrained {{Bayesian}} Inverse Problems with {{Riemann}} Manifold {{Hamiltonian Monte Carlo}}},
  author = {Bui-Thanh, T and Girolami, M},
  date = {2014-11-01},
  journaltitle = {Inverse Problems},
  shortjournal = {Inverse Problems},
  volume = {30},
  pages = {114014},
  issn = {0266-5611, 1361-6420},
  doi = {10.1088/0266-5611/30/11/114014},
  url = {https://iopscience.iop.org/article/10.1088/0266-5611/30/11/114014},
  urldate = {2020-09-15},
  file = {/Users/hyan46/Zotero/storage/Y2ICTJX3/Bui-Thanh and Girolami - 2014 - Solving large-scale PDE-constrained Bayesian inver.pdf},
  langid = {english},
  number = {11}
}

@article{bukkapatnamAnalysis1999,
  ids = {bukkapatnamAnalysis1999a},
  title = {Analysis of Acoustic Emission Signals in Machining},
  author = {Bukkapatnam, Satish and Kumara, Soundar RT and Lakhtakia, Akhlesh},
  date = {1999},
  issn = {1087-1357},
  file = {/Users/hyan46/Dropbox (ASU)/ZoteroData/Bukkapatnam et al_1999_Analysis of acoustic emission signals in machining.pdf},
  keywords = {acoustic emission,Aerospace,Change detection,Machining,Neural networks,nonlinear dynamics,Supervised learning,tool wear,wavelet packet}
}

@article{bukkapatnamChaotic1997,
  ids = {bukkapatnamChaotic1997a},
  title = {Chaotic Neurons for On-Line Quality Control in Manufacturing},
  author = {Bukkapatnam, Satish and Lakhtakia, A. and Kumara, S. R. T.},
  date = {1997},
  journaltitle = {International Journal of Advanced Manufacturing Technology},
  shortjournal = {Int J Adv Manuf Tech Int J Adv Manuf Tech},
  volume = {13},
  pages = {95--100},
  issn = {0268-3768},
  url = {://WOS:A1997WT38500003},
  abstract = {Given today's trend towards globalisation of markets, on-line quality control of manufacturing processes is deemed essential. We describe the use of neural networks and chaos theory to implement the idea of intelligent integrated diagnostics (IID) for this purpose. Our efforts are specifically concentrated on implementing IID in the turning process - a ubiquitous manufacturing process. We propose and develop two types of chaotic neurons - neural network architectures trained to capture the underlying chaotic dynamics of the turning process - to address the common problems of tool wear and chatter. The first, called the fractal estimation continuously estimates tool wear; the second, called the COPAVAS, initiates optimal chatter control.},
  keywords = {adaptive-observer,chaos theory,chatter,chatter control,computer vision,neural nets,signals,tool wear,turning},
  langid = {english},
  number = {2}
}

@article{bukkapatnamClassification2008,
  title = {Classification of Atrial Fibrillation Episodes from Sparse Electrocardiogram Data},
  author = {Bukkapatnam, Satish and Komanduri, R. and Yang, H. and Rao, P. and Lih, W. C. and Malshe, M. and Raff, L. M. and Benjamin, B. and Rockley, M.},
  date = {2008-07},
  journaltitle = {Journal of Electrocardiology},
  shortjournal = {J Electrocardiol J Electrocardiol},
  volume = {41},
  pages = {292--299},
  issn = {0022-0736},
  url = {://WOS:000257349600004},
  abstract = {Background: Atrial fibrillation (AF) is the most common form of cardiac arrhythmia. This paper presents the application of the Classification and Regression Tree (CART) technique for detecting spontaneous termination or sustenance of AF with sparse data. Method: Electrocardiogram (ECG) recordings were obtained from the PhysioNet (AF Termination Challenge Database 2004) Web site. Signal analysis, feature extraction, and classification were made to distinguish among 3 AF episodes, namely, Nonterminating (N), Soon ({$<$}1 minute) to be terminating (S), and Terminating immediately ({$<$}1 second) (T). Results: A continuous wavelet transform whose basis functions match the EKG patterns was found to yield compact representation (similar to 2 orders of magnitude). This facilitates the development of efficient algorithms for beat detection, QRST subtraction, and multiple ECG quantifier extraction (eg, QRS width, QT interval). A compact feature set was extracted through principal component analysis of these quantifiers. Accuracies exceeding 90\% for AF episode classification were achieved. Conclusions: A wavelet representation customized to the ECG signal pattern was found to yield 98\% lower entropies compared with other representations that use standard library wavelets. The Classification and Regression Tree (CART) technique seems to distinguish the N vs T, and the S vs T classifications very accurately. (C) 2008 Elsevier Inc. All rights reserved.},
  keywords = {atrial fibrillation (af),cart decision tree,challenge,computers,electrocardiogram (ecg),feature extraction,physionet,statistical analysis,termination,time,wavelet analysis},
  langid = {english},
  number = {4}
}

@article{bukkapatnamDynamic2007,
  title = {Dynamic Modeling and Monitoring of Contour Crafting - {{An}} Extrusion-Based Layered Manufacturing Process},
  author = {Bukkapatnam, Satish and Clark, B.},
  date = {2007-02},
  journaltitle = {Journal of Manufacturing Science and Engineering-Transactions of the Asme},
  shortjournal = {J Manuf Sci E-T Asme J Manuf Sci E-T Asme},
  volume = {129},
  pages = {135--142},
  issn = {1087-1357},
  url = {://WOS:000244467900015},
  abstract = {Layered manufacturing (LM) processes have emerged as legitimate processes for manufacturing various precision microelectronic components and bio-implants. These processes are also being considered for fabricating large customized free forms like buildings, statues, reactor beds, and car bodies. Many of these applications demand high levels of quality (e.g., R-a {$<$} 0.1 mu m) and functional performance. Among the LM processes, extrusion-based processes can potentially offer high production rates together with lower setup and operating costs. Yet process failures resulting from anomalies, such as nozzle clogging, overflow, dynamic instabilities, bambooing, and machine degradation impede a widespread applicability of these processes. Scientific principles that relate the sources of these anomalies to process. dynamics seem necessary for effective quality monitoring. In this paper we present a nonlinear lumped-mass model to capture dynamics underlying contour crafting, which is an extrusion-based LM process. The two degrees-of-freedom model, developed based on experimental characterizations, captures salient features of the process dynamics including the prominent manifestations of process nonlinearity. Experimental investigations show that the model can lead to effective monitoring of process conditions including overflow and underflow of material from extrusion nozzle, as well as suboptimal (fast and slow) feed rates of the extrusion head.},
  keywords = {injection,mold filling process,simulation},
  langid = {english},
  number = {1}
}

@article{bukkapatnamExperimental2008,
  title = {Experimental Dynamics Characterization and Monitoring of {{MRR}} in Oxide Chemical Mechanical Planarization ({{CMP}}) Process},
  author = {Bukkapatnam, Satish and Rao, P and Komanduri, R},
  date = {2008},
  journaltitle = {International Journal of Machine Tools and Manufacture},
  volume = {48},
  pages = {1375--1386},
  issn = {0890-6955},
  keywords = {Chemical mechanical planarization,Microelectronics,Nonlinear dynamics,Performance monitoring,Quality monitoring,Recurrence analysis,Regression,Supervised learning},
  number = {12-13}
}

@article{bukkapatnamForecasting2010,
  title = {Forecasting the Evolution of Nonlinear and Nonstationary Systems Using Recurrence-Based Local {{Gaussian}} Process Models},
  author = {Bukkapatnam, Satish and Cheng, Changqing},
  date = {2010},
  journaltitle = {Physical Review E},
  volume = {82},
  pages = {056206},
  file = {/Users/hyan46/Dropbox (ASU)/ZoteroData/Bukkapatnam_Cheng_2010_Forecasting the evolution of nonlinear and nonstationary systems using.pdf},
  keywords = {Application: Assembly,Automotive,Local Gaussian Process,Method: Recurrence,Nonlinear dynamics,Performance monitoring,Problem: Forecasting,Problem: Supervised learning,Throughput prediction},
  number = {5}
}

@article{bukkapatnamFractal2000,
  ids = {bukkapatnamFractal2000a},
  title = {Fractal Estimation of Flank Wear in Turning},
  author = {Bukkapatnam, Satish and Kumara, Soundar RT and Lakhtakia, Akhlesh},
  date = {2000},
  journaltitle = {J. Dyn. Sys., Meas., Control},
  volume = {122},
  pages = {89--94},
  issn = {0022-0434},
  file = {/Users/hyan46/Dropbox (ASU)/ZoteroData/Bukkapatnam et al_2000_Fractal estimation of flank wear in turning.pdf},
  keywords = {Application: Aerospace,Machining,Method: Deep Learning,nonlinear dynamics,Problem: Process Monitoring,sensor fusion,Supervised learning,tool wear,wavelet packet},
  number = {1}
}

@article{bukkapatnamGenetic2005,
  title = {A Genetic Algorithm for Unified Approach-Based Predictive Modeling of Fatigue Crack Growth},
  author = {Bukkapatnam, Satish and Sadananda, K},
  date = {2005},
  journaltitle = {International Journal of Fatigue},
  volume = {27},
  pages = {1354--1359},
  issn = {0142-1123},
  file = {/Users/hyan46/Dropbox (ASU)/ZoteroData/Bukkapatnam_Sadananda_2005_A genetic algorithm for unified approach-based predictive modeling of fatigue.pdf},
  number = {10-12}
}

@article{bukkapatnamLocal1999,
  title = {Local Eigenfunctions Based Suboptimal Wavelet Packet Representation of Contaminated Chaotic Signals},
  author = {Bukkapatnam, Satish and Kumara, S. R. T. and Lakhtakia, A.},
  date = {1999-10},
  journaltitle = {Ima Journal of Applied Mathematics},
  shortjournal = {Ima J Appl Math Ima J Appl Math},
  volume = {63},
  pages = {149--162},
  issn = {0272-4960},
  url = {://WOS:000083124600003},
  abstract = {We report a suboptimal wavelet packet representation (SWPR) of signals emanating from a chaotic attractor contaminated by low levels of noise. Our method-geared towards choosing a suboptimal scaling function to parsimoniously represent the signal-involves extracting local eigenfunctions using artificial ensembles generated from a psendo-probability space, and using the extracted local eigenfunctions to develop a suboptimal scaling function. The application of our novel representation method to actual acoustic emission (AE) signals, sampled as time-series data (TSD) from the turning process, reveals the superiority of these methods over the existing signal representations.},
  keywords = {filters},
  langid = {english},
  number = {2}
}

@article{bukkapatnamMachine2019,
  title = {Machine Learning and {{AI}} for Long-Term Fault Prognosis in Complex Manufacturing Systems},
  author = {Bukkapatnam, Satish and Afrin, Kahkashan and Dave, Darpit and Kumara, Soundar RT},
  date = {2019},
  journaltitle = {CIRP Annals},
  volume = {68},
  pages = {459--462},
  issn = {0007-8506},
  keywords = {Assembly,Automotive,Balanced Random Survival Forest,Breakdown prediction,Nonlinear dynamics,Prognotics,Supervised learning,Survival analysis},
  number = {1}
}

@article{bukkapatnamNeighborhood2002,
  title = {The Neighborhood Method and Its Coupling with the Wavelet Method for Signal Separation of Chaotic Signals},
  author = {Bukkapatnam, Satish and Kumara, S. R. T. and Lakhtakia, A. and Srinivasan, P.},
  date = {2002-10},
  journaltitle = {Signal Processing},
  shortjournal = {Signal Process Signal Process},
  volume = {82},
  pages = {1351--1374},
  issn = {0165-1684},
  url = {://WOS:000178707600005},
  abstract = {Signal separation, i.e., the elimination or suppression of extraneous components from measured signals, is an essential module of modem signal analysis. We report the development of two novel signal separation methods-(i) the neighborhood method (NM) and (ii) a modified wavelet method (MWM)-that seem to be aptly suited for signals acquired from machining process sensors, i.e., for chaotic signals with small, uniform Lyapunov exponents. For the NM, a variant of shadowing signal separation methods used for signal separation of chaotic signals, we establish theoretical bounds on performance under various noisy conditions and analyze its algorithmic complexity. Our MWM is an adaptation of Donoho's wavelet method to nonlinear, and possibly chaotic, signals with multiplicative noise. It incorporates certain features of the NM and it has lower algorithmic complexity than the NM, and is, therefore, more suitable for on-line implementation. Both methods were tested on chaotic signals corresponding to the reconstructed Rossler attractor. A discussion on the application of both methods to signals obtained from actual machining process sensors is provided in order to motivate their suitability to real-world nonlinear processes. (C) 2002 Elsevier Science B.V. All rights reserved.},
  keywords = {combinations,nonlinear signals,signal separation,wavelet method},
  langid = {english},
  number = {10}
}

@article{bukkapatnamParametrization2006,
  ids = {bukkapatnamParametrization2006a},
  title = {Parametrization of Interatomic Potential Functions Using a Genetic Algorithm Accelerated with a Neural Network},
  author = {Bukkapatnam, Satish and Malshe, M. and Agrawal, P. M. and Raff, L. M. and Komanduri, R.},
  date = {2006-12},
  journaltitle = {Physical Review B},
  shortjournal = {Phys Rev B Phys Rev B},
  volume = {74},
  issn = {2469-9950},
  url = {://WOS:000243195600018},
  abstract = {A genetic algorithm (GA) can be used to fit highly nonlinear functional forms, such as empirical interatomic potentials from a large ensemble of data. The performance of a GA for fitting such functional forms is enhanced through an approach that is based on the use of a neural network (NN) to accelerate the computation of the fitness function for the GA. Application of the new approach for fitting an ensemble of potentials computed from ab initio calculations to a specified functional form (here, the Tersoff potential functional form is used as an example) has shown that the computational efficiency achieved through the use of a NN can reduce computational time by over two orders of magnitude. The potentials estimated from functions thus fitted were within 0.1\% of the actual potential values. Specifically, the mean squared error (MSE) on molecular potentials was {$<$} 10(-5) eV(2) for fitting Tersoff potentials, and {$<$} 0.0025 eV(2) for fitting ab initio potential energies of isolated, 5-atom silicon clusters. Furthermore, since the potential was fitted to a physically meaningful Tersoff functional form, the resulting potential function appears to have the ability to extrapolate over a reasonable range of the parameter space, and may have a better accuracy in estimating the forces compared to that obtained from neural networks, which are often highly inaccurate when extrapolated. Hence, the method can be useful for rendering various molecular dynamics (MD) simulations more tractable. It is also apparent, based on the present investigation, that a Tersoff potential, albeit with different (GA parametrized) coefficients, is adequate for representing the ab initio potentials of 5-atom Si clusters.},
  keywords = {dynamics,energy surface,implementation,md simulation,metals,models,silicon,single-crystal aluminum,systems,vinyl bromide},
  langid = {english},
  number = {22}
}

@article{bukkapatnamPlanar2018,
  title = {Planar Random Graph Representations of Spatiotemporal Surface Morphology: {{Application}} to Finishing of 3-{{D}} Printed Components},
  author = {Bukkapatnam, Satish and Iquebal, A. S. and Kumara, S. R. T.},
  date = {2018},
  journaltitle = {Cirp Annals-Manufacturing Technology},
  shortjournal = {Cirp Ann-Manuf Techn Cirp Ann-Manuf Techn},
  volume = {67},
  pages = {495--498},
  issn = {0007-8506},
  url = {://WOS:000438470400122},
  abstract = {Surface finishing processes consume 20-70\% of the cycle time of the emerging additive manufacturing process chains. Effective representations of the spatiotemporal evolution of the surface morphology are imperative towards developing monitoring schemes to arrest cycle time overruns. We present a thermodynamically consistent random planar graph representation to monitor, via in situ imaging, the spatiotemporal evolution of surface morphology during finishing processes. Experimental investigations into the finishing of electron beam printed Ti-6Al-4V components to Sa {$<$} 20 nm roughness suggest that the proposed representation captures the complex interflow among neighbouring asperities during finishing, and establishes a radically new endpoint criterion, i.e., surface quality improves only until each asperity interflows with six neighbours. (C) 2018 Published by Elsevier Ltd on behalf of CIRP.},
  keywords = {finishing,network,quality assurance,spectral graph analytics},
  langid = {english},
  number = {1}
}

@article{bukkapatnamProcess2007,
  title = {Process Characterization and Statistical Analysis of Oxide {{CMP}} on a Silicon Wafer with Sparse Data},
  author = {Bukkapatnam, Satish and Rao, PK and Lih, W-C and Chandrasekaran, N and Komanduri, R},
  date = {2007},
  journaltitle = {Applied Physics A},
  volume = {88},
  pages = {785--792},
  issn = {0947-8396},
  keywords = {Chemical mechanical planarization,Microelectronics,Performance monitoring,Quality monitoring,Supervised learning},
  number = {4}
}

@article{bukkapatnamWaveletbased2005,
  title = {A Wavelet-Based, Distortion Energy Approach to Structural Health Monitoring},
  author = {Bukkapatnam, Satish and Nichols, J. M. and Seaver, M. and Trickey, S. T. and Hunter, M.},
  date = {2005-09},
  journaltitle = {Structural Health Monitoring-an International Journal},
  shortjournal = {Struct Health Monit Struct Health Monit},
  volume = {4},
  pages = {247--258},
  issn = {1475-9217},
  url = {://WOS:000231952900004},
  abstract = {A method for quantifying damage-induced distortions to the vibrational response of an experimental plate is presented. By examining a wavelet representation of the difference in strain response between the damaged and the undamaged structures, the distortion energy may be computed on multiple timescales. This feature is tested in its ability to detect both the presence and the location of degradation of the plate. In addition, the effects of competing excitation mechanisms, including the outputs of Lorenz and Rossler systems, as well as a 0-225 Hz Gaussian noise are studied. The results indicate that the distortion energies, statistically speaking, are significantly higher under damaged conditions compared to those extracted under undamaged conditions, implying that the new distortion energy approach will yield adequate features for detecting the presence as well as possibly the location of damage in a structure.},
  keywords = {attractor,bragg grating strain sensor,chaotic excitation,damage detection,wavelets},
  langid = {english},
  number = {3}
}

@online{chalkidisEmpirical2020,
  title = {An {{Empirical Study}} on {{Large}}-{{Scale Multi}}-{{Label Text Classification Including Few}} and {{Zero}}-{{Shot Labels}}},
  author = {Chalkidis, Ilias and Fergadiotis, Manos and Kotitsas, Sotiris and Malakasiotis, Prodromos and Aletras, Nikolaos and Androutsopoulos, Ion},
  date = {2020-10-04},
  url = {http://arxiv.org/abs/2010.01653},
  urldate = {2021-06-15},
  abstract = {Large-scale Multi-label Text Classification (LMTC) has a wide range of Natural Language Processing (NLP) applications and presents interesting challenges. First, not all labels are well represented in the training set, due to the very large label set and the skewed label distributions of LMTC datasets. Also, label hierarchies and differences in human labelling guidelines may affect graph-aware annotation proximity. Finally, the label hierarchies are periodically updated, requiring LMTC models capable of zero-shot generalization. Current state-of-the-art LMTC models employ Label-Wise Attention Networks (LWANs), which (1) typically treat LMTC as flat multi-label classification; (2) may use the label hierarchy to improve zero-shot learning, although this practice is vastly understudied; and (3) have not been combined with pre-trained Transformers (e.g. BERT), which have led to state-of-the-art results in several NLP benchmarks. Here, for the first time, we empirically evaluate a battery of LMTC methods from vanilla LWANs to hierarchical classification approaches and transfer learning, on frequent, few, and zero-shot learning on three datasets from different domains. We show that hierarchical methods based on Probabilistic Label Trees (PLTs) outperform LWANs. Furthermore, we show that Transformer-based approaches outperform the state-of-the-art in two of the datasets, and we propose a new state-of-the-art method which combines BERT with LWANs. Finally, we propose new models that leverage the label hierarchy to improve few and zero-shot learning, considering on each dataset a graph-aware annotation proximity measure that we introduce.},
  archiveprefix = {arXiv},
  eprint = {2010.01653},
  eprinttype = {arxiv},
  file = {/Users/hyan46/Dropbox (ASU)/ZoteroData/Chalkidis et al_2020_An Empirical Study on Large-Scale Multi-Label Text Classification Including Few.pdf;/Users/hyan46/Zotero/storage/KI5VL5JI/2010.html},
  keywords = {Computer Science - Computation and Language},
  primaryclass = {cs}
}

@article{chandolaAnomaly2009,
  title = {Anomaly Detection: {{A}} Survey},
  shorttitle = {Anomaly Detection},
  author = {Chandola, Varun and Banerjee, Arindam and Kumar, Vipin},
  date = {2009-07-30},
  journaltitle = {ACM Computing Surveys},
  shortjournal = {ACM Comput. Surv.},
  volume = {41},
  pages = {15:1--15:58},
  issn = {0360-0300},
  doi = {10.1145/1541880.1541882},
  url = {https://doi.org/10.1145/1541880.1541882},
  urldate = {2020-05-25},
  abstract = {Anomaly detection is an important problem that has been researched within diverse research areas and application domains. Many anomaly detection techniques have been specifically developed for certain application domains, while others are more generic. This survey tries to provide a structured and comprehensive overview of the research on anomaly detection. We have grouped existing techniques into different categories based on the underlying approach adopted by each technique. For each category we have identified key assumptions, which are used by the techniques to differentiate between normal and anomalous behavior. When applying a given technique to a particular domain, these assumptions can be used as guidelines to assess the effectiveness of the technique in that domain. For each category, we provide a basic anomaly detection technique, and then show how the different existing techniques in that category are variants of the basic technique. This template provides an easier and more succinct understanding of the techniques belonging to each category. Further, for each category, we identify the advantages and disadvantages of the techniques in that category. We also provide a discussion on the computational complexity of the techniques since it is an important issue in real application domains. We hope that this survey will provide a better understanding of the different directions in which research has been done on this topic, and how techniques developed in one area can be applied in domains for which they were not intended to begin with.},
  keywords = {anomaly,Anomaly detection,outlier detection},
  number = {3}
}

@article{changBayesian2015,
  title = {Bayesian {{Sensitivity Analysis}} of a {{Cardiac Cell Model Using}} a {{Gaussian Process Emulator}}},
  author = {Chang, Eugene T. Y. and Strong, Mark and Clayton, Richard H.},
  date = {2015-06-26},
  journaltitle = {PLOS ONE},
  shortjournal = {PLOS ONE},
  volume = {10},
  pages = {e0130252},
  publisher = {{Public Library of Science}},
  issn = {1932-6203},
  doi = {10.1371/journal.pone.0130252},
  url = {https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0130252},
  urldate = {2020-05-24},
  abstract = {Models of electrical activity in cardiac cells have become important research tools as they can provide a quantitative description of detailed and integrative physiology. However, cardiac cell models have many parameters, and how uncertainties in these parameters affect the model output is difficult to assess without undertaking large numbers of model runs. In this study we show that a surrogate statistical model of a cardiac cell model (the Luo-Rudy 1991 model) can be built using Gaussian process (GP) emulators. Using this approach we examined how eight outputs describing the action potential shape and action potential duration restitution depend on six inputs, which we selected to be the maximum conductances in the Luo-Rudy 1991 model. We found that the GP emulators could be fitted to a small number of model runs, and behaved as would be expected based on the underlying physiology that the model represents. We have shown that an emulator approach is a powerful tool for uncertainty and sensitivity analysis in cardiac cell models.},
  file = {/Users/hyan46/Dropbox (ASU)/ZoteroData/Chang et al_2015_Bayesian Sensitivity Analysis of a Cardiac Cell Model Using a Gaussian Process.PDF},
  keywords = {Action potentials,Biophysics,Cardiac,Cell membranes,Computer modeling,GP,Ion channels,metamodel,Method: Bayesian,Monte Carlo method,Normal distribution,Sensory physiology},
  langid = {english},
  number = {6}
}

@article{Change,
  title = {Change {{Detection}} in {{Dynamic Multi}}-{{Dimensional Data Streams Using The ARMAX}}-{{GARCH Model}}},
  file = {/Users/hyan46/Dropbox (ASU)/ZoteroData/Change Detection in Dynamic Multi-Dimensional Data Streams Using The.pdf}
}

@article{changQuantitative2012,
  title = {Quantitative Characterization and Modeling Strategy of Nanoparticle Dispersion in Polymer Composites},
  author = {Chang, Chia-Jung and Xu, Lijuan and Huang, Qiang and Shi, Jianjun},
  date = {2012-07},
  journaltitle = {IIE Transactions},
  shortjournal = {IIE Transactions},
  volume = {44},
  pages = {523--533},
  issn = {0740-817X, 1545-8830},
  doi = {10.1080/0740817X.2011.588995},
  url = {http://www.tandfonline.com/doi/abs/10.1080/0740817X.2011.588995},
  urldate = {2020-07-04},
  abstract = {Nanoparticle dispersion plays a crucial role in the mechanical properties of polymer nanocomposites. Transmission Electron Microscope/Scanning Electron Microscope (TEM/SEM) images are commonly used to represent nanoparticle dispersion without further quantifications on its properties. Therefore, there is a strong need to develop a quantitative measure to effectively describe nanoparticle dispersion from a TEM/SEM image. This article reports an effective modeling strategy to characterize nanoparticle dispersion states among different locations of a nanocomposite surface. An engineering-driven inhomogenous Poisson random field is proposed to represent the nanoparticle dispersion at the nanoscale. The model parameters are estimated through the Bayesian Markov Chain Monte Carlo technique to overcome the challenge of the limited amount of accessible data due to the time-consuming sample collection process. The TEM images taken from nano-silica/epoxy composites are used to support the proposed methodology. The research strategy and framework are generally applicable to other nanocomposite materials.},
  file = {/Users/hyan46/Dropbox (ASU)/ZoteroData/Chang et al_2012_Quantitative characterization and modeling strategy of nanoparticle dispersion.pdf},
  keywords = {Application: Manufacturing,Application: Nano,Application: Surface Scanning,Method: Functional,People: Qiang Huang},
  langid = {english},
  number = {7}
}

@article{chehadeDatalevel2018,
  title = {A Data-Level Fusion Approach for Degradation Modeling and Prognostic Analysis under Multiple Failure Modes},
  author = {Chehade, Abdallah and Song, Changyue and Liu, Kaibo and Saxena, Abhinav and Zhang, Xi},
  date = {2018-04-03},
  journaltitle = {Journal of Quality Technology},
  shortjournal = {Journal of Quality Technology},
  volume = {50},
  pages = {150--165},
  issn = {0022-4065, 2575-6230},
  doi = {10.1080/00224065.2018.1436829},
  url = {https://www.tandfonline.com/doi/full/10.1080/00224065.2018.1436829},
  urldate = {2020-07-04},
  abstract = {Operating units, in practice, often suffer from multiple modes of failure, and each failure mode has a distinct influence on the service life cycle path of a unit. The rapid development of sensor and communication technologies has enabled multiple sensors to simultaneously monitor and track the health status of a unit in real time. However, one challenging question that remains to be resolved is how to leverage data from multiple sensors for better degradation modeling and prognostic analysis, especially when there are multiple failure modes. Currently, many of the existing approaches in prognostics either (a) fail to capture the dependency between sensors and instead focus on analyzing each sensor independently or (b) fail to incorporate the failure-mode diagnosis for better degradation modeling and prognostics during condition monitoring. To address the limitations in the existing literature, we propose a data-level fusion methodology to construct a composite failure-mode index, named FM-INDEX, via the fusion of multiple sensor data. Our goal is to utilize the FM-INDEX to better characterize the failure mode of an operating unit in real time, thus leading to better degradation modeling and prognostic analysis. A case study that involves the degradation data set of an aircraft gas turbine engine with two potential failure modes is conducted to numerically evaluate the performance of our proposed method compared to other techniques in the related literature.},
  file = {/Users/hyan46/Dropbox (ASU)/ZoteroData/Chehade et al_2018_A data-level fusion approach for degradation modeling and prognostic analysis.pdf},
  keywords = {Application: Engine,Data: Profiles,Method: Health Index,People: Kaibo Liu,Problem: Prognostics},
  langid = {english},
  number = {2}
}

@article{chehadeSensoryBased2017,
  title = {Sensory-{{Based Failure Threshold Estimation}} for {{Remaining Useful Life Prediction}}},
  author = {Chehade, Abdallah and Bonk, Scott and Liu, Kaibo},
  date = {2017-09},
  journaltitle = {IEEE Transactions on Reliability},
  shortjournal = {IEEE Trans. Rel.},
  volume = {66},
  pages = {939--949},
  issn = {0018-9529, 1558-1721},
  doi = {10.1109/TR.2017.2695119},
  url = {http://ieeexplore.ieee.org/document/7924404/},
  urldate = {2020-07-04},
  abstract = {The rapid development of sensor and computing technology has created an unprecedented opportunity for condition monitoring and prognostic analysis in various manufacturing and healthcare industries. With the massive amount of sensor information available, important research efforts have been made in modeling the degradation signals of a unit and estimating its remaining useful life distribution. In particular, a unit is often considered to have failed when its degradation signal crosses a predefined failure threshold, which is assumed to be known a priori. Unfortunately, such a simplified assumption may not be valid in many applications given the stochastic nature of the underlying degradation mechanism. While there are some extended studies considering the variability in the estimated failure threshold via data-driven approaches, they focus on the failure threshold distribution of the population instead of that of an individual unit. Currently, the existing literature still lacks an effective approach to accurately estimate the failure threshold distribution of an operating unit based on its in-situ sensory data during condition monitoring. To fill this literature gap, this paper develops a convex quadratic formulation that combines the information from the degradation profiles of historical units and the in-situ sensory data from an operating unit to online estimate the failure threshold of this particular unit in the field. With a more accurate estimation of the failure threshold of the operating unit in real time, a better remaining useful life prediction is expected. Simulations as well as a case study involving a degradation dataset of aircraft turbine engines were used to numerically evaluate and compare the performance of the proposed methodology with the existing literature in the context of failure threshold estimation and remaining useful life prediction.},
  file = {/Users/hyan46/Dropbox (ASU)/ZoteroData/Chehade et al_2017_Sensory-Based Failure Threshold Estimation for Remaining Useful Life Prediction.pdf},
  keywords = {Application: Engine,Data: Profiles,People: Kaibo Liu,Problem: Prognostics},
  langid = {english},
  number = {3}
}

@article{chehadeStructural2019,
  title = {Structural {{Degradation Modeling Framework}} for {{Sparse Data Sets With}} an {{Application}} on {{Alzheimer}}’s {{Disease}}},
  author = {Chehade, Abdallah and Liu, Kaibo},
  date = {2019-01},
  journaltitle = {IEEE Transactions on Automation Science and Engineering},
  shortjournal = {IEEE Trans. Automat. Sci. Eng.},
  volume = {16},
  pages = {192--205},
  issn = {1545-5955, 1558-3783},
  doi = {10.1109/TASE.2018.2829770},
  url = {https://ieeexplore.ieee.org/document/8361039/},
  urldate = {2020-07-04},
  abstract = {The rapid development of information technologies provided unprecedented big data environments for condition monitoring and degradation analyses. However, the available big data sets are often sparse with a limited number of observations per recorded unit. For example, in many healthcare systems, data are collected from a large number of patients, but the available observations from each patient are quite limited. Unfortunately, most of the existing approaches for data-driven degradation modeling may not work well in this scenario as they either pool the information from the population or require rich historical observations in each unit. To address the challenges in “sparse data environments,” this paper proposes a structural degradation modeling framework (SDM). The SDM is inspired by the recommender system, which provides recommendations about specific items for the user. In addition, it is also tailored to the needs of degradation modeling. In particular, the framework takes into consideration: 1) the available data from the unit of interest; 2) the population characteristics; 3) the relationship between the available units; and 4) the precision of the available units. Simulation studies and a case study that involves the Alzheimer’s disease (AD) neuroimaging initiative data set are conducted, which shows satisfactory performance of the proposed method.},
  file = {/Users/hyan46/Dropbox (ASU)/ZoteroData/Chehade_Liu_2019_Structural Degradation Modeling Framework for Sparse Data Sets With an.pdf},
  keywords = {Application: Engine,Application: Health,Data: Profiles,Method: Health Index,People: Kaibo Liu,Problem: Prognostics},
  langid = {english},
  number = {1}
}

@inproceedings{chen2015event,
  title = {Event Extraction via Dynamic Multi-Pooling Convolutional Neural Networks},
  booktitle = {Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing (Volume 1: {{Long}} Papers)},
  author = {Chen, Yubo and Xu, Liheng and Liu, Kang and Zeng, Daojian and Zhao, Jun},
  date = {2015},
  pages = {167--176}
}

@article{chengControl2012,
  title = {Towards Control of Carbon Nanotube Synthesis Process Using Prediction-Based Fast {{Monte Carlo}} Simulations},
  author = {Cheng, Changqing and Bukkapatnam, Satish and Raff, Lionel M and Komanduri, Ranga},
  date = {2012},
  journaltitle = {Journal of manufacturing systems},
  volume = {31},
  pages = {438--443}
}

@article{chengHybrid2020,
  title = {A Hybrid Transfer Learning Framework for In-Plane Freeform Shape Accuracy Control in Additive Manufacturing},
  author = {Cheng, Longwei and Wang, Kai and Tsung, Fugee},
  date = {2020-04-22},
  journaltitle = {IISE Transactions},
  shortjournal = {IISE Transactions},
  pages = {1--15},
  issn = {2472-5854, 2472-5862},
  doi = {10.1080/24725854.2020.1741741},
  url = {https://www.tandfonline.com/doi/full/10.1080/24725854.2020.1741741},
  urldate = {2020-07-20},
  abstract = {Shape accuracy control is one of the quality issues of greatest concern in Additive Manufacturing (AM). An efficient approach to improving the shape accuracy of a fabricated product is to compensate the fabrication errors of AM systems by modifying the input shape defined by a digital design model. In contrast with mass production, AM processes typically fabricate customized products with extremely low volume and huge shape varieties, which makes shape accuracy control in AM a challenging problem. In this article, we propose a hybrid transfer learning framework to predict and compensate the in-plane shape deviations of new and untried freeform products based on a small number of previously fabricated products. Within this framework, the shape deviation is decomposed into a shape-independent error and a shape-specific error. A parameter-based transfer learning approach is used to facilitate a sharing of parameters for modeling the shape-independent error, whereas a feature-based transfer learning approach is taken to promote the learning of a common representation of local shape features for modeling the shape-specific error. Experimental studies of a fused filament fabrication process demonstrate the effectiveness of our proposed framework in predicting the shape deviation and improving the shape accuracy of new products with freeform shapes.},
  file = {/Users/hyan46/Dropbox (ASU)/ZoteroData/Cheng et al_2020_A hybrid transfer learning framework for in-plane freeform shape accuracy.pdf},
  keywords = {Application: Additive Manufacturing,Method: Functional,Method: Transfer Learning,Problem: Control},
  langid = {english}
}

@online{chengInferring2019,
  title = {Inferring {{Trip Destinations}} in {{Transit Smart Card Data Using}} a {{Probabilistic Topic Model}}},
  author = {Cheng, Zhanhong and Trépanier, Martin and Sun, Lijun},
  date = {2019},
  url = {/paper/Inferring-Trip-Destinations-in-Transit-Smart-Card-a-Cheng-Tr%C3%A9panier/9c91f340251ff92fdb4c9744a984308683f44f82},
  urldate = {2020-05-31},
  abstract = {Inferring trip destination in smart card data with only tap-in control is an important application. Most existing methods estimate trip destination based on the continuity of trip chains, while the destinations of isolated/unlinked trips cannot be properly handled. We address this problem with a probabilistic topic model. A three-dimensional Latent Dirichlet Allocation (LDA) model is developed to extract latent topics of departure time, origin, and destination among the population; each passenger’s travel behavior is characterized by a latent topic distribution defined on a three-dimensional simplex. Given the origin station and departure time, the most likely destination can be obtained by statistical inference. Furthermore, we propose to represent stations by their rank of visiting frequency, which transforms divergent spatial patterns into similar behavioral regularities. The proposed destination estimation framework is tested on Guangzhou Metro smart card data, in which the ground-truth is available. Compared with benchmark models, the topic model not only shows increased accuracy but also captures essential latent patterns in passengers’ travel behavior. The proposed topic model can be used to infer the destination of unlinked trips, analyze travel pattern, and passenger clustering.},
  file = {/Users/hyan46/Dropbox (ASU)/ZoteroData/Cheng et al_2019_Inferring Trip Destinations in Transit Smart Card Data Using a Probabilistic2.pdf;/Users/hyan46/Zotero/storage/GCJ67BLI/9c91f340251ff92fdb4c9744a984308683f44f82.html},
  keywords = {Method: Tensor},
  langid = {english}
}

@article{chengPrediction2018,
  title = {A Prediction and Compensation Scheme for In-Plane Shape Deviation of Additive Manufacturing with Information on Process Parameters},
  author = {Cheng, Longwei and Wang, Andi and Tsung, Fugee},
  date = {2018-05-04},
  journaltitle = {IISE Transactions},
  shortjournal = {IISE Transactions},
  volume = {50},
  pages = {394--406},
  issn = {2472-5854, 2472-5862},
  doi = {10.1080/24725854.2017.1402224},
  url = {https://www.tandfonline.com/doi/full/10.1080/24725854.2017.1402224},
  urldate = {2020-07-20},
  file = {/Users/hyan46/Dropbox (ASU)/ZoteroData/Cheng et al_2018_A prediction and compensation scheme for in-plane shape deviation of additive.pdf},
  keywords = {Application: Additive Manufacturing,Method: Functional,Method: Gaussian Process,Method: Kernel,Problem: Supervised Learning},
  langid = {english},
  number = {5}
}

@article{chengTime2015,
  title = {Time Series Forecasting for Nonlinear and Non-Stationary Processes: {{A}} Review and Comparative Study},
  author = {Cheng, Changqing and Sa-Ngasoongsong, Akkarapol and Beyca, Omer and Le, Trung and Yang, Hui and Kong, Zhenyu and Bukkapatnam, Satish},
  date = {2015},
  journaltitle = {Iie Transactions},
  volume = {47},
  pages = {1053--1071},
  issn = {0740-817X},
  file = {/Users/hyan46/Dropbox (ASU)/ZoteroData/Cheng et al_2015_Time series forecasting for nonlinear and non-stationary processes.pdf},
  keywords = {Data: Time Series,Method: Nonlinear},
  number = {10}
}

@article{chengUltraprecision2015,
  title = {Ultra-Precision Machining Process Dynamics and Surface Quality Monitoring},
  author = {Cheng, Changqing and Wang, Zimo and Hung, Wayne and Bukkapatnam, Satish and Komanduri, Ranga},
  date = {2015},
  journaltitle = {Procedia Manufacturing},
  volume = {1},
  pages = {607--618},
  issn = {2351-9789},
  keywords = {Aerospace,Gaussian process,Machining,Nonlinear dynamics,Quality monitoring,Supervised learning,Surface finish,Ultraprecision}
}

@article{chenRobust,
  title = {Robust {{Sparse Regression}} under {{Adversarial Corruption}}},
  author = {Chen, Yudong and Caramanis, Constantine and Mannor, Shie},
  pages = {9},
  abstract = {We consider high dimensional sparse regression with arbitrary – possibly, severe or coordinated – errors in the covariates matrix. We are interested in understanding how many corruptions we can tolerate, while identifying the correct support. To the best of our knowledge, neither standard outlier rejection techniques, nor recently developed robust regression algorithms (that focus only on corrupted response variables), nor recent algorithms for dealing with stochastic noise or erasures, can provide guarantees on support recovery. As we show, neither can the natural brute force algorithm that takes exponential time to find the subset of data and support columns, that yields the smallest regression error.},
  file = {/Users/hyan46/Dropbox (ASU)/ZoteroData/Chen et al_Robust Sparse Regression under Adversarial Corruption.pdf},
  langid = {english}
}

@article{chenTimedependent2020,
  title = {A {{Time}}-Dependent {{SIR}} Model for {{COVID}}-19 with {{Undetectable Infected Persons}}},
  author = {Chen, Yi-Cheng and Lu, Ping-En and Chang, Cheng-Shang and Liu, Tzu-Hsuan},
  date = {2020},
  journaltitle = {IEEE Transactions on Network Science and Engineering},
  shortjournal = {IEEE Trans. Netw. Sci. Eng.},
  pages = {1--1},
  issn = {2327-4697, 2334-329X},
  doi = {10.1109/TNSE.2020.3024723},
  url = {http://arxiv.org/abs/2003.00122},
  urldate = {2020-12-19},
  abstract = {In this paper, we conduct mathematical and numerical analyses to address the following crucial questions for COVID-19: (Q1) Is it possible to contain COVID-19? (Q2) When will be the peak and the end of the epidemic? (Q3) How do the asymptomatic infections affect the spread of disease? (Q4) What is the ratio of the population that needs to be infected to achieve herd immunity? (Q5) How effective are the social distancing approaches? (Q6) What is the ratio of the population infected in the long run? For (Q1) and (Q2), we propose a time-dependent susceptible-infected-recovered (SIR) model that tracks 2 time series: (i) the transmission rate at time t and (ii) the recovering rate at time t. Such an approach is more adaptive than traditional static SIR models and more robust than direct estimation methods. Using the data provided by China, we show that the one-day prediction errors for the numbers of confirmed cases are almost in 3\%, and the total number of confirmed cases is precisely predicted. Also, the turning point, defined as the day that the transmission rate is less than the recovering rate can be accurately predicted. After that day, the basic reproduction number \$R\_0\$ is less than 1. For (Q3), we extend our SIR model by considering 2 types of infected persons: detectable and undetectable infected persons. Whether there is an outbreak in such a model is characterized by the spectral radius of a 2 by 2 matrix that is closely related to \$R\_0\$. For (Q4), we show that herd immunity can be achieved after at least 1-1/\$R\_0\$ fraction of individuals being infected. For (Q5) and (Q6), we analyze the independent cascade (IC) model for disease propagation in a configuration random graph. By relating the propagation probabilities in the IC model to the transmission rates and recovering rates in the SIR model, we show 2 approaches of social distancing that can lead to a reduction of \$R\_0\$.},
  archiveprefix = {arXiv},
  eprint = {2003.00122},
  eprinttype = {arxiv},
  file = {/Users/hyan46/Zotero/storage/KLAZZKGF/Chen et al. - 2020 - A Time-dependent SIR model for COVID-19 with Undet.pdf},
  keywords = {Computer Science - Machine Learning,Quantitative Biology - Populations and Evolution,Statistics - Machine Learning},
  langid = {english}
}

@article{choeChangePoint2016,
  title = {Change-{{Point Detection}} on {{Solar Panel Performance Using Thresholded LASSO}}:},
  shorttitle = {Change-{{Point Detection}} on {{Solar Panel Performance Using Thresholded LASSO}}},
  author = {Choe, Youngjun and Guo, Weihong and Byon, Eunshin and Jin, Jionghua and Li, Jingjing},
  date = {2016-12},
  journaltitle = {Quality and Reliability Engineering International},
  shortjournal = {Qual. Reliab. Engng. Int.},
  volume = {32},
  pages = {2653--2665},
  issn = {07488017},
  doi = {10.1002/qre.2077},
  url = {http://doi.wiley.com/10.1002/qre.2077},
  urldate = {2020-07-04},
  file = {/Users/hyan46/Dropbox (ASU)/ZoteroData/Choe et al_2016_Change-Point Detection on Solar Panel Performance Using Thresholded LASSO.pdf},
  keywords = {Application: Solar,Method: Sparse,People: Judy Jin,Problem: Process Monitoring},
  langid = {english},
  number = {8}
}

@online{clearZettelkasten,
  title = {Zettelkasten — {{How One German Scholar Was So Freakishly Productive}}},
  author = {Clear, David B},
  file = {/Users/hyan46/Dropbox (ASU)/ZoteroData/Clear_Zettelkasten — How One German Scholar Was So Freakishly Productive.pdf},
  langid = {english}
}

@inproceedings{cockayneProbabilistic2017,
  title = {Probabilistic Numerical Methods for {{PDE}}-Constrained {{Bayesian}} Inverse Problems},
  author = {Cockayne, Jon and Oates, Chris and Sullivan, Tim and Girolami, Mark},
  date = {2017},
  pages = {060001},
  location = {{Ghent, Belgium}},
  doi = {10.1063/1.4985359},
  url = {http://aip.scitation.org/doi/abs/10.1063/1.4985359},
  urldate = {2020-09-15},
  abstract = {This paper develops meshless methods for probabilistically describing discretisation error in the numerical solution of partial differential equations. This construction enables the solution of Bayesian inverse problems while accounting for the impact of the discretisation of the forward problem. In particular, this drives statistical inferences to be more conservative in the presence of significant solver error. Theoretical results are presented describing rates of convergence for the posteriors in both the forward and inverse problems. This method is tested on a challenging inverse problem with a nonlinear forward model.},
  eventtitle = {{{BAYESIAN INFERENCE AND MAXIMUM ENTROPY METHODS IN SCIENCE AND ENGINEERING}}: {{Proceedings}} of the 36th {{International Workshop}} on {{Bayesian Inference}} and {{Maximum Entropy Methods}} in {{Science}} and {{Engineering}} ({{MaxEnt}} 2016)},
  file = {/Users/hyan46/Zotero/storage/GNXP3T33/Cockayne et al. - 2017 - Probabilistic numerical methods for PDE-constraine.pdf},
  langid = {english}
}

@article{colosimoOpportunities2018,
  title = {Opportunities and Challenges of Quality Engineering for Additive Manufacturing},
  author = {Colosimo, Bianca M. and Huang, Qiang and Dasgupta, Tirthankar and Tsung, Fugee},
  date = {2018-07-03},
  journaltitle = {Journal of Quality Technology},
  shortjournal = {Journal of Quality Technology},
  volume = {50},
  pages = {233--252},
  issn = {0022-4065, 2575-6230},
  doi = {10.1080/00224065.2018.1487726},
  url = {https://www.tandfonline.com/doi/full/10.1080/00224065.2018.1487726},
  urldate = {2020-07-04},
  abstract = {Additive manufacturing (AM), commonly known as three-dimensional printing, is widely recognized as a disruptive technology, and it has the potential to fundamentally change the nature of future manufacturing. Through building products layer by layer, AM represents a paradigm shift in manufacturing, with many industrial applications. It enables production of huge varieties of customized products with considerable geometric complexity, extended capabilities, and functional performances. Despite tremendous enthusiasm AM faces major research challenges for widespread adoption of this innovative technology. Specifically, addressing the unique challenges associated with quality engineering of AM processes is crucial to the eventual success of AM. This article presents an overview of quality-related issues for AM processes and products, focusing on opportunities and challenges in quality inspection, monitoring, control, optimization, and transfer learning as well as on building quality into the product through design.},
  file = {/Users/hyan46/Dropbox (ASU)/ZoteroData/Colosimo et al_2018_Opportunities and challenges of quality engineering for additive manufacturing.pdf},
  keywords = {Application: Additive Manufacturing,Application: Manufacturing,People: Qiang Huang,Problem: Process Monitoring},
  langid = {english},
  number = {3}
}

@online{Computational,
  title = {Computational and {{Data}}-{{Enabled Science}} and {{Engineering}} | {{NSF}} - {{National Science Foundation}}},
  url = {https://www.nsf.gov/funding/pgm_summ.jsp?pims_id=504813},
  urldate = {2020-05-23},
  file = {/Users/hyan46/Dropbox (ASU)/ZoteroData/Computational and Data-Enabled Science and Engineering NSF - National Science.pdf;/Users/hyan46/Zotero/storage/PCISFQMQ/pgm_summ.html},
  keywords = {Funding}
}

@article{cotterApproximation2010,
  title = {Approximation of {{Bayesian Inverse Problems}} for {{PDEs}}},
  author = {Cotter, S. L. and Dashti, M. and Stuart, A. M.},
  date = {2010-01},
  journaltitle = {SIAM Journal on Numerical Analysis},
  shortjournal = {SIAM J. Numer. Anal.},
  volume = {48},
  pages = {322--345},
  issn = {0036-1429, 1095-7170},
  doi = {10.1137/090770734},
  url = {http://epubs.siam.org/doi/10.1137/090770734},
  urldate = {2020-09-15},
  abstract = {Inverse problems are often ill posed, with solutions that depend sensitively on data. In any numerical approach to the solution of such problems, regularization of some form is needed to counteract the resulting instability. This paper is based on an approach to regularization, employing a Bayesian formulation of the problem, which leads to a notion of well posedness for inverse problems, at the level of probability measures. The stability which results from this well posedness may be used as the basis for quantifying the approximation, in finite dimensional spaces, of inverse problems for functions. This paper contains a theory which utilizes this stability property to estimate the distance between the true and approximate posterior distributions, in the Hellinger metric, in terms of error estimates for approximation of the underlying forward problem. This is potentially useful as it allows for the transfer of estimates from the numerical analysis of forward problems into estimates for the solution of the related inverse problem. It is noteworthy that, when the prior is a Gaussian random field model, controlling differences in the Hellinger metric leads to control on the differences between expected values of polynomially bounded functions and operators, including the mean and covariance operator. The ideas are applied to some non-Gaussian inverse problems where the goal is determination of the initial condition for the Stokes or Navier–Stokes equation from Lagrangian and Eulerian observations, respectively.},
  file = {/Users/hyan46/Zotero/storage/X4YBFCMA/Cotter et al. - 2010 - Approximation of Bayesian Inverse Problems for PDE.pdf},
  langid = {english},
  number = {1}
}

@article{coxRegression1972,
  title = {Regression {{Models}} and {{Life}}-{{Tables}}},
  author = {Cox, D R},
  date = {1972},
  journaltitle = {Journal of the Royal Statistical Society: Series B (Methodological)},
  volume = {34},
  pages = {187--202},
  abstract = {The analysis of censored failure times is considered. It is assumed that on each individual are available values of one or more explanatory variables. The hazard function (age-specific failure rate) is taken to be a function of the explanatory variables and unknown regression coefficients multiplied by an arbitrary and unknown function of time. A conditional likelihood is obtained, leading to inferences about the unknown regression coefficients. Some generalizations are outlined.},
  file = {/Users/hyan46/Dropbox (ASU)/ZoteroData/Cox_2020_Regression Models and Life-Tables.pdf},
  langid = {english}
}

@article{dahireBayesian2018,
  title = {Bayesian {{Network}} Inference for Probabilistic Strength Estimation of Aging Pipeline Systems},
  author = {Dahire, Sonam and Tahir, Fraaz and Jiao, Yang and Liu, Yongming},
  date = {2018},
  journaltitle = {International Journal of Pressure Vessels and Piping},
  volume = {162},
  pages = {30--39},
  publisher = {{Elsevier}},
  isbn = {0308-0161}
}

@article{danielModel2020,
  title = {Model Order Reduction Assisted by Deep Neural Networks ({{ROM}}-Net)},
  author = {Daniel, Thomas and Casenave, Fabien and Akkari, Nissrine and Ryckelynck, David},
  date = {2020-12},
  journaltitle = {Advanced Modeling and Simulation in Engineering Sciences},
  shortjournal = {Adv. Model. and Simul. in Eng. Sci.},
  volume = {7},
  pages = {16},
  issn = {2213-7467},
  doi = {10.1186/s40323-020-00153-6},
  url = {https://amses-journal.springeropen.com/articles/10.1186/s40323-020-00153-6},
  urldate = {2020-09-02},
  abstract = {In this paper, we propose a general framework for projection-based model order reduction assisted by deep neural networks. The proposed methodology, called ROM-net, consists in using deep learning techniques to adapt the reduced-order model to a stochastic input tensor whose nonparametrized variabilities strongly influence the quantities of interest for a given physics problem. In particular, we introduce the concept of dictionary-based ROM-nets, where deep neural networks recommend a suitable local reduced-order model from a dictionary. The dictionary of local reduced-order models is constructed from a clustering of simplified simulations enabling the identification of the subspaces in which the solutions evolve for different input tensors. The training examples are represented by points on a Grassmann manifold, on which distances are computed for clustering. This methodology is applied to an anisothermal elastoplastic problem in structural mechanics, where the damage field depends on a random temperature field. When using deep neural networks, the selection of the best reduced-order model for a given thermal loading is 60 times faster than when following the clustering procedure used in the training phase.},
  file = {/Users/hyan46/Zotero/storage/MBMLRPG8/Daniel et al. - 2020 - Model order reduction assisted by deep neural netw.pdf},
  langid = {english},
  number = {1}
}

@online{datamanExplain2020,
  title = {Explain {{Your Model}} with the {{SHAP Values}}},
  author = {Dataman, Dr},
  date = {2020-05-12T02:19:58},
  url = {https://towardsdatascience.com/explain-your-model-with-the-shap-values-bc36aac4de3d},
  urldate = {2020-05-23},
  abstract = {Use the SHAP Values to Explain Any Complex ML Model},
  file = {/Users/hyan46/Dropbox (ASU)/ZoteroData/Dataman_2020_Explain Your Model with the SHAP Values.pdf;/Users/hyan46/Zotero/storage/UJT9L987/explain-your-model-with-the-shap-values-bc36aac4de3d.html},
  langid = {english},
  organization = {{Medium}}
}

@article{dawoudUsing2008,
  title = {Using Inverse Electrocardiography to Image Myocardial Infarction—Reflecting on the 2007 {{PhysioNet}}/{{Computers}} in {{Cardiology Challenge}}},
  author = {Dawoud, Fady and Wagner, Galen S. and Moody, George and Horáček, B. Milan},
  date = {2008-11},
  journaltitle = {Journal of Electrocardiology},
  shortjournal = {Journal of Electrocardiology},
  volume = {41},
  pages = {630--635},
  issn = {00220736},
  doi = {10.1016/j.jelectrocard.2008.07.022},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0022073608002720},
  urldate = {2020-09-09},
  file = {/Users/hyan46/Dropbox (ASU)/ZoteroData/Dawoud et al_2008_Using inverse electrocardiography to image myocardial infarction—reflecting on.pdf},
  keywords = {_tablet},
  langid = {english},
  number = {6}
}

@online{Deep,
  title = {Deep Learning | {{Nature}}},
  url = {https://www.nature.com/articles/nature14539},
  urldate = {2020-07-03}
}

@article{desouzaborgesferreiraAutomated2020,
  title = {Automated {{Geometric Shape Deviation Modeling}} for {{Additive Manufacturing Systems}} via {{Bayesian Neural Networks}}},
  author = {de Souza Borges Ferreira, Raquel and Sabbaghi, Arman and Huang, Qiang},
  date = {2020-04},
  journaltitle = {IEEE Transactions on Automation Science and Engineering},
  shortjournal = {IEEE Trans. Automat. Sci. Eng.},
  volume = {17},
  pages = {584--598},
  issn = {1545-5955, 1558-3783},
  doi = {10.1109/TASE.2019.2936821},
  url = {https://ieeexplore.ieee.org/document/8851391/},
  urldate = {2020-07-04},
  abstract = {A significant challenge in comprehensive geometric accuracy control of an additive manufacturing (AM) system is the specification of shape deviation models for different computer-aided design products manufactured on its constituent AM processes. Current deviation modeling techniques do not satisfactorily address this challenge because they can require substantial user inputs and efforts to implement. We present a new model building methodology based on a class of Bayesian neural networks (NNs) that directly addresses this challenge with much less effort. Our method enables automated deviation modeling of different shapes and AM processes, and yields models with higher predictive accuracies compared to existing modeling methods on the same samples of manufactured products. A fundamental innovation in our methodology is the design of new and connectable NN structures that facilitate the leveraging of previously specified deviation models for adaptive model building of new shapes and AM processes. The power and broad scope of our method are demonstrated with several case studies on both in-plane and out-of-plane deviations for a wide variety of shapes manufactured under different stereolithography processes. Our Bayesian methodology for automated and comprehensive deviation modeling can ultimately help to advance flexible, efficient, and high-quality manufacturing in an AM system.},
  file = {/Users/hyan46/Dropbox (ASU)/ZoteroData/de Souza Borges Ferreira et al_2020_Automated Geometric Shape Deviation Modeling for Additive Manufacturing Systems.pdf},
  keywords = {Application: Additive Manufacturing,Application: Manufacturing,Method: Deep Learning,People: Qiang Huang},
  langid = {english},
  number = {2},
  options = {useprefix=true}
}

@online{devlinBERT2019,
  title = {{{BERT}}: {{Pre}}-Training of {{Deep Bidirectional Transformers}} for {{Language Understanding}}},
  shorttitle = {{{BERT}}},
  author = {Devlin, Jacob and Chang, Ming-Wei and Lee, Kenton and Toutanova, Kristina},
  date = {2019-05-24},
  url = {http://arxiv.org/abs/1810.04805},
  urldate = {2021-02-23},
  abstract = {We introduce a new language representation model called BERT, which stands for Bidirectional Encoder Representations from Transformers. Unlike recent language representation models (Peters et al., 2018a; Radford et al., 2018), BERT is designed to pretrain deep bidirectional representations from unlabeled text by jointly conditioning on both left and right context in all layers. As a result, the pre-trained BERT model can be finetuned with just one additional output layer to create state-of-the-art models for a wide range of tasks, such as question answering and language inference, without substantial taskspecific architecture modifications.},
  archiveprefix = {arXiv},
  eprint = {1810.04805},
  eprinttype = {arxiv},
  file = {/Users/hyan46/Dropbox (ASU)/ZoteroData/Devlin et al_2019_BERT.pdf},
  keywords = {Computer Science - Computation and Language},
  langid = {english},
  primaryclass = {cs}
}

@online{dhamalaHighdimensional2018,
  title = {High-Dimensional {{Bayesian Optimization}} of {{Personalized Cardiac Model Parameters}} via an {{Embedded Generative Model}}},
  author = {Dhamala, Jwala and Ghimire, Sandesh and Sapp, John L. and Horácek, B. Milan and Wang, Linwei},
  date = {2018},
  volume = {11071},
  pages = {499--507},
  doi = {10.1007/978-3-030-00934-2_56},
  url = {http://arxiv.org/abs/2005.07804},
  urldate = {2020-05-24},
  abstract = {The estimation of patient-specific tissue properties in the form of model parameters is important for personalized physiological models. However, these tissue properties are spatially varying across the underlying anatomical model, presenting a significance challenge of high-dimensional (HD) optimization at the presence of limited measurement data. A common solution to reduce the dimension of the parameter space is to explicitly partition the anatomical mesh, either into a fixed small number of segments or a multi-scale hierarchy. This anatomy-based reduction of parameter space presents a fundamental bottleneck to parameter estimation, resulting in solutions that are either too low in resolution to reflect tissue heterogeneity, or too high in dimension to be reliably estimated within feasible computation. In this paper, we present a novel concept that embeds a generative variational auto-encoder (VAE) into the objective function of Bayesian optimization, providing an implicit low-dimensional (LD) search space that represents the generative code of the HD spatially-varying tissue properties. In addition, the VAE-encoded knowledge about the generative code is further used to guide the exploration of the search space. The presented method is applied to estimating tissue excitability in a cardiac electrophysiological model. Synthetic and real-data experiments demonstrate its ability to improve the accuracy of parameter estimation with more than 10x gain in efficiency.},
  archiveprefix = {arXiv},
  eprint = {2005.07804},
  eprinttype = {arxiv},
  file = {/Users/hyan46/Dropbox (ASU)/ZoteroData/Dhamala et al_2018_High-dimensional Bayesian Optimization of Personalized Cardiac Model Parameters.pdf},
  keywords = {Bayesian Optimization,Cardiac,Computer Science - Machine Learning,Mathematics - Optimization and Control,Statistics - Machine Learning},
  primaryclass = {cs, math, stat}
}

@article{dhamalaSpatially2017,
  title = {Spatially {{Adaptive Multi}}-{{Scale Optimization}} for {{Local Parameter Estimation}} in {{Cardiac Electrophysiology}}},
  author = {Dhamala, Jwala and Arevalo, Hermenegild J. and Sapp, John and Horacek, Milan and Wu, Katherine C. and Trayanova, Natalia A. and Wang, Linwei},
  date = {2017-09},
  journaltitle = {IEEE Transactions on Medical Imaging},
  volume = {36},
  pages = {1966--1978},
  issn = {1558-254X},
  doi = {10.1109/TMI.2017.2697820},
  abstract = {To obtain a patient-specific cardiac electro-physiological (EP) model, it is important to estimate the 3-D distributed tissue properties of the myocardium. Ideally, the tissue property should be estimated at the resolution of the cardiac mesh. However, such high-dimensional estimation faces major challenges in identifiability and computation. Most existing works reduce this dimension by partitioning the cardiac mesh into a pre-defined set of segments. The resulting low-resolution solutions have a limited ability to represent the underlying heterogeneous tissue properties of varying sizes, locations, and distributions. In this paper, we present a novel framework that, going beyond a uniform low-resolution approach, is able to obtain a higher resolution estimation of tissue properties represented by spatially non-uniform resolution. This is achieved by two central elements: 1) a multi-scale coarse-to-fine optimization that facilitates higher resolution optimization using the lower resolution solution and 2) a spatially adaptive decision criterion that retains lower resolution in homogeneous tissue regions and allows higher resolution in heterogeneous tissue regions. The presented framework is evaluated in estimating the local tissue excitability properties of a cardiac EP model on both synthetic and real data experiments. Its performance is compared with optimization using pre-defined segments. Results demonstrate the feasibility of the presented framework to estimate local parameters and to reveal heterogeneous tissue properties at a higher resolution without using a high number of unknowns.},
  eventtitle = {{{IEEE Transactions}} on {{Medical Imaging}}},
  file = {/Users/hyan46/Dropbox (ASU)/ZoteroData/Dhamala et al_2017_Spatially Adaptive Multi-Scale Optimization for Local Parameter Estimation in.pdf},
  keywords = {Method: Bayesian},
  number = {9}
}

@book{diggleStatistical2013,
  title = {Statistical {{Analysis}} of {{Spatial}} and {{Spatio}}-{{Temporal Point Patterns}}, {{Third Edition}}},
  author = {Diggle, Peter J.},
  date = {2013-07-23},
  publisher = {{CRC Press}},
  abstract = {Written by a prominent statistician and author, the first edition of this bestseller broke new ground in the then emerging subject of spatial statistics with its coverage of spatial point patterns. Retaining all the material from the second edition and adding substantial new material, Statistical Analysis of Spatial and Spatio-Temporal Point Patterns, Third Edition presents models and statistical methods for analyzing spatially referenced point process data.  Reflected in the title, this third edition now covers spatio-temporal point patterns. It explores the methodological developments from the last decade along with diverse applications that use spatio-temporally indexed data. Practical examples illustrate how the methods are applied to analyze spatial data in the life sciences.  This edition also incorporates the use of R through several packages dedicated to the analysis of spatial point process data. Sample R code and data sets are available on the author’s website.},
  eprint = {XR8bAAAAQBAJ},
  eprinttype = {googlebooks},
  isbn = {978-1-4665-6023-9},
  keywords = {Mathematics / Probability & Statistics / General,Science / Earth Sciences / Geology,Technology & Engineering / Remote Sensing & Geographic Information Systems},
  langid = {english},
  pagetotal = {302}
}

@article{dingDistributed2006,
  title = {Distributed {{Sensing}} for {{Quality}} and {{Productivity Improvements}}},
  author = {Ding, Y. and Elsayed, E.A. and Kumara, S. and Lu, J.-C. and Niu, F. and Shi, J.},
  date = {2006-10},
  journaltitle = {IEEE Transactions on Automation Science and Engineering},
  shortjournal = {IEEE Trans. Automat. Sci. Eng.},
  volume = {3},
  pages = {344--359},
  issn = {1545-5955},
  doi = {10.1109/TASE.2006.876610},
  url = {http://ieeexplore.ieee.org/document/1707953/},
  urldate = {2020-08-12},
  abstract = {Distributed sensing, a system-wide deployment of sensing devices, has resulted in both temporally and spatially dense data-rich environments. This new technology provides unprecedented opportunities for quality and productivity improvement. This paper discusses the state-of-the-art practice, research challenges, and future directions related to distributed sensing. The discussion includes the optimal design of distributed sensor systems, information criteria, and processing for distributed sensing and optimal decision making in distributed sensing. The discussion also provides applications based on the authors’ research experiences.},
  file = {/Users/hyan46/Dropbox (ASU)/ZoteroData/Ding et al_2006_Distributed Sensing for Quality and Productivity Improvements.pdf},
  langid = {english},
  number = {4}
}

@article{dongModeling2020,
  title = {Modeling and {{Change Detection}} for {{Count}}-{{Weighted Multilayer Networks}}},
  author = {Dong, Hang and Chen, Nan and Wang, Kaibo},
  date = {2020-04-02},
  journaltitle = {Technometrics},
  shortjournal = {Technometrics},
  volume = {62},
  pages = {184--195},
  issn = {0040-1706, 1537-2723},
  doi = {10.1080/00401706.2019.1625812},
  url = {https://www.tandfonline.com/doi/full/10.1080/00401706.2019.1625812},
  urldate = {2020-07-04},
  abstract = {In a typical network with a set of individuals, it is common to have multiple types of interactions between two individuals. In practice, these interactions are usually sparse and correlated, which is not sufficiently accounted for in the literature. This article proposes a multilayer weighted stochastic block model (MZIPSBM) based on a multivariate zero-inflated Poisson (MZIP) distribution to characterize the sparse and correlated multilayer interactions of individuals. A variational-EM algorithm is developed to estimate the parameters in this model. We further propose a monitoring statistic based on the score test of MZIPSBM model parameters for change detection in multilayer networks. The proposed model and monitoring scheme are validated using extensive simulation studies and the case study from Enron E-mail network.},
  file = {/Users/hyan46/Dropbox (ASU)/ZoteroData/Dong et al_2020_Modeling and Change Detection for Count-Weighted Multilayer Networks.pdf},
  keywords = {Data: Network,People: Kaibo Wang,Problem: Process Monitoring},
  langid = {english},
  number = {2}
}

@article{drinkwaterUltrasonic2006,
  title = {Ultrasonic Arrays for Non-Destructive Evaluation: {{A}} Review},
  shorttitle = {Ultrasonic Arrays for Non-Destructive Evaluation},
  author = {Drinkwater, Bruce W. and Wilcox, Paul D.},
  date = {2006-10},
  journaltitle = {NDT \& E International},
  shortjournal = {NDT \& E International},
  volume = {39},
  pages = {525--541},
  issn = {09638695},
  doi = {10.1016/j.ndteint.2006.03.006},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0963869506000272},
  urldate = {2020-07-15},
  abstract = {An ultrasonic array is a single transducer that contains a number of individually connected elements. Recent years have seen a dramatic increase in the use of ultrasonic arrays for non-destructive evaluation. Arrays offer great potential to increase inspection quality and reduce inspection time. Their main advantages are their increased flexibility over traditional single element transducer methods, meaning that one array can be used to perform a number of different inspections, and their ability to produce immediate images of the test structure. These advantages have led to the rapid uptake of arrays by the engineering industry. These industrial applications are underpinned by a wide range of published research which describes new piezoelectric materials, array geometries, modelling methods and inspection modalities. The aim of this paper is to bring together the most relevant published work on arrays for non-destructive evaluation applications, comment on the state-of the art and discuss future directions. There is also a significant body of published literature referring to use of arrays in the medical and sonar fields and the most relevant papers from these related areas are also reviewed. However, although there is much common ground, the use of arrays in non-destructive evaluation offers some distinctly different challenges to these other disciplines.},
  file = {/Users/hyan46/Dropbox (ASU)/ZoteroData/Drinkwater_Wilcox_2006_Ultrasonic arrays for non-destructive evaluation.pdf},
  langid = {english},
  number = {7}
}

@article{duanmuScaleup2018,
  title = {Scale-up Modeling for Manufacturing Nanoparticles Using Microfluidic {{T}}-Junction},
  author = {Duanmu, Yanqing and Riche, Carson T. and Gupta, Malancha and Malmstadt, Noah and Huang, Qiang},
  date = {2018-10-03},
  journaltitle = {IISE Transactions},
  shortjournal = {IISE Transactions},
  volume = {50},
  pages = {892--899},
  issn = {2472-5854, 2472-5862},
  doi = {10.1080/24725854.2018.1443529},
  url = {https://www.tandfonline.com/doi/full/10.1080/24725854.2018.1443529},
  urldate = {2020-07-04},
  abstract = {Nanoparticles have great potential to revolutionize industry and improve our lives in various fields such as energy, security, medicine, food, and environmental science. Droplet-based microfluidic reactors serve as an important tool to facilitate monodisperse nanoparticles with a high yield. Depending on process settings, droplet formation in a typical microfluidic T-junction is explained by different mechanisms, squeezing, dripping, or squeezing-to-dripping. Therefore, the manufacturing process can potentially operate under multiple physical domains due to uncertainties. Although mechanistic models have been developed for individual domains, a modeling approach for the scale-up manufacturing of droplet formation across multiple domains does not exist. Establishing an integrated and scalable droplet formation model, which is vital for scaling up microfluidic reactors for large-scale production, faces two critical challenges: the high dimensionality of the modeling space; and ambiguity among the boundaries of physical domains. This work establishes a novel and generic formulation for the scale-up of multiple-domain manufacturing processes and provides a scalable modeling approach for the quality control of products, which enables and supports the scale-up of manufacturing processes that can potentially operate under multiple physical domains due to uncertainties.},
  file = {/Users/hyan46/Dropbox (ASU)/ZoteroData/Duanmu et al_2018_Scale-up modeling for manufacturing nanoparticles using microfluidic T-junction.pdf},
  keywords = {Application: Manufacturing,Application: Nano,People: Qiang Huang},
  langid = {english},
  number = {10}
}

@article{duOptimal2019,
  title = {Optimal {{Placement}} of {{Actuators Via Sparse Learning}} for {{Composite Fuselage Shape Control}}},
  author = {Du, Juan and Yue, Xiaowei and Hunt, Jeffrey H. and Shi, Jianjun},
  date = {2019-10-01},
  journaltitle = {Journal of Manufacturing Science and Engineering},
  volume = {141},
  pages = {101004},
  issn = {1087-1357, 1528-8935},
  doi = {10.1115/1.4044249},
  url = {https://asmedigitalcollection.asme.org/manufacturingscience/article/doi/10.1115/1.4044249/955917/Optimal-Placement-of-Actuators-Via-Sparse-Learning},
  urldate = {2020-07-21},
  abstract = {Shape control is a critical task in the composite fuselage assembly process due to the dimensional variabilities of incoming fuselages. To realize fuselage shape adjustment, actuators are used to pull or push several points on a fuselage. Given a fixed number of actuators, the locations of actuators on a fuselage will impact on the effectiveness of shape control. Thus, it is important to determine the optimal placement of actuators in the fuselage shape control problem. In current practice, the actuators are placed with equal distance along the edge of a fuselage without considering its incoming dimensional shape. Such practice has two limitations: (1) it is non-optimal and (2) larger actuator forces may be applied for some locations than needed. This paper proposes an optimal actuator placement methodology for efficient composite fuselage shape control by developing a sparse learning model and corresponding parameter estimation algorithm. The case study shows that our proposed method achieves the optimal actuator placement for shape adjustments of the composite fuselage.},
  file = {/Users/hyan46/Dropbox (ASU)/ZoteroData/Du et al_2019_Optimal Placement of Actuators Via Sparse Learning for Composite Fuselage Shape.pdf},
  keywords = {Method: Active Learning},
  langid = {english},
  number = {10}
}

@article{duStatistical2016,
  title = {Statistical {{Metamodeling}} and {{Sequential Design}} of {{Computer Experiments}} to {{Model Glyco}}-{{Altered Gating}} of {{Sodium Channels}} in {{Cardiac Myocytes}}},
  author = {Du, Dongping and Yang, Hui and Ednie, Andrew R. and Bennett, Eric S.},
  date = {2016-09},
  journaltitle = {IEEE Journal of Biomedical and Health Informatics},
  volume = {20},
  pages = {1439--1452},
  issn = {2168-2208},
  doi = {10.1109/JBHI.2015.2458791},
  abstract = {Glycan structures account for up to 35\% of the mass of cardiac sodium (Nav) channels. To question whether and how reduced sialylation affects Nav activity and cardiac electrical signaling, we conducted a series of in vitro experiments on ventricular apex myocytes under two different glycosylation conditions, reduced protein sialylation (ST3Gal4-/-) and full glycosylation (control). Although aberrant electrical signaling is observed in reduced sialylation, realizing a better understanding of mechanistic details of pathological variations in INa and AP is difficult without performing in silico studies. However, computer model of Nav channels and cardiac myocytes involves greater levels of complexity, e.g., high-dimensional parameter space, nonlinear and nonconvex equations. Traditional linear and nonlinear optimization methods have encountered many difficulties for model calibration. This paper presents a new statistical metamodeling approach for efficient computer experiments and optimization of Nav models. First, we utilize a fractional factorial design to identify control variables from the large set of model parameters, thereby reducing the dimensionality of parametric space. Further, we develop the Gaussian process model as a surrogate of expensive and time-consuming computer models and then identify the next best design point that yields the maximal probability of improvement. This process iterates until convergence, and the performance is evaluated and validated with real-world experimental data. Experimental results show the proposed algorithm achieves superior performance in modeling the kinetics of Nav channels under a variety of glycosylation conditions. As a result, in silico models provide a better understanding of glyco-altered mechanistic details in state transitions and distributions of Nav channels. Notably, ST3Gal4-/- myocytes are shown to have higher probabilities accumulated in intermediate inactivation during the repolarization and yield a shorter refractory period than WTs. The proposed statistical design of computer experiments is generally extensible to many other disciplines that involve large-scale and computationally expensive models.},
  eventtitle = {{{IEEE Journal}} of {{Biomedical}} and {{Health Informatics}}},
  file = {/Users/hyan46/Dropbox (ASU)/ZoteroData/Du et al_2016_Statistical Metamodeling and Sequential Design of Computer Experiments to Model.pdf},
  keywords = {Algorithm design and analysis,Animals,bioelectric phenomena,biomembrane transport,cardiac electrical signaling,cardiac myocytes,Cardiac myocytes,cardiology,cellular biophysics,Computational Biology,Computational modeling,Computers,Data models,design of computer experiments,design of experiments,fractional factorial design,Gaussian process,Gaussian process model,Gaussian processes,Glycosylation,glycosylation conditions,Humans,Markov Chains,Mathematical model,metamodel,Metamodeling,Models; Theoretical,Myocytes; Cardiac,Predictive models,sequential design of computer experiments,simulation model,sodium,sodium channel,Sodium Channels,space filling design,statistical analysis,statistical metamodel,statistical metamodeling,ventricular apex myocytes},
  number = {5}
}

@article{el-alamilaaroussiOptimal2018,
  title = {An Optimal Control Problem for a Spatiotemporal {{SIR}} Model},
  author = {El-Alami Laaroussi, Adil and Rachik, Mostafa and Elhia, Mohamed},
  date = {2018-03},
  journaltitle = {International Journal of Dynamics and Control},
  shortjournal = {Int. J. Dynam. Control},
  volume = {6},
  pages = {384--397},
  issn = {2195-268X, 2195-2698},
  doi = {10.1007/s40435-016-0283-5},
  url = {http://link.springer.com/10.1007/s40435-016-0283-5},
  urldate = {2020-08-09},
  abstract = {In this paper, an SIR spatiotemporal epidemic model is formulated as a system of parabolic partial differential equations with no-flux boundary conditions. Immunity is forced through vaccine distribution considered a control variable. Our principal objective is to characterize an optimal control that minimizes the number of infected individuals and the costs associated with vaccination over a finite space and time domain. The existence of solutions to the state system and the existence of an optimal control is proved. An optimal control characterization in terms of state and adjoint functions is provided. Furthermore, a second condition of optimality is given. The optimality systems are solved based on an iterative discrete scheme that converges following an appropriate test similar the one related to the forward–backward sweep method. Numerical results are provided to illustrate the effectiveness of our approach for several scenarios.},
  file = {/Users/hyan46/Dropbox (ASU)/ZoteroData/El-Alami Laaroussi et al_2018_An optimal control problem for a spatiotemporal SIR model.pdf},
  langid = {english},
  number = {1}
}

@inproceedings{entezariAll2020,
  title = {All {{You Need Is Low}} ({{Rank}}): {{Defending Against Adversarial Attacks}} on {{Graphs}}},
  shorttitle = {All {{You Need Is Low}} ({{Rank}})},
  booktitle = {Proceedings of the 13th {{International Conference}} on {{Web Search}} and {{Data Mining}}},
  author = {Entezari, Negin and Al-Sayouri, Saba A. and Darvishzadeh, Amirali and Papalexakis, Evangelos E.},
  date = {2020-01-20},
  pages = {169--177},
  publisher = {{ACM}},
  location = {{Houston TX USA}},
  doi = {10.1145/3336191.3371789},
  url = {https://dl.acm.org/doi/10.1145/3336191.3371789},
  urldate = {2020-11-18},
  abstract = {Recent studies have demonstrated that machine learning approaches like deep learning methods are easily fooled by adversarial attacks. Recently, a highly-influential study examined the impact of adversarial attacks on graph data and demonstrated that graph embedding techniques are also vulnerable to adversarial attacks. Fake users on social media and fake product reviews are examples of perturbations in graph data that are realistic counterparts of the adversarial models proposed. Graphs are widely used in a variety of domains and it is highly important to develop graph analysis techniques that are robust to adversarial attacks. One of the recent studies on generating adversarial attacks for graph data is Nettack. The Nettack model has shown to be very successful in deceiving the Graph Convolutional Network (GCN) model. Nettack is also transferable to other node classification approaches e.g. node embeddings. In this paper, we explore the properties of Nettack perturbations, in search for effective defenses against them. Our first finding is that Nettack demonstrates a very specific behavior in the spectrum of the graph: only high-rank (low-valued) singular components of the graph are affected. Following that insight, we show that a low-rank approximation of the graph, that uses only the top singular components for its reconstruction, can greatly reduce the effects of Nettack and boost the performance of GCN when facing adversarial attacks. Indicatively, on the CiteSeer dataset, our proposed defense mechanism is able to reduce the success rate of Nettack from 98\% to 36\%. Furthermore, we show that tensor-based node embeddings, which by default project the graph into a lowrank subspace, are robust against Nettack perturbations. Lastly, we propose LowBlow, a low-rank adversarial attack which is able to affect the classification performance of both GCN and tensorbased node embeddings and we show that the low-rank attack is noticeable and making it unnoticeable results in a high-rank attack.},
  eventtitle = {{{WSDM}} '20: {{The Thirteenth ACM International Conference}} on {{Web Search}} and {{Data Mining}}},
  file = {/Users/hyan46/Dropbox (ASU)/ZoteroData/Entezari et al_2020_All You Need Is Low (Rank).pdf},
  isbn = {978-1-4503-6822-3},
  langid = {english}
}

@online{evciRigging2020,
  title = {Rigging the {{Lottery}}: {{Making All Tickets Winners}}},
  shorttitle = {Rigging the {{Lottery}}},
  author = {Evci, Utku and Gale, Trevor and Menick, Jacob and Castro, Pablo Samuel and Elsen, Erich},
  date = {2020-07-25},
  url = {http://arxiv.org/abs/1911.11134},
  urldate = {2021-02-25},
  abstract = {Many applications require sparse neural networks due to space or inference time restrictions. There is a large body of work on training dense networks to yield sparse networks for inference, but this limits the size of the largest trainable sparse model to that of the largest trainable dense model. In this paper we introduce a method to train sparse neural networks with a fixed parameter count and a fixed computational cost throughout training, without sacrificing accuracy relative to existing dense-to-sparse training methods. Our method updates the topology of the sparse network during training by using parameter magnitudes and infrequent gradient calculations. We show that this approach requires fewer floating-point operations (FLOPs) to achieve a given level of accuracy compared to prior techniques. We demonstrate state-of-the-art sparse training results on a variety of networks and datasets, including ResNet-50, MobileNets on Imagenet-2012, and RNNs on WikiText-103. Finally, we provide some insights into why allowing the topology to change during the optimization can overcome local minima encountered when the topology remains static. Code used in our work can be found in github.com/google-research/rigl.},
  archiveprefix = {arXiv},
  eprint = {1911.11134},
  eprinttype = {arxiv},
  file = {/Users/hyan46/Zotero/storage/6VC5KMLH/Evci et al. - 2020 - Rigging the Lottery Making All Tickets Winners.pdf;/Users/hyan46/Zotero/storage/3D2NBF3V/1911.html},
  keywords = {Computer Science - Computer Vision and Pattern Recognition,Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryclass = {cs, stat}
}

@online{Extended,
  title = {Extended {{SIR Prediction}} of the {{Epidemics Trend}} of {{COVID}}-19 in {{Italy}} and {{Compared With Hunan}}, {{China}}},
  url = {https://www.frontiersin.org/articles/10.3389/fmed.2020.00169/full?utm_source=fweb&utm_medium=nblog&utm_campaign=ba-sci-fmed-covid-extended-sir},
  urldate = {2020-08-09},
  file = {/Users/hyan46/Zotero/storage/QLR2U9H6/full.html}
}

@article{fangImageBased2019,
  title = {Image-{{Based Prognostics Using Penalized Tensor Regression}}},
  author = {Fang, Xiaolei and Paynabar, Kamran and Gebraeel, Nagi},
  date = {2019-07-03},
  journaltitle = {Technometrics},
  shortjournal = {Technometrics},
  volume = {61},
  pages = {369--384},
  issn = {0040-1706, 1537-2723},
  doi = {10.1080/00401706.2018.1527727},
  url = {https://www.tandfonline.com/doi/full/10.1080/00401706.2018.1527727},
  urldate = {2020-07-07},
  abstract = {This article proposes a new methodology to predict and update the residual useful lifetime of a system using a sequence of degradation images. The methodology integrates tensor linear algebra with traditional location-scale regression widely used in reliability and prognostics. To address the high dimensionality challenge, the degradation image streams are first projected to a low-dimensional tensor subspace that is able to preserve their information. Next, the projected image tensors are regressed against time-tofailure via penalized location-scale tensor regression. The coefficient tensor is then decomposed using CANDECOMP/PARAFAC (CP) and Tucker decompositions, which enables parameter estimation in a highdimensional setting. Two optimization algorithms with a global convergence property are developed for model estimation. The effectiveness of our models is validated using two simulated datasets and infrared degradation image streams from a rotating machinery.},
  file = {/Users/hyan46/Dropbox (ASU)/ZoteroData/Fang et al_2019_Image-Based Prognostics Using Penalized Tensor Regression.pdf},
  keywords = {Method: Tensor},
  langid = {english},
  number = {3}
}

@article{fangMultiSensor2020,
  title = {Multi-{{Sensor Prognostics Modeling}} for {{Applications}} with {{Highly Incomplete Signals}}},
  author = {Fang, Xiaolei and Yan, Hao and Gebraeel, Nagi and Paynabar, Kamran},
  date = {2020-07-01},
  journaltitle = {IISE Transactions},
  shortjournal = {IISE Transactions},
  pages = {1--30},
  issn = {2472-5854, 2472-5862},
  doi = {10.1080/24725854.2020.1789779},
  url = {https://www.tandfonline.com/doi/full/10.1080/24725854.2020.1789779},
  urldate = {2020-07-08},
  abstract = {Multi-stream degradation signals have been widely used to predict the residual useful lifetime of partially degraded systems. To achieve this goal, most of the existing prognostics models assume that degradation signals are complete, i.e., they are observed continuously and frequently at regular time grids. In reality, however, degradation signals are often (highly) incomplete, i.e., containing missing and corrupt observations. Such signal incompleteness poses a significant challenge for the parameter estimation of prognostics models. To address this challenge, this article proposes a prognostics methodology that is capable of using highly incomplete multi-stream degradation signals to predict the residual useful lifetime of partially degraded systems. The method first employs multivariate functional principal components analysis to fuse multi-stream signals. Next, the fused features are regressed against time-to-failure using (log)-location-scale regression. To estimate the fused features using incomplete multi-stream degradation signals, we develop two computationally efficient algorithms: subspace detection and signal recovery. The performance of the proposed prognostics methodology is evaluated using simulated datasets and a degradation dataset of aircraft turbofan engines from the NASA repository.},
  file = {/Users/hyan46/Dropbox (ASU)/ZoteroData/Fang et al_2020_Multi-Sensor Prognostics Modeling for Applications with Highly Incomplete2.pdf},
  keywords = {Data: Sigmal,Method: Matrix Decomposition,Problem: Prognostics},
  langid = {english}
}

@article{fangMultistream2017,
  title = {Multistream Sensor Fusion-Based Prognostics Model for Systems with Single Failure Modes},
  author = {Fang, Xiaolei and Paynabar, Kamran and Gebraeel, Nagi},
  date = {2017-03},
  journaltitle = {Reliability Engineering \& System Safety},
  shortjournal = {Reliability Engineering \& System Safety},
  volume = {159},
  pages = {322--331},
  issn = {09518320},
  doi = {10.1016/j.ress.2016.11.008},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0951832016308249},
  urldate = {2020-07-07},
  abstract = {Advances in sensor technology have facilitated the capability of monitoring the degradation of complex engineering systems through the analysis of multistream degradation signals. However, the varying levels of correlation with physical degradation process for different sensors, high-dimensionality of the degradation signals and cross-correlation among different signal streams pose significant challenges in monitoring and prognostics of such systems. To address the foregoing challenges, we develop a three-step multi-sensor prognostic methodology that utilizes multistream signals to predict residual useful lifetimes of partially degraded systems. We first identify the informative sensors via the penalized (log)-location-scale regression. Then, we fuse the degradation signals of the informative sensors using multivariate functional principal component analysis, which is capable of modeling the cross-correlation of signal streams. Finally, the third step focuses on utilizing the fused signal features for prognostics via adaptive penalized (log)-location-scale regression. We validate our multi-sensor prognostic methodology using simulation study as well as a case study of aircraft turbofan engines available from NASA repository.},
  file = {/Users/hyan46/Dropbox (ASU)/ZoteroData/Fang et al_2017_Multistream sensor fusion-based prognostics model for systems with single.pdf},
  langid = {english}
}

@article{fangScalable2017,
  title = {Scalable Prognostic Models for Large-Scale Condition Monitoring Applications},
  author = {Fang, Xiaolei and Gebraeel, Nagi Z. and Paynabar, Kamran},
  date = {2017-07-03},
  journaltitle = {IISE Transactions},
  shortjournal = {IISE Transactions},
  volume = {49},
  pages = {698--710},
  issn = {2472-5854, 2472-5862},
  doi = {10.1080/24725854.2016.1264646},
  url = {https://www.tandfonline.com/doi/full/10.1080/24725854.2016.1264646},
  urldate = {2020-07-07},
  abstract = {High-value engineering assets are often embedded with numerous sensing technologies that monitor and track their performance. Capturing physical and performance degradation entails the use of various types of sensors that generate massive amounts of multivariate data. Building a prognostic model for such largescale datasets, however, often presents two key challenges: how to effectively fuse the degradation signals from a large number of sensors and how to make the model scalable to the large data size. To address the two challenges, this article presents a scalable semi-parametric statistical framework specifically designed for synthesizing and combining multistream sensor signals using two signal fusion algorithms developed from functional principal component analysis. Using the algorithms, we identify fused signal features and predict (in near real-time) the remaining lifetime of partially degraded systems using an adaptive functional (log)-location-scale regression modeling framework. We validate the proposed multi-sensor prognostic methodology using numerical and data-driven case studies.},
  file = {/Users/hyan46/Zotero/storage/U3MRT87N/Fang et al. - 2017 - Scalable prognostic models for large-scale conditi.pdf},
  langid = {english},
  number = {7}
}

@article{fathiaghdamModeling2017,
  title = {Modeling {{Interaction}} in {{Nanowire Growth Process Toward Improved Yield}}},
  author = {Fathi Aghdam, Faranak and Liao, Haitao and Huang, Qiang},
  date = {2017-04},
  journaltitle = {IEEE Transactions on Automation Science and Engineering},
  shortjournal = {IEEE Trans. Automat. Sci. Eng.},
  volume = {14},
  pages = {1139--1149},
  issn = {1545-5955, 1558-3783},
  doi = {10.1109/TASE.2015.2499210},
  url = {http://ieeexplore.ieee.org/document/7342993/},
  urldate = {2020-07-04},
  abstract = {Research on nanowire growth with patterned arrays of catalyst has shown that wire-to-wire spacing is an important factor affecting nanowire quality. To improve the process yield and the length uniformity of fabricated nanowires, it is important to reduce the resource competition between nanowires during the growth process. In this paper, we propose a physical-statistical nanowire-interaction model considering the shadowing effect and shared substrate diffusion area to determine the optimal pitch that would ensure the minimum competition between nanowires. A sigmoid function is used in the model, and the method of least squares is used to estimate the model parameters. The estimated model is then used to determine the optimal spatial arrangement of catalyst arrays. This work is an early attempt at the physical-statistical modeling of selective nanowire growth for the improvement of process yield.},
  file = {/Users/hyan46/Dropbox (ASU)/ZoteroData/Fathi Aghdam et al_2017_Modeling Interaction in Nanowire Growth Process Toward Improved Yield.pdf},
  keywords = {Application: Manufacturing,Application: Nano,Method: Physics,People: Qiang Huang},
  langid = {english},
  number = {2}
}

@article{fengDynamic2019,
  title = {Dynamic {{Inspection}} of {{Latent Variables}} in {{State}}-{{Space Systems}}},
  author = {Feng, Tianshu and Qian, Xiaoning and Liu, Kaibo and Huang, Shuai},
  date = {2019-07},
  journaltitle = {IEEE Transactions on Automation Science and Engineering},
  shortjournal = {IEEE Trans. Automat. Sci. Eng.},
  volume = {16},
  pages = {1232--1243},
  issn = {1545-5955, 1558-3783},
  doi = {10.1109/TASE.2018.2884149},
  url = {https://ieeexplore.ieee.org/document/8603831/},
  urldate = {2020-07-04},
  abstract = {The state-space models (SSMs) are widely used in a variety of areas where a set of observable variables are used to track some latent variables. While most existing works focus on the statistical modeling of the relationship between the latent variables and observable variables or statistical inferences of the latent variables based on the observable variables, it comes to our awareness that an important problem has been largely neglected. In many applications, although the latent variables cannot be routinely acquired, they can be occasionally acquired to enhance the monitoring of the state-space system. Therefore, in this paper, novel dynamic inspection (DI) methods under a general framework of SSMs are developed to identify and inspect the latent variables that are most uncertain. Extensive numeric studies are conducted to demonstrate the effectiveness of the proposed methods.},
  file = {/Users/hyan46/Dropbox (ASU)/ZoteroData/Feng et al_2019_Dynamic Inspection of Latent Variables in State-Space Systems2.pdf},
  keywords = {Method: State Space,People: Kaibo Liu,Problem: Process Monitoring},
  langid = {english},
  number = {3}
}

@article{feurerAutoSklearn,
  title = {Auto-{{Sklearn}} 2.0: {{The Next Generation}}},
  author = {Feurer, Matthias and Eggensperger, Katharina and Falkner, Stefan and Lindauer, Marius and Hutter, Frank},
  pages = {18},
  abstract = {Automated Machine Learning, which supports practitioners and researchers with the tedious task of manually designing machine learning pipelines, has recently achieved substantial success. In this paper we introduce new Automated Machine Learning (AutoML) techniques motivated by our winning submission to the second ChaLearn AutoML challenge, PoSH Auto-sklearn. For this, we extend Auto-sklearn with a new, simpler meta-learning technique, improve its way of handling iterative algorithms and enhance it with a successful bandit strategy for budget allocation. Furthermore, we go one step further and study the design space of AutoML itself and propose a solution towards truly hand-free AutoML. Together, these changes give rise to the next generation of our AutoML system, Auto-sklearn (2.0). We verify the improvement by these additions in a large experimental study on 39 AutoML benchmark datasets and conclude the paper by comparing to Auto-sklearn (1.0), reducing the regret by up to a factor of five.},
  file = {/Users/hyan46/Dropbox (ASU)/ZoteroData/Feurer et al_Auto-Sklearn 2.pdf},
  langid = {english}
}

@inproceedings{feurerEfficient2015,
  title = {Efficient and Robust Automated Machine Learning},
  booktitle = {Advances in {{Neural Information Processing Systems}}},
  author = {Feurer, Matthias and Klein, Aaron and Eggensperger, Katharina and Springenberg, Jost Tobias and Blum, Manuel and Hutter, Frank},
  date = {2015},
  pages = {2962--2970},
  issn = {10495258},
  abstract = {The success of machine learning in a broad range of applications has led to an ever-growing demand for machine learning systems that can be used off the shelf by non-experts. To be effective in practice, such systems need to automatically choose a good algorithm and feature preprocessing steps for a new dataset at hand, and also set their respective hyperparameters. Recent work has started to tackle this automated machine learning (AutoML) problem with the help of efficient Bayesian optimization methods. Building on this, we introduce a robust new AutoML system based on scikit-learn (using 15 classifiers, 14 feature preprocessing methods, and 4 data preprocessing methods, giving rise to a structured hypothesis space with 110 hyperparameters). This system, which we dub AUTO-SKLEARN, improves on existing AutoML methods by automatically taking into account past performance on similar datasets, and by constructing ensembles from the models evaluated during the optimization. Our system won the first phase of the ongoing ChaLearn AutoML challenge, and our comprehensive analysis on over 100 diverse datasets shows that it substantially outperforms the previous state of the art in AutoML. We also demonstrate the performance gains due to each of our contributions and derive insights into the effectiveness of the individual components of AUTO-SKLEARN.},
  file = {/Users/hyan46/Dropbox (ASU)/ZoteroData/Feurer et al_2015_Efficient and robust automated machine learning.pdf}
}

@article{Franciosa:2020ih,
  title = {Deep Learning Enhanced Digital Twin for Remote Laser Welding of Aluminium Structures},
  author = {Franciosa, Pasquale and Sokolov, Mikhail and Sinha, Sumit and Sun, Tianzhu and Ceglarek, Dariusz},
  date = {2020-06},
  journaltitle = {CIRP Annals},
  publisher = {{Elsevier}},
  doi = {10.1016/j.cirp.2020.04.110},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0007850620301323},
  abstract = {A digital twin framework is presented for assembly systems with compliant parts fusing sensors with deep learning and CAE simulations. Its underlying …},
  date-added = {2020-07-03T19:21:19GMT},
  date-modified = {2020-07-04T00:26:51GMT},
  keywords = {Application: Assembly,Application: Manufacturing,Method: Deep Learning,People: Cerek,Problem: Digital Twin},
  langid = {english},
  rating = {0},
  read = {Yes},
  uri = {papers3://publication/doi/10.1016/j.cirp.2020.04.110}
}

@online{frankleLottery2019,
  title = {The {{Lottery Ticket Hypothesis}}: {{Finding Sparse}}, {{Trainable Neural Networks}}},
  shorttitle = {The {{Lottery Ticket Hypothesis}}},
  author = {Frankle, Jonathan and Carbin, Michael},
  date = {2019-03-04},
  url = {http://arxiv.org/abs/1803.03635},
  urldate = {2021-02-25},
  abstract = {Neural network pruning techniques can reduce the parameter counts of trained networks by over 90\%, decreasing storage requirements and improving computational performance of inference without compromising accuracy. However, contemporary experience is that the sparse architectures produced by pruning are difficult to train from the start, which would similarly improve training performance. We find that a standard pruning technique naturally uncovers subnetworks whose initializations made them capable of training effectively. Based on these results, we articulate the "lottery ticket hypothesis:" dense, randomly-initialized, feed-forward networks contain subnetworks ("winning tickets") that - when trained in isolation - reach test accuracy comparable to the original network in a similar number of iterations. The winning tickets we find have won the initialization lottery: their connections have initial weights that make training particularly effective. We present an algorithm to identify winning tickets and a series of experiments that support the lottery ticket hypothesis and the importance of these fortuitous initializations. We consistently find winning tickets that are less than 10-20\% of the size of several fully-connected and convolutional feed-forward architectures for MNIST and CIFAR10. Above this size, the winning tickets that we find learn faster than the original network and reach higher test accuracy.},
  archiveprefix = {arXiv},
  eprint = {1803.03635},
  eprinttype = {arxiv},
  file = {/Users/hyan46/Zotero/storage/KGRLX9QX/Frankle and Carbin - 2019 - The Lottery Ticket Hypothesis Finding Sparse, Tra.pdf;/Users/hyan46/Zotero/storage/V2W3NLAF/1803.html},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Machine Learning,Computer Science - Neural and Evolutionary Computing},
  primaryclass = {cs}
}

@article{fuLowrank,
  title = {Low-Rank {{Joint Embedding}} and Its {{Application}} for {{Robust Process Monitoring}}},
  author = {Fu, Yuanjian and Luo, Chaomin},
  pages = {12},
  abstract = {Industrial data is in general corrupted by noises and outliers. In this context, robustness to the contaminated data is a challenging issue in process monitoring. In this paper, a novel method named low-rank joint embedding (LRJE) is proposed for robust process monitoring. By learning a low-rank coefficient matrix, LRJE can capture the global structure of the original data and alleviate the negative effect of outliers, making the monitoring results more reliable. Moreover, a manifold regularization is introduced to preserve the local geometric structure of data, which enables the extracted low-dimensional representation of data to be more faithful and informative to enhance the monitoring capability. Based on projection learning, the LRJE can learn an explicit projection that transforms the data not involved in the training data into the low-dimensional space, avoiding the out-ofsample problem. Furthermore, a reconstruction-based contribution (RBC) plots based on the LRJE is developed to identify the potential faulty variables. Case studies on the Tennessee Eastman (TE) process and a real industrial application demonstrate the effectiveness of the proposed monitoring approach.},
  file = {/Users/hyan46/Dropbox (ASU)/ZoteroData/Fu_Luo_Low-rank Joint Embedding and its Application for Robust Process Monitoring.pdf},
  langid = {english}
}

@article{fuLowRank2021,
  title = {Low-{{Rank Joint Embedding}} and {{Its Application}} for {{Robust Process Monitoring}}},
  author = {Fu, Yuanjian and Luo, Chaomin and Bi, Zhuming},
  date = {2021},
  journaltitle = {IEEE Transactions on Instrumentation and Measurement},
  volume = {70},
  pages = {1--13},
  issn = {1557-9662},
  doi = {10.1109/TIM.2021.3075017},
  abstract = {Industrial data are in general corrupted by noises and outliers. In this context, robustness to the contaminated data is a challenging issue in process monitoring. In this article, a novel method named low-rank joint embedding is proposed for robust process monitoring. By learning a low-rank coefficient matrix, low-rank joint embedding can capture the global structure of the original data and alleviate the negative effect of outliers, making the monitoring results more reliable. Moreover, a manifold regularization is introduced to preserve the local geometric structure of data, which enables the extracted low-dimensional representation of data to be more faithful and informative to enhance the monitoring capability. Based on projection learning, the low-rank joint embedding can learn an explicit projection that transforms the data not involved in the training data into the low-dimensional space, avoiding the out-of-sample problem. Furthermore, a reconstruction-based contribution plots based on the low-rank joint embedding is developed to identify the potential faulty variables. Case studies on the Tennessee Eastman process and a real industrial application demonstrate the effectiveness of the proposed monitoring approach.},
  eventtitle = {{{IEEE Transactions}} on {{Instrumentation}} and {{Measurement}}},
  file = {/Users/hyan46/Dropbox (ASU)/ZoteroData/Fu et al_2021_Low-Rank Joint Embedding and Its Application for Robust Process Monitoring.pdf;/Users/hyan46/Zotero/storage/57DL5Q64/9411820.html},
  keywords = {Feature extraction,Gaussian distribution,Linear programming,Low-rank representation (LRR),manifold learning,process monitoring,Process monitoring,Robustness,structure preserving,Task analysis,Training data}
}

@article{funckImage2003,
  title = {Image Segmentation Algorithms Applied to Wood Defect Detection},
  author = {Funck, J.W and Zhong, Y and Butler, D.A and Brunner, C.C and Forrer, J.B},
  date = {2003-12},
  journaltitle = {Computers and Electronics in Agriculture},
  shortjournal = {Computers and Electronics in Agriculture},
  volume = {41},
  pages = {157--179},
  issn = {01681699},
  doi = {10.1016/S0168-1699(03)00049-8},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0168169903000498},
  urldate = {2020-07-15},
  file = {/Users/hyan46/Dropbox (ASU)/ZoteroData/Funck et al_2003_Image segmentation algorithms applied to wood defect detection.pdf},
  langid = {english},
  number = {1-3}
}

@article{fuTensor2016,
  title = {Tensor {{LRR}} and {{Sparse Coding}}-{{Based Subspace Clustering}}},
  author = {Fu, Yifan and Gao, Junbin and Tien, David and Lin, Zhouchen and Hong, Xia},
  date = {2016-10},
  journaltitle = {IEEE Transactions on Neural Networks and Learning Systems},
  shortjournal = {IEEE Trans. Neural Netw. Learning Syst.},
  volume = {27},
  pages = {2120--2133},
  issn = {2162-237X, 2162-2388},
  doi = {10.1109/TNNLS.2016.2553155},
  url = {http://ieeexplore.ieee.org/document/7460141/},
  urldate = {2021-07-03},
  abstract = {Subspace clustering groups a set of samples from a union of several linear subspaces into clusters, so that samples in the same cluster are drawn from the same linear subspace. In the majority of existing work on subspace clustering, clusters are built based on the samples’ feature information, while sample correlations in their original spatial structure are simply ignored. Besides, original high-dimensional feature vector contains noisy/redundant information, and the time complexity grows exponentially with the number of dimensions. To address these issues, we propose a tensor low-rank representation (TLRR) and sparse coding (SC) based subspace clustering method (TLRRSC) by simultaneously considering the samples’ feature information and spatial structures. TLRR seeks a lowest-rank representation over original spatial structures along all spatial directions. Sparse coding learns a dictionary along feature spaces, so that each sample can be represented by a few atoms of the learned dictionary. The affinity matrix used for spectral clustering is built from the joint similarities in both spatial and feature spaces. TLRRSC can well capture the global structure and inherent feature information of data, and provide a robust subspace segmentation from corrupted data. Experimental results on both synthetic and real-world datasets show that TLRRSC outperforms several established state-of-the-art methods.},
  file = {/Users/hyan46/Zotero/storage/Q2YJVKK4/Fu et al. - 2016 - Tensor LRR and Sparse Coding-Based Subspace Cluste.pdf},
  langid = {english},
  number = {10}
}

@article{gahrooeiAdaptive2019,
  title = {An Adaptive Fused Sampling Approach of High-Accuracy Data in the Presence of Low-Accuracy Data},
  author = {Gahrooei, Mostafa Reisi and Paynabar, Kamaran and Pacella, Massimo and Colosimo, Bianca Maria},
  date = {2019-11-02},
  journaltitle = {IISE Transactions},
  shortjournal = {IISE Transactions},
  volume = {51},
  pages = {1251--1264},
  issn = {2472-5854, 2472-5862},
  doi = {10.1080/24725854.2018.1540901},
  url = {https://www.tandfonline.com/doi/full/10.1080/24725854.2018.1540901},
  urldate = {2020-07-07},
  abstract = {In several applications, a large amount of Low-Accuracy (LA) data can be acquired at a small cost. However, in many situations, such LA data is not sufficient for generating a higidelity model of a system. To adjust and improve the model constructed by LA data, a small sample of HighAccuracy (HA) data, which is expensive to obtain, is usually fused with the LA data. Unfortunately, current techniques assume that the HA data is already collected and concentrate on fusion strategies, without providing guidelines on how to sample the HA data. This work addresses the problem of collecting HA data adaptively and sequentially so when it is integrated with the LA data a more accurate surrogate model is achieved. For this purpose, we propose an approach that takes advantage of the information provided by LA data as well as the previously selected HA data points and computes an improvement criterion over a design space to choose the next HA data point. The performance of the proposed method is evaluated, using both simulation and case studies. The results show the benefits of the proposed method in generating an accurate surrogate model when compared to three other benchmarks.},
  file = {/Users/hyan46/Dropbox (ASU)/ZoteroData/Gahrooei et al_2019_An adaptive fused sampling approach of high-accuracy data in the presence of.pdf},
  langid = {english},
  number = {11}
}

@article{gahrooeiChange2018,
  title = {Change Detection in a Dynamic Stream of Attributed Networks},
  author = {Gahrooei, Mostafa Reisi and Paynabar, Kamran},
  date = {2018-10-02},
  journaltitle = {Journal of Quality Technology},
  shortjournal = {Journal of Quality Technology},
  volume = {50},
  pages = {418--430},
  issn = {0022-4065, 2575-6230},
  doi = {10.1080/00224065.2018.1507558},
  url = {https://www.tandfonline.com/doi/full/10.1080/00224065.2018.1507558},
  urldate = {2020-07-04},
  abstract = {While anomaly detection in static networks has been extensively studied, only recently have researchers focused on dynamic networks. This trend is mainly due to the capacity of dynamic networks to represent complex physical, biological, cyber, and social systems. This article proposes a new methodology for modeling and monitoring dynamic attributed networks for quick detection of temporal changes in network structures. In this methodology, the generalized linear model (GLM) is used to model static attributed networks. This model is then combined with a state transition equation to capture the dynamic behavior of the system. Extended Kalman filter (EKF) is used as an online, recursive inference procedure to predict and update network parameters over time. In order to detect changes in the underlying mechanism of edge formation, prediction residuals are monitored through an exponentially weighted moving average (EWMA) control chart. The proposed modeling and monitoring procedure is examined through simulations for attributed binary and weighted networks. Email communication data from the Enron corporation is used as a case study to show how the method can be applied in real-world problems.},
  file = {/Users/hyan46/Dropbox (ASU)/ZoteroData/Gahrooei_Paynabar_2018_Change detection in a dynamic stream of attributed networks.pdf},
  keywords = {People: Kamran Paynabar,Problem: Process Monitoring},
  langid = {english},
  number = {4}
}

@article{gahrooeiMultiple2020,
  title = {Multiple {{Tensor}}-on-{{Tensor Regression}}: {{An Approach}} for {{Modeling Processes With Heterogeneous Sources}} of {{Data}}},
  author = {Gahrooei, Mostafa Reisi and Yan, Hao and Paynabar, Kamran and Shi, Jianjun},
  date = {2020},
  journaltitle = {Technometrics},
  publisher = {{American Statistical Association}},
  issn = {15372723},
  doi = {10.1080/00401706.2019.1708463},
  abstract = {In recent years, measurement or collection of heterogeneous sets of data such as those containing scalars, waveform signals, images, and even structured point clouds, has become more common. Statistical models based on such heterogeneous sets of data that represent the behavior of an underlying system can be used in the monitoring, control, and optimization of the system. Unfortunately, available methods mainly focus on the scalars and profiles and do not provide a general framework for integrating different sources of data to construct a model. This article addresses the problem of estimating a process output, measured by a scalar, curve, image, or structured point cloud by a set of heterogeneous process variables such as scalar process setting, profile sensor readings, and images. We introduce a general multiple tensor-on-tensor regression approach in which each set of input data (predictor) and output measurements are represented by tensors. We formulate a linear regression model between the input and output tensors and estimate the parameters by minimizing a least square loss function. To avoid overfitting and reduce the number of parameters to be estimated, we decompose the model parameters using several basis matrices that span the input and output spaces, and provide efficient optimization algorithms for learning the basis and coefficients. Through several simulation and case studies, we evaluate the performance of the proposed method. The results reveal the advantage of the proposed method over some benchmarks in the literature in terms of the mean square prediction error. Supplementary materials for this article are available online.},
  annotation = {\_eprint: 1803.00138},
  file = {/Users/hyan46/Dropbox (ASU)/ZoteroData/Gahrooei et al_2020_Multiple Tensor-on-Tensor Regression3.pdf},
  keywords = {Application: Manufacturing,Method: Tensor,Problem: Classification}
}

@article{galDeep,
  title = {Deep {{Bayesian Active Learning}} with {{Image Data}}},
  author = {Gal, Yarin and Islam, Riashat and Ghahramani, Zoubin},
  pages = {10},
  abstract = {Even though active learning forms an important pillar of machine learning, deep learning tools are not prevalent within it. Deep learning poses several difficulties when used in an active learning setting. First, active learning (AL) methods generally rely on being able to learn and update models from small amounts of data. Recent advances in deep learning, on the other hand, are notorious for their dependence on large amounts of data. Second, many AL acquisition functions rely on model uncertainty, yet deep learning methods rarely represent such model uncertainty. In this paper we combine recent advances in Bayesian deep learning into the active learning framework in a practical way. We develop an active learning framework for high dimensional data, a task which has been extremely challenging so far, with very sparse existing literature. Taking advantage of specialised models such as Bayesian convolutional neural networks, we demonstrate our active learning techniques with image data, obtaining a significant improvement on existing active learning approaches. We demonstrate this on both the MNIST dataset, as well as for skin cancer diagnosis from lesion images (ISIC2016 task).},
  file = {/Users/hyan46/Dropbox (ASU)/ZoteroData/Gal et al_Deep Bayesian Active Learning with Image Data.pdf},
  langid = {english}
}

@article{ganchevPosterior2010,
  title = {Posterior {{Regularization}} for {{Structured Latent Variable Models}}},
  author = {Ganchev, Kuzman and Graça, João and Gillenwater, Jennifer and Taskar, Ben},
  date = {2010},
  journaltitle = {The Journal of Machine Learning Research},
  shortjournal = {JMLR},
  volume = {11},
  pages = {2001--2049},
  file = {/Users/hyan46/Dropbox (ASU)/ZoteroData/Ganchev et al_2010_Posterior Regularization for Structured Latent Variable Models.pdf},
  langid = {english}
}

@article{gaoOptimal2020,
  title = {Optimal {{Integration}} of {{Supervised Tensor Decomposition}} and {{Ensemble Learning}} for {{itIn Situ Quality Evaluation}} in {{Friction Stir Blind Riveting}}},
  author = {Gao, Zhe and Guo, Weihong and Yue, Xiaowei},
  date = {2020},
  journaltitle = {IEEE Transactions on Automation Science and Engineering},
  shortjournal = {IEEE Trans. Automat. Sci. Eng.},
  pages = {1--17},
  issn = {1545-5955, 1558-3783},
  doi = {10.1109/TASE.2019.2955397},
  url = {https://ieeexplore.ieee.org/document/8967240/},
  urldate = {2020-07-21},
  abstract = {This article develops a novel in situ nondestructive quality evaluation for friction stir blind riveting in joining lightweight materials. This method is able to solve the small sample size problem that is commonly occurred in manufacturing experiments. The proposed method achieves an optimal integration of the tensor decomposition and ensemble learning by utilizing the mutual benefits. On the one hand, diversified feature matrices are extracted via tensor decomposition to maximize the ensemble learning performance. On the other hand, regularized tensor decomposition results deviate with different regularization parameter values and ensemble learning is able to determine the optimal parameter value via a heuristic algorithm, which stabilizes the tensor decomposition results. This optimal integration is built by developing a novel diversity-based feature generation and selection approach: 1) a diversity measure is defined to evaluate the extracted features; 2) a heuristic adaptive algorithm is developed with ensemble learning to determine the optimal regularization parameter for integration; and 3) the optimal features are selected via clustering to maximize the diversity measure, which is expected to strengthen ensemble learning performance for better evaluation results. Numerical studies and case studies are performed to demonstrate the effectiveness of the proposed method as well as its superiority over the existing methods.},
  file = {/Users/hyan46/Dropbox (ASU)/ZoteroData/Gao et al_2020_Optimal Integration of Supervised Tensor Decomposition and Ensemble Learning.pdf},
  keywords = {Method: Tensor},
  langid = {english}
}

@article{gaoVariational2018,
  title = {Variational {{Bayesian Subgroup Adaptive Sparse Component Extraction}} for {{Diagnostic Imaging System}}},
  author = {Gao, Bin and Lu, Peng and Woo, Wai Lok and Tian, Gui Yun and Zhu, Yuyu and Johnston, Martin},
  date = {2018-10},
  journaltitle = {IEEE Transactions on Industrial Electronics},
  shortjournal = {IEEE Trans. Ind. Electron.},
  volume = {65},
  pages = {8142--8152},
  issn = {0278-0046, 1557-9948},
  doi = {10.1109/TIE.2018.2801809},
  url = {https://ieeexplore.ieee.org/document/8281110/},
  urldate = {2020-07-15},
  abstract = {A novel unsupervised sparse component extraction algorithm is proposed for detecting micro defects while employing a thermography imaging system. The proposed approach is developed using the variational Bayesian framework. This enables a fully automated determination of the model parameters and bypasses the need for human intervention in manually selecting the appropriate image contrast frames. An internal subsparse grouping mechanism and adaptive fine-tuning strategy have been built to control the sparsity of the solution. The proposed algorithm is computationally affordable and yields a high-accuracy objective performance. Experimental tests on both artificial and natural defects have been conducted to verify the efficacy of the proposed method.},
  file = {/Users/hyan46/Dropbox (ASU)/ZoteroData/Gao et al_2018_Variational Bayesian Subgroup Adaptive Sparse Component Extraction for.pdf},
  langid = {english},
  number = {10}
}

@online{geGenerative2017,
  title = {Generative {{OpenMax}} for {{Multi}}-{{Class Open Set Classification}}},
  author = {Ge, ZongYuan and Demyanov, Sergey and Chen, Zetao and Garnavi, Rahil},
  date = {2017-07-24},
  url = {http://arxiv.org/abs/1707.07418},
  urldate = {2020-09-06},
  abstract = {We present a conceptually new and flexible method for multi-class open set classification. Unlike previous methods where unknown classes are inferred with respect to the feature or decision distance to the known classes, our approach is able to provide explicit modelling and decision score for unknown classes. The proposed method, called Generative OpenMax (G-OpenMax), extends OpenMax by employing generative adversarial networks (GANs) for novel category image synthesis. We validate the proposed method on two datasets of handwritten digits and characters, resulting in superior results over previous deep learning based method OpenMax Moreover, G-OpenMax provides a way to visualize samples representing the unknown classes from open space. Our simple and effective approach could serve as a new direction to tackle the challenging multi-class open set classification problem.},
  archiveprefix = {arXiv},
  eprint = {1707.07418},
  eprinttype = {arxiv},
  file = {/Users/hyan46/Dropbox (ASU)/ZoteroData/Ge et al_2017_Generative OpenMax for Multi-Class Open Set Classification.pdf},
  keywords = {Computer Science - Computer Vision and Pattern Recognition},
  langid = {english},
  primaryclass = {cs}
}

@article{geMultimode2009,
  title = {Multimode Process Monitoring Based on {{Bayesian}} Method},
  author = {Ge, Zhiqiang and Song, Zhihuan},
  date = {2009},
  journaltitle = {Journal of Chemometrics},
  volume = {23},
  pages = {636--650},
  issn = {1099-128X},
  doi = {10.1002/cem.1262},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/cem.1262},
  urldate = {2020-05-25},
  abstract = {Multimode process monitoring has recently attracted much attention both in academy and industry. Conventional methods assume that either the process data are Gaussian in each operation mode, or some process knowledge should be incorporated, thus making the methods supervised. In this paper, a new unsupervised method is developed for multimode process monitoring, which is based on Bayesian inference and two-step independent component analysis–principal component analysis (ICA–PCA) feature extraction strategy. ICA–PCA is first introduced for feature extraction and dimension reduction. By transferring the traditional monitoring statistic to fault probability in each operation mode, monitoring results in different operation modes can be easily combined by the Bayesian inference. Another contribution of the present paper is the development of a new fault identification method. Through analyses of the posterior probability and the joint probability for the monitored data sample, the correct operation mode or fault scenario can be identified. Three case studies are demonstrated to evaluate the feasibility and efficiency of the proposed method. Copyright © 2009 John Wiley \& Sons, Ltd.},
  annotation = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/cem.1262},
  file = {/Users/hyan46/Zotero/storage/UNPMULSL/cem.html},
  keywords = {Bayesian inference,fault identification,ICA–PCA,Method: Bayesian,multimode,Problem: Process Monitoring,process monitoring,statistical analysis},
  langid = {english},
  number = {12}
}

@online{gengRecent2020,
  title = {Recent {{Advances}} in {{Open Set Recognition}}: {{A Survey}}},
  shorttitle = {Recent {{Advances}} in {{Open Set Recognition}}},
  author = {Geng, Chuanxing and Huang, Sheng-jun and Chen, Songcan},
  date = {2020-03-21},
  doi = {10.1109/TPAMI.2020.2981604},
  url = {http://arxiv.org/abs/1811.08581},
  urldate = {2020-09-06},
  abstract = {In real-world recognition/classification tasks, limited by various objective factors, it is usually difficult to collect training samples to exhaust all classes when training a recognizer or classifier. A more realistic scenario is open set recognition (OSR), where incomplete knowledge of the world exists at training time, and unknown classes can be submitted to an algorithm during testing, requiring the classifiers to not only accurately classify the seen classes, but also effectively deal with unseen ones. This paper provides a comprehensive survey of existing open set recognition techniques covering various aspects ranging from related definitions, representations of models, datasets, evaluation criteria, and algorithm comparisons. Furthermore, we briefly analyze the relationships between OSR and its related tasks including zero-shot, one-shot (few-shot) recognition/learning techniques, classification with reject option, and so forth. Additionally, we also review the open world recognition which can be seen as a natural extension of OSR. Importantly, we highlight the limitations of existing approaches and point out some promising subsequent research directions in this field.},
  archiveprefix = {arXiv},
  eprint = {1811.08581},
  eprinttype = {arxiv},
  file = {/Users/hyan46/Dropbox (ASU)/ZoteroData/Geng et al_2020_Recent Advances in Open Set Recognition.pdf},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  langid = {english},
  primaryclass = {cs, stat}
}

@book{gittinsMultiarmed2011,
  title = {Multi-Armed Bandit Allocation Indices},
  author = {Gittins, John and Glazebrook, Kevin and Weber, Richard},
  date = {2011-02-18},
  publisher = {{John Wiley \& Sons}},
  abstract = {In 1989 the first edition of this book set out Gittins' pioneering index solution to the multi-armed bandit problem and his subsequent investigation of a wide of sequential resource allocation and stochastic scheduling problems. Since then there has been a remarkable flowering of new insights, generalizations and applications, to which Glazebrook and Weber have made major contributions. This second edition brings the story up to date. There are new chapters on the achievable region approach to stochastic optimization problems, the construction of performance bounds for suboptimal policies, Whittle's restless bandits, and the use of Lagrangian relaxation in the construction and evaluation of index policies. Some of the many varied proofs of the index theorem are discussed along with the insights that they provide. Many contemporary applications are surveyed, and over 150 new references are included. Over the past 40 years the Gittins index has helped theoreticians and practitioners to address a huge variety of problems within chemometrics, economics, engineering, numerical analysis, operational research, probability, statistics and website design. This new edition will be an important resource for others wishing to use this approach.},
  eprint = {LzSLMHfM3QgC},
  eprinttype = {googlebooks},
  isbn = {978-1-119-99021-5},
  keywords = {Mathematics / Probability & Statistics / General,Mathematics / Probability & Statistics / Stochastic Processes},
  langid = {english},
  pagetotal = {287}
}

@article{goernitzSupervised2013,
  title = {Toward {{Supervised Anomaly Detection}}},
  author = {Goernitz, N. and Kloft, M. and Rieck, K. and Brefeld, U.},
  date = {2013-02-20},
  journaltitle = {Journal of Artificial Intelligence Research},
  volume = {46},
  pages = {235--262},
  issn = {1076-9757},
  doi = {10.1613/jair.3623},
  url = {https://www.jair.org/index.php/jair/article/view/10802},
  urldate = {2020-05-25},
  file = {/Users/hyan46/Zotero/storage/XTLX5CTY/10802.html},
  keywords = {semianomaly},
  langid = {english}
}

@article{gorgannejadQuantitative2019,
  title = {Quantitative Prediction of the Aged State of {{Ni}}-Base Superalloys Using {{PCA}} and Tensor Regression},
  author = {Gorgannejad, S. and Reisi Gahrooei, M. and Paynabar, K. and Neu, R.W.},
  date = {2019-02},
  journaltitle = {Acta Materialia},
  shortjournal = {Acta Materialia},
  volume = {165},
  pages = {259--269},
  issn = {13596454},
  doi = {10.1016/j.actamat.2018.11.047},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S1359645418309236},
  urldate = {2020-07-07},
  abstract = {The microstructure of Ni-base superalloy components evolves and degrades during the operation of gas turbines. Since the remaining life depends on the degradation, it is highly desirable to have a quantitative descriptor of the aged state of the microstructure that can be linked to the operating conditions. In this paper, data analytics algorithms are used to develop such relationships. High-throughput aging experiments were performed to generate a dataset comprising multiple aged microstructure images. The digital images of the g/g0 phase are used as an indicator of the aged state and statistically evaluated using 2-point spatial correlation functions. To reduce the high-dimensional structural information so that a quantitative linkage can be made between aging conditions and the aged state, two algorithms were considered. The first algorithm involves two steps, first using conventional principal component analysis (PCA) to provide a lower dimension descriptor of the microstructure and then regression analysis to generate the linkage. The second algorithm, called tensor regression (TR), is a novel algorithm that merges the dimensionality reduction and model construction step into a single step. The output of the TR model is directly the statistical descriptors of the microstructure rather than the PC scores, thereby reducing the amount of information loss. Even though PCA provides an effective tool for visualization and classification of data, the model built based on the TR algorithm is shown to have stronger prediction capability.},
  file = {/Users/hyan46/Dropbox (ASU)/ZoteroData/Gorgannejad et al_2019_Quantitative prediction of the aged state of Ni-base superalloys using PCA and.pdf},
  langid = {english}
}

@article{guoCalibration,
  title = {On {{Calibration}} of {{Modern Neural Networks}}},
  author = {Guo, Chuan and Pleiss, Geoff and Sun, Yu and Weinberger, Kilian Q},
  pages = {14},
  abstract = {Confidence calibration – the problem of predicting probability estimates representative of the true correctness likelihood – is important for classification models in many applications. We discover that modern neural networks, unlike those from a decade ago, are poorly calibrated. Through extensive experiments, we observe that depth, width, weight decay, and Batch Normalization are important factors influencing calibration. We evaluate the performance of various post-processing calibration methods on state-ofthe-art architectures with image and document classification datasets. Our analysis and experiments not only offer insights into neural network learning, but also provide a simple and straightforward recipe for practical settings: on most datasets, temperature scaling – a singleparameter variant of Platt Scaling – is surprisingly effective at calibrating predictions.},
  file = {/Users/hyan46/Dropbox (ASU)/ZoteroData/Guo et al_On Calibration of Modern Neural Networks.pdf},
  langid = {english}
}

@article{guoDecision2015,
  title = {A Decision Support System on Surgical Treatments for Rotator Cuff Tears},
  author = {Guo, Weihong and Jin, Jionghua and Paynabar, Kamran and Miller, Bruce and Carpenter, James},
  date = {2015-07-03},
  journaltitle = {IIE Transactions on Healthcare Systems Engineering},
  shortjournal = {IIE Transactions on Healthcare Systems Engineering},
  volume = {5},
  pages = {197--210},
  issn = {1948-8300, 1948-8319},
  doi = {10.1080/19488300.2015.1065935},
  url = {http://www.tandfonline.com/doi/full/10.1080/19488300.2015.1065935},
  urldate = {2020-07-07},
  abstract = {Treatment of patients with rotator cuff tears usually starts with physical therapy, but some patients will still eventually need surgery. Ineffective physical therapy increases the time and cost of treatment and pain for patients. The quality of treatment can be improved if patients who will not respond to physical therapy are identified at an early stage. However, there is little research available to systematically help physicians make a timely decision on whether a surgical treatment is eventually needed or not. In this research, we developed a decision support system that can predict the probability of eventually needing a surgical treatment by effectively analyzing the available patients’ information at an early stage. Missing value imputation, variable selection, and classification methods are integrated in developing such a decision support system. The probability given by our model will either confirm physician’s expert decision, or remind physician if there is any information ignored. This research has the potential to improve patient safety, reduce cost of unnecessary treatment, and help physicians prevent treatment errors.},
  file = {/Users/hyan46/Dropbox (ASU)/ZoteroData/Guo et al_2015_A decision support system on surgical treatments for rotator cuff tears.pdf},
  langid = {english},
  number = {3}
}

@article{guoProfile2019,
  title = {Profile {{Monitoring}} and {{Fault Diagnosis Via Sensor Fusion}} for {{Ultrasonic Welding}}},
  author = {Guo, Weihong and Jin, Jionghua and Jack Hu, S.},
  date = {2019-08-01},
  journaltitle = {Journal of Manufacturing Science and Engineering},
  volume = {141},
  pages = {081001},
  issn = {1087-1357, 1528-8935},
  doi = {10.1115/1.4043731},
  url = {https://asmedigitalcollection.asme.org/manufacturingscience/article/doi/10.1115/1.4043731/726771/Profile-Monitoring-and-Fault-Diagnosis-Via-Sensor},
  urldate = {2020-07-04},
  abstract = {Sensor signals acquired during the manufacturing process contain rich information that can be used to facilitate effective monitoring of operational quality, early detection of system anomalies, and quick diagnosis of fault root causes. This paper develops a method for effective monitoring and diagnosis of multisensor heterogeneous profile data based on multilinear discriminant analysis. The proposed method operates directly on the multistream profiles and then extracts uncorrelated discriminative features through tensor-to-vector projection, and thus, preserving the interrelationship of different sensors. The extracted features are then fed into classifiers to detect faulty operations and recognize fault types. The developed method is demonstrated with both simulated and real data from ultrasonic metal welding.},
  file = {/Users/hyan46/Dropbox (ASU)/ZoteroData/Guo et al_2019_Profile Monitoring and Fault Diagnosis Via Sensor Fusion for Ultrasonic Welding.pdf},
  keywords = {Data: Profiles,Method: Functional,Method: Tensor,People: Judy Jin,Problem: Process Monitoring},
  langid = {english},
  number = {8}
}

@online{guptaGenerative2021,
  title = {Generative {{Multi}}-{{Label Zero}}-{{Shot Learning}}},
  author = {Gupta, Akshita and Narayan, Sanath and Khan, Salman and Khan, Fahad Shahbaz and Shao, Ling and van de Weijer, Joost},
  date = {2021-01-28},
  url = {http://arxiv.org/abs/2101.11606},
  urldate = {2021-06-15},
  abstract = {Multi-label zero-shot learning strives to classify images into multiple unseen categories for which no data is available during training. The test samples can additionally contain seen categories in the generalized variant. Existing approaches rely on learning either shared or labelspecific attention from the seen classes. Nevertheless, computing reliable attention maps for unseen classes during inference in a multi-label setting is still a challenge. In contrast, state-of-the-art single-label generative adversarial network (GAN) based approaches learn to directly synthesize the class-specific visual features from the corresponding class attribute embeddings. However, synthesizing multi-label features from GANs is still unexplored in the context of zero-shot setting. In this work, we introduce different fusion approaches at the attribute-level, featurelevel and cross-level (across attribute and feature-levels) for synthesizing multi-label features from their corresponding multi-label class embeddings. To the best of our knowledge, our work is the first to tackle the problem of multilabel feature synthesis in the (generalized) zero-shot setting. Comprehensive experiments are performed on three zeroshot image classification benchmarks: NUS-WIDE, Open Images and MS COCO. Our cross-level fusion-based generative approach outperforms the state-of-the-art on all three datasets. Furthermore, we show the generalization capabilities of our fusion approach in the zero-shot detection task on MS COCO, achieving favorable performance against existing methods. The source code is available at https: //github.com/akshitac8/Generative\_MLZSL.},
  archiveprefix = {arXiv},
  eprint = {2101.11606},
  eprinttype = {arxiv},
  file = {/Users/hyan46/Dropbox (ASU)/ZoteroData/Gupta et al_2021_Generative Multi-Label Zero-Shot Learning.pdf},
  keywords = {Computer Science - Computer Vision and Pattern Recognition},
  langid = {english},
  options = {useprefix=true},
  primaryclass = {cs}
}

@inproceedings{hanKernel2019,
  title = {The {{Kernel Spatial Scan Statistic}}},
  booktitle = {Proceedings of the 27th {{ACM SIGSPATIAL International Conference}} on {{Advances}} in {{Geographic Information Systems}}},
  author = {Han, Mingxuan and Matheny, Michael and Phillips, Jeff M.},
  date = {2019-11-05},
  pages = {349--358},
  publisher = {{Association for Computing Machinery}},
  location = {{Chicago, IL, USA}},
  doi = {10.1145/3347146.3359101},
  url = {https://doi.org/10.1145/3347146.3359101},
  urldate = {2020-05-25},
  abstract = {Kulldorff's (1997) seminal paper on spatial scan statistics (SSS) has led to many methods considering different regions of interest, different statistical models, and different approximations while also having numerous applications in epidemiology, environmental monitoring, and homeland security. SSS provides a way to rigorously test for the existence of an anomaly and provide statistical guarantees as to how "anomalous" that anomaly is. However, these methods rely on defining specific regions where the spatial information a point contributes is limited to binary 0 or 1, of either inside or outside the region, while in reality anomalies will tend to follow smooth distributions with decaying density further from an epicenter. In this work, we propose a method that addresses this shortcoming through a continuous scan statistic that generalizes SSS by allowing the point contribution to be defined by a kernel. We provide extensive experimental and theoretical results that shows our methods can be computed efficiently while providing high statistical power for detecting anomalous regions.},
  file = {/Users/hyan46/Dropbox (ASU)/ZoteroData/Han et al_2019_The Kernel Spatial Scan Statistic.pdf},
  isbn = {978-1-4503-6909-1},
  keywords = {Anomaly detection,Kernels,Method: Functional,Scalable Algorithms,scan statistics,Spatial Scan Statistics,Spatio temporal},
  series = {{{SIGSPATIAL}} '19}
}

@article{haoControlling2017,
  title = {Controlling the {{Residual Life Distribution}} of {{Parallel Unit Systems Through Workload Adjustment}}},
  author = {Hao, Li and Liu, Kaibo and Gebraeel, Nagi and Shi, Jianjun},
  date = {2017-04},
  journaltitle = {IEEE Transactions on Automation Science and Engineering},
  shortjournal = {IEEE Trans. Automat. Sci. Eng.},
  volume = {14},
  pages = {1042--1052},
  issn = {1545-5955, 1558-3783},
  doi = {10.1109/TASE.2015.2481703},
  url = {http://ieeexplore.ieee.org/document/7302091/},
  urldate = {2020-07-04},
  abstract = {Complex systems often consist of multiple units that are required to work together in parallel to satisfy a specific engineering objective. As an example, in manufacturing processes, several identical machines may need to operate together to simultaneously fabricate the same products in order to meet the high production demand. This parallel configuration is often designed with some level of redundancy to compensate for unexpected events. In this way, when only a small portion of units fail to operate due to either unexpected machine downtime or scheduled maintenance, the remaining units can still achieve the engineering objective by increasing their workloads up to the designed capacities. However, the workload of a unit apparently impacts the unit's degradation rate as well as its failure time. Specifically, this paper considers the case that a higher workload assignment accelerates the unit's degradation and vice versa. Based on this assumption, we develop a method to actively control the degradation as well as the predicted failure time of each unit by dynamically adjusting its workloads. Our goal is to prevent the overlap of unit failures within a certain time period through taking advantage of the natural redundancy of the parallel structure, which may potentially lead to a better utilization of maintenance resources as well as a consistently ensured system throughput. A numerical study is used to evaluate the performance of the proposed method under different scenarios.},
  file = {/Users/hyan46/Dropbox (ASU)/ZoteroData/Hao et al_2017_Controlling the Residual Life Distribution of Parallel Unit Systems Through.pdf},
  keywords = {Application: Engine,Data: Profiles,Method: Health Index,People: Kaibo Liu,Problem: Prognostics},
  langid = {english},
  number = {2}
}

@article{haoyanDeep2021,
  title = {Deep {{Multistage Multi}}-{{Task Learning}} for {{Quality Prediction}} and {{Diagnostics}} of {{Multistage Manufacturing Systems}}},
  author = {{Hao Yan} and {Nurretin D. Sergin} and {William A. Brenneman} and {Stephen J. Lange} and {Shan Ba}},
  date = {2021},
  journaltitle = {Journal of Quality Technology},
  pages = {1--27},
  doi = {10.1080/00224065.2021.1903822},
  abstract = {In multistage manufacturing systems, modeling multiple quality indices based on the process sensing variables is important. However, the classic modeling technique predicts each quality variable one at a time, which fails to consider the correlation within or between stages. We propose a deep multistage multi-task learning framework to jointly predict all output sensing variables in a unified end-to-end learning framework according to the sequential system architecture in the MMS. Our numerical studies and real case study have shown that the new model has a superior performance compared to many benchmark methods as well as great interpretability through developed variable selection techniques.},
  keywords = {Application: Manufacturing,Data: Sigmal,Method: Deep Learning,Method: Multi-task Learning,Problem: Regression}
}

@article{harkoExact2014,
  title = {Exact Analytical Solutions of the {{Susceptible}}-{{Infected}}-{{Recovered}} ({{SIR}}) Epidemic Model and of the {{SIR}} Model with Equal Death and Birth Rates},
  author = {Harko, Tiberiu and Lobo, Francisco S.N. and Mak, M.K.},
  date = {2014-06},
  journaltitle = {Applied Mathematics and Computation},
  shortjournal = {Applied Mathematics and Computation},
  volume = {236},
  pages = {184--194},
  issn = {00963003},
  doi = {10.1016/j.amc.2014.03.030},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S009630031400383X},
  urldate = {2021-01-07},
  abstract = {In this paper, the exact analytical solution of the Susceptible-Infected-Recovered (SIR) epidemic model is obtained in a parametric form. By using the exact solution we investigate some explicit models corresponding to fixed values of the parameters, and show that the numerical solution reproduces exactly the analytical solution. We also show that the generalization of the SIR model, including births and deaths, described by a nonlinear system of differential equations, can be reduced to an Abel type equation. The reduction of the complex SIR model with vital dynamics to an Abel type equation can greatly simplify the analysis of its properties. The general solution of the Abel equation is obtained by using a perturbative approach, in a power series form, and it is shown that the general solution of the SIR model with vital dynamics can be represented in an exact parametric form.},
  file = {/Users/hyan46/Zotero/storage/FA7QRACL/Harko et al. - 2014 - Exact analytical solutions of the Susceptible-Infe.pdf},
  langid = {english}
}

@online{harrisScalable2021,
  title = {Scalable {{Multiple Changepoint Detection}} for {{Functional Data Sequences}}},
  author = {Harris, Trevor and Li, Bo and Tucker, James Derek},
  date = {2021-03-01},
  url = {http://arxiv.org/abs/2008.01889},
  urldate = {2021-06-13},
  abstract = {We propose the Multiple Changepoint Isolation (MCI) method for detecting multiple changes in the mean and covariance of a functional process. We first introduce a pair of projections to represent the variability “between” and “within” the functional observations. We then present an augmented fused lasso procedure to split the projections into multiple regions robustly. These regions act to isolate each changepoint away from the others so that the classical univariate CUSUM statistic can be applied region-wise to find all changepoints. Simulations show that our method accurately detects the number and locations of changepoints under many different scenarios. These include light and heavy tailed data, data with symmetric and skewed distributions, sparsely and densely sampled changepoints, and mean and covariance changes. We show that our method outperforms a recent multiple functional changepoint detector and several univariate changepoint detectors applied to our proposed projections. We also show that MCI is more robust than existing approaches and scales linearly with sample size. Finally, we demonstrate our method on a large time series of water vapor mixing ratio profiles from atmospheric emitted radiance interferometer measurements.},
  archiveprefix = {arXiv},
  eprint = {2008.01889},
  eprinttype = {arxiv},
  file = {/Users/hyan46/Zotero/storage/RIRQ3RAR/Harris et al. - 2021 - Scalable Multiple Changepoint Detection for Functi.pdf},
  keywords = {Statistics - Methodology},
  langid = {english},
  primaryclass = {stat}
}

@article{heDistancebased2018,
  title = {A Distance-Based Control Chart for Monitoring Multivariate Processes Using Support Vector Machines},
  author = {He, Shuguang and Jiang, Wei and Deng, Houtao},
  date = {2018-04},
  journaltitle = {Annals of Operations Research},
  shortjournal = {Ann Oper Res},
  volume = {263},
  pages = {191--207},
  issn = {0254-5330, 1572-9338},
  doi = {10.1007/s10479-016-2186-4},
  url = {http://link.springer.com/10.1007/s10479-016-2186-4},
  urldate = {2020-07-04},
  abstract = {Traditional control charts assume a baseline parametric model, against which new observations are compared in order to identify significant departures from the baseline model. To monitor a process without a baseline model, real-time contrasts (RTC) control charts were recently proposed to monitor classification errors when seperarting new observations from limited phase I data using a binary classifier. In contrast to the RTC framework, the distance between an in-control dataset and a dataset of new observations can also be used to measure the shift of the process. In this paper, we propose a distance-based multivariate process control chart using support vector machines (SVM), referred to as D-SVM chart. The SVM classifier provides a continuous score or distance from the boundary for each observation and allows smaller sample sizes than the previously random forest based RTC charts. An extensive experimental study shows that the RTC charts with the SVM scores are more efficient than those with the random forest for detecting changes in high-dimensional processes and/or non-normal processes. A real-life example from a mobile phone assembly process is also considered.},
  file = {/Users/hyan46/Dropbox (ASU)/ZoteroData/He et al_2018_A distance-based control chart for monitoring multivariate processes using.pdf},
  keywords = {Application: Assembly,Application: Manufacturing,Method: Classification,People: Wei Jiang,Problem: Classification,Problem: Process Monitoring},
  langid = {english},
  number = {1-2}
}

@online{hintonDistilling2015,
  title = {Distilling the Knowledge in a Neural Network},
  author = {Hinton, Geoffrey and Vinyals, Oriol and Dean, Jeff},
  date = {2015},
  archiveprefix = {arXiv},
  eprint = {1503.02531},
  eprinttype = {arxiv},
  file = {/Users/hyan46/Dropbox (ASU)/ZoteroData/Hinton et al_2015_Distilling the knowledge in a neural network.pdf}
}

@article{hitchcockExpression1927,
  title = {The {{Expression}} of a {{Tensor}} or a {{Polyadic}} as a {{Sum}} of {{Products}}},
  author = {Hitchcock, Frank L.},
  date = {1927},
  journaltitle = {Journal of Mathematics and Physics},
  volume = {6},
  pages = {164--189},
  issn = {1467-9590},
  doi = {10.1002/sapm192761164},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/sapm192761164},
  urldate = {2021-02-26},
  annotation = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/sapm192761164},
  file = {/Users/hyan46/Zotero/storage/Y59Q7F72/sapm192761164.html},
  langid = {english},
  number = {1-4}
}

@article{hoffMULTILINEAR2015,
  title = {{{MULTILINEAR TENSOR REGRESSION FOR LONGITUDINAL RELATIONAL DATA}}},
  author = {Hoff, Peter D.},
  date = {2015-09},
  journaltitle = {The annals of applied statistics},
  shortjournal = {Ann Appl Stat},
  volume = {9},
  pages = {1169--1193},
  issn = {1932-6157},
  doi = {10.1214/15-AOAS839},
  url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4957660/},
  urldate = {2020-06-13},
  abstract = {A fundamental aspect of relational data, such as from a social network, is the possibility of dependence among the relations. In particular, the relations between members of one pair of nodes may have an effect on the relations between members of another pair. This article develops a type of regression model to estimate such effects in the context of longitudinal and multivariate relational data, or other data that can be represented in the form of a tensor. The model is based on a general multilinear tensor regression model, a special case of which is a tensor autoregression model in which the tensor of relations at one time point are parsimoniously regressed on relations from previous time points. This is done via a separable, or Kronecker-structured, regression parameter along with a separable covariance model. In the context of an analysis of longitudinal multivariate relational data, it is shown how the multilinear tensor regression model can represent patterns that often appear in relational and network data, such as reciprocity and transitivity.},
  eprint = {27458495},
  eprinttype = {pmid},
  file = {/Users/hyan46/Dropbox (ASU)/ZoteroData/Hoff_2015_MULTILINEAR TENSOR REGRESSION FOR LONGITUDINAL RELATIONAL DATA2.pdf},
  keywords = {Method: Tensor},
  number = {3},
  pmcid = {PMC4957660}
}

@article{hohleAdditiveMultiplicative2009,
  title = {Additive-{{Multiplicative Regression Models}} for {{Spatio}}-{{Temporal Epidemics}}},
  author = {Höhle, Michael},
  date = {2009},
  journaltitle = {Biometrical Journal},
  volume = {51},
  pages = {961--978},
  issn = {1521-4036},
  doi = {10.1002/bimj.200900050},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/bimj.200900050},
  urldate = {2020-08-07},
  abstract = {An extension of the stochastic susceptible–infectious–recovered (SIR) model is proposed in order to accommodate a regression context for modelling infectious disease data. The proposal is based on a multivariate counting process specified by conditional intensities, which contain an additive epidemic component and a multiplicative endemic component. This allows the analysis of endemic infectious diseases by quantifying risk factors for infection by external sources in addition to infective contacts. Inference can be performed by considering the full likelihood of the stochastic process with additional parameter restrictions to ensure non-negative conditional intensities. Simulation from the model can be performed by Ogata's modified thinning algorithm. As an illustrative example, we analyse data provided by the Federal Research Centre for Virus Diseases of Animals, Wusterhausen, Germany, on the incidence of the classical swine fever virus in Germany during 1993–2004.},
  annotation = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/bimj.200900050},
  file = {/Users/hyan46/Dropbox (ASU)/ZoteroData/Höhle_2009_Additive-Multiplicative Regression Models for Spatio-Temporal Epidemics.pdf;/Users/hyan46/Zotero/storage/MP5ZELGU/bimj.html},
  keywords = {Additive-multiplicative intensity,Classical swine fever virus,Constrained maximum likelihood,Stochastic epidemic modelling},
  langid = {english},
  number = {6}
}

@article{houOnline2016,
  title = {Online {{Steady State Detection Based}} on {{Rao}}-{{Blackwellized Sequential Monte Carlo}}: {{Online Steady State Detection}}},
  shorttitle = {Online {{Steady State Detection Based}} on {{Rao}}-{{Blackwellized Sequential Monte Carlo}}},
  author = {Hou, Yuxing and Wu, Jianguo and Chen, Yong},
  date = {2016-12},
  journaltitle = {Quality and Reliability Engineering International},
  shortjournal = {Qual. Reliab. Engng. Int.},
  volume = {32},
  pages = {2667--2683},
  issn = {07488017},
  doi = {10.1002/qre.2067},
  url = {http://doi.wiley.com/10.1002/qre.2067},
  urldate = {2020-07-04},
  file = {/Users/hyan46/Dropbox (ASU)/ZoteroData/Hou et al_2016_Online Steady State Detection Based on Rao-Blackwellized Sequential Monte Carlo.pdf},
  keywords = {Application: Manufacturing,Application: Nano,Method: Bayesian,Method: State Space,People: Chen Yong,Problem: Online Detection},
  langid = {english},
  number = {8}
}

@inproceedings{huang-etal-2018-zero,
  title = {Zero-Shot Transfer Learning for Event Extraction},
  booktitle = {Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 1: {{Long}} Papers)},
  author = {Huang, Lifu and Ji, Heng and Cho, Kyunghyun and Dagan, Ido and Riedel, Sebastian and Voss, Clare},
  date = {2018-07},
  pages = {2160--2170},
  publisher = {{Association for Computational Linguistics}},
  location = {{Melbourne, Australia}},
  doi = {10.18653/v1/P18-1201},
  url = {https://www.aclweb.org/anthology/P18-1201},
  abstract = {Most previous supervised event extraction methods have relied on features derived from manual annotations, and thus cannot be applied to new event types without extra annotation effort. We take a fresh look at event extraction and model it as a generic grounding problem: mapping each event mention to a specific type in a target event ontology. We design a transferable architecture of structural and compositional neural networks to jointly represent and map event mentions and types into a shared semantic space. Based on this new framework, we can select, for each event mention, the event type which is semantically closest in this space as its type. By leveraging manual annotations available for a small set of existing event types, our framework can be applied to new unseen event types without additional manual annotations. When tested on 23 unseen event types, our zero-shot framework, without manual annotations, achieved performance comparable to a supervised model trained from 3,000 sentences annotated with 500 event mentions.},
  file = {/Users/hyan46/Dropbox (ASU)/ZoteroData/Huang et al_2018_Zero-shot transfer learning for event extraction.pdf}
}

@article{huangAnalytical2016,
  title = {An {{Analytical Foundation}} for {{Optimal Compensation}} of {{Three}}-{{Dimensional Shape Deformation}} in {{Additive Manufacturing}}},
  author = {Huang, Qiang},
  date = {2016-06-01},
  journaltitle = {Journal of Manufacturing Science and Engineering},
  volume = {138},
  pages = {061010},
  issn = {1087-1357, 1528-8935},
  doi = {10.1115/1.4032220},
  url = {https://asmedigitalcollection.asme.org/manufacturingscience/article/doi/10.1115/1.4032220/392464/An-Analytical-Foundation-for-Optimal-Compensation},
  urldate = {2020-07-04},
  abstract = {Additive manufacturing (AM) or three-dimensional (3D) printing is a promising technology that enables the direct fabrication of products with complex shapes without extra tooling and fixturing. However, control of 3D shape deformation in AM built products has been a challenging issue due to geometric complexity, product varieties, material phase changing and shrinkage, and interlayer bonding. One viable approach for accuracy control is through compensation of the product design to offset the geometric shape deformation. This work provides an analytical foundation to achieve optimal compensation for high-precision AM. We first present the optimal compensation policy or the optimal amount of compensation for two-dimensional (2D) shape deformation. By analyzing its optimality property, we propose the minimum area deviation (MAD) criterion to offset 2D shape deformation. This result is then generalized by establishing the minimum volume deviation (MVD) criterion and by deriving the optimal amount of compensation for 3D shape deformation. Furthermore, MAD and MVD criteria provide convenient quality measure or quality index for AM built products that facilitate online monitoring and feedback control of shape geometric accuracy.},
  file = {/Users/hyan46/Dropbox (ASU)/ZoteroData/Huang_2016_An Analytical Foundation for Optimal Compensation of Three-Dimensional Shape.pdf},
  keywords = {Application: Additive Manufacturing,Application: Manufacturing,People: Qiang Huang},
  langid = {english},
  number = {6}
}

@online{huangBidirectional2015,
  title = {Bidirectional {{LSTM}}-{{CRF Models}} for {{Sequence Tagging}}},
  author = {Huang, Zhiheng and Xu, Wei and Yu, Kai},
  date = {2015-08-09},
  url = {http://arxiv.org/abs/1508.01991},
  urldate = {2021-02-24},
  abstract = {In this paper, we propose a variety of Long Short-Term Memory (LSTM) based models for sequence tagging. These models include LSTM networks, bidirectional LSTM (BI-LSTM) networks, LSTM with a Conditional Random Field (CRF) layer (LSTM-CRF) and bidirectional LSTM with a CRF layer (BI-LSTM-CRF). Our work is the first to apply a bidirectional LSTM CRF (denoted as BI-LSTM-CRF) model to NLP benchmark sequence tagging data sets. We show that the BI-LSTM-CRF model can efficiently use both past and future input features thanks to a bidirectional LSTM component. It can also use sentence level tag information thanks to a CRF layer. The BI-LSTM-CRF model can produce state of the art (or close to) accuracy on POS, chunking and NER data sets. In addition, it is robust and has less dependence on word embedding as compared to previous observations.},
  archiveprefix = {arXiv},
  eprint = {1508.01991},
  eprinttype = {arxiv},
  file = {/Users/hyan46/Zotero/storage/5B6R4NP8/Huang et al. - 2015 - Bidirectional LSTM-CRF Models for Sequence Tagging.pdf;/Users/hyan46/Zotero/storage/9MQRSYNM/1508.html},
  keywords = {Computer Science - Computation and Language},
  primaryclass = {cs}
}

@inproceedings{huangEdge2021,
  title = {Edge {{Computing Accelerated Defect Classification Based}} on {{Deep Convolutional Neural Network With Application}} in {{Rolling Image Inspection}}},
  author = {Huang, Jiayu and Sergin, Nurretin and Dua, Akshay and Tavakoli, Erfan Bank and Yan, Hao and Ren, Fengbo and Ju, Feng},
  date = {2021-01-15},
  publisher = {{American Society of Mechanical Engineers Digital Collection}},
  doi = {10.1115/MSEC2020-8261},
  url = {https://asmedigitalcollection.asme.org/MSEC/proceedings/MSEC2020/84263/V002T07A037/1095749},
  urldate = {2021-01-27},
  abstract = {This paper develops a unified framework for training and deploying deep neural networks on the edge computing framework for image defect detection and classification. In the proposed framework, we combine the transfer learning and data augmentation with the improved accuracy given the small sample size. We further implement the edge computing framework to satisfy the real-time computational requirement. After the implement of the proposed model into a rolling manufacturing system, we conclude that deep learning approaches can perform around 30–40\% better than some traditional machine learning algorithms such as random forest, decision tree, and SVM in terms of prediction accuracy. Furthermore, by deploying the CNNs in the edge computing framework, we can significantly reduce the computational time and satisfy the real-time computational requirement in the high-speed rolling and inspection system. Finally, the saliency map and embedding layer visualization techniques are used for a better understanding of proposed deep learning models.},
  eventtitle = {{{ASME}} 2020 15th {{International Manufacturing Science}} and {{Engineering Conference}}},
  keywords = {Application: Manufacturing,Data: Image,Method: Deep Learning,Problem: Classification},
  langid = {english}
}

@article{huangGeometric2020,
  title = {Geometric {{Deep Learning}} for {{Shape Correspondence}} in {{Mass Customization}} by {{Three}}-{{Dimensional Printing}}},
  author = {Huang, Jida and Sun, Hongyue and Kwok, Tsz-Ho and Zhou, Chi and Xu, Wenyao},
  date = {2020-06-01},
  journaltitle = {Journal of Manufacturing Science and Engineering},
  volume = {142},
  pages = {061003},
  issn = {1087-1357, 1528-8935},
  doi = {10.1115/1.4046746},
  url = {https://asmedigitalcollection.asme.org/manufacturingscience/article/doi/10.1115/1.4046746/1081979/Geometric-Deep-Learning-for-Shape-Correspondence},
  urldate = {2020-07-21},
  abstract = {Abstract             Many industries, such as human-centric product manufacturing, are calling for mass customization with personalized products. One key enabler of mass customization is 3D printing, which makes flexible design and manufacturing possible. However, the personalized designs bring challenges for the shape matching and analysis, owing to the high complexity and shape variations. Traditional shape matching methods are limited to spatial alignment and finding a transformation matrix for two shapes, which cannot determine a vertex-to-vertex or feature-to-feature correlation between the two shapes. Hence, such a method cannot measure the deformation of the shape and interested features directly. To measure the deformations widely seen in the mass customization paradigm and address the issues of alignment methods in shape matching, we identify the geometry matching of deformed shapes as a correspondence problem. The problem is challenging due to the huge solution space and nonlinear complexity, which is difficult for conventional optimization methods to solve. According to the observation that the well-established massive databases provide the correspondence results of the treated teeth models, a learning-based method is proposed for the shape correspondence problem. Specifically, a state-of-the-art geometric deep learning method is used to learn the correspondence of a set of collected deformed shapes. Through learning the deformations of the models, the underlying variations of the shapes are extracted and used for finding the vertex-to-vertex mapping among these shapes. We demonstrate the application of the proposed approach in the orthodontics industry, and the experimental results show that the proposed method can predict correspondence fast and accurate, also robust to extreme cases. Furthermore, the proposed method is favorably suitable for deformed shape analysis in mass customization enabled by 3D printing.},
  file = {/Users/hyan46/Dropbox (ASU)/ZoteroData/Huang et al_2020_Geometric Deep Learning for Shape Correspondence in Mass Customization by.pdf},
  keywords = {Method: Deep Learning},
  langid = {english},
  number = {6}
}

@article{huangOptimal2015,
  title = {Optimal Offline Compensation of Shape Shrinkage for Three-Dimensional Printing Processes},
  author = {Huang, Qiang and Zhang, Jizhe and Sabbaghi, Arman and Dasgupta, Tirthankar},
  date = {2015-05-04},
  journaltitle = {IIE Transactions},
  shortjournal = {IIE Transactions},
  volume = {47},
  pages = {431--441},
  issn = {0740-817X, 1545-8830},
  doi = {10.1080/0740817X.2014.955599},
  url = {http://www.tandfonline.com/doi/abs/10.1080/0740817X.2014.955599},
  urldate = {2020-07-04},
  abstract = {Dimensional accuracy is a key control issue in direct three-dimensional (3D) printing. Part shrinkage due to material phase changes often leads to deviations in the final shape, requiring extra post-machining steps for correction. Shrinkage has traditionally been analyzed through finite element simulation and experimental investigations. Systematic models for accuracy control through shrinkage compensation are rarely available, particularly for complete control of all local features. To fill the gap for direct printing and compensate for shape shrinkage, this article develops a new approach to (i) model and predict part shrinkage and (ii) derive an optimal shrinkage compensation plan to achieve dimensional accuracy. The developed approach is demonstrated both analytically and experimentally in a stereolithography process, one of the most widely employed 3D printing techniques. Experimental results demonstrate the ability of the proposed compensation approach to achieve an improvement of an order of magnitude in the reduction of geometric errors for cylindrical products.},
  file = {/Users/hyan46/Dropbox (ASU)/ZoteroData/Huang et al_2015_Optimal offline compensation of shape shrinkage for three-dimensional printing.pdf},
  keywords = {People: Qiang Huang},
  langid = {english},
  number = {5}
}

@article{huangPhysicsdriven2010,
  title = {Physics-Driven {{Bayesian}} Hierarchical Modeling of the Nanowire Growth Process at Each Scale},
  author = {Huang, Qiang},
  date = {2010-10-29},
  journaltitle = {IIE Transactions},
  shortjournal = {IIE Transactions},
  volume = {43},
  pages = {1--11},
  issn = {0740-817X, 1545-8830},
  doi = {10.1080/07408171003795335},
  url = {http://www.tandfonline.com/doi/abs/10.1080/07408171003795335},
  urldate = {2020-07-04},
  abstract = {Despite significant advances in nanoscience, current physical models are unable to predict nanomanufacturing processes under uncertainties. This research work aims to model the nanowire (NW) growth process at any scale of interest. The main idea is to integrate available data and physical knowledge through a Bayesian hierarchical framework with consideration of scale effects. At each scale the NW growth model describes the time–space evolution of NWs at different sites on a substrate. The model consists of two major components: NW morphology and local variability. The morphology component represents the overall trend characterized by growth kinetics. The area-specific variability is less understood in nanophysics due to complex interactions among neighboring NWs. The local variability is therefore modeled by an intrinsic Gaussian Markov random field to separate it from the growth kinetics in the morphology component. Case studies are provided to illustrate the NW growth process model at coarse and fine scales, respectively.},
  file = {/Users/hyan46/Dropbox (ASU)/ZoteroData/Huang_2010_Physics-driven Bayesian hierarchical modeling of the nanowire growth process at.pdf},
  keywords = {Application: Manufacturing,Application: Nano,Method: Bayesian,Method: Physics,People: Qiang Huang},
  langid = {english},
  number = {1}
}

@article{huangShape2020,
  title = {Shape {{Deviation Generator}}--{{A Convolution Framework}} for {{Learning}} and {{Predicting}} 3-{{D Printing Shape Accuracy}}},
  author = {Huang, Qiang and Wang, Yuanxiang and Lyu, Mingdong and Lin, Weizhi},
  date = {2020},
  journaltitle = {IEEE Transactions on Automation Science and Engineering},
  shortjournal = {IEEE Trans. Automat. Sci. Eng.},
  pages = {1--15},
  issn = {1545-5955, 1558-3783},
  doi = {10.1109/TASE.2019.2959211},
  url = {https://ieeexplore.ieee.org/document/8957379/},
  urldate = {2020-07-04},
  abstract = {The 3-D shape accuracy is a critical performance measure for products built via additive manufacturing (AM). With advances in computing and increased accessibility of AM product data, machine learning for AM (ML4AM) has become a viable strategy for enhancing 3-D printing performance. A proper description of the 3-D shape formation through the layer-by-layer fabrication process is critical to ML4AM, such as feature selection and AM process modeling. The physics-based modeling and simulation approaches present voxel-level description of an object formation from points to lines, lines to surfaces, and surfaces to 3-D shapes. However, this computationally intensive modeling framework does not provide a clear structure for machine learning of AM data. Significant progress has been made to model and predict the shape accuracy of planar objects under data analytical frameworks. In order to predict, learn, and compensate for 3-D shape deviations using shape measurement data, we propose a shape deviation generator (SDG) under a novel convolution formulation to facilitate the learning and prediction of 3-D printing accuracy. The shape deviation representation, individual layer input function, and layer-to-layer transfer function for the convolution modeling framework are proposed and derived. A deconvolution problem for identifying the transfer function is formulated to capture the interlayer interaction and error accumulation effects in the layer-by-layer fabrication processes. Physics-informed sequential model estimation is developed to fully establish the SDG models. The Gaussian process regression is adopted to capture spatial correlations. The printed 2-D and 3-D shapes via a stereolithography (SLA) process are used to demonstrate the proposed modeling framework and derive new process insights for AM processes.},
  file = {/Users/hyan46/Dropbox (ASU)/ZoteroData/Huang et al_2020_Shape Deviation Generator--A Convolution Framework for Learning and Predicting.pdf},
  keywords = {Application: Additive Manufacturing,Application: Manufacturing,Application: Surface Scanning,People: Qiang Huang},
  langid = {english}
}

@article{huangSparse2013,
  title = {A {{Sparse Structure Learning Algorithm}} for {{Gaussian Bayesian Network Identification}} from {{High}}-{{Dimensional Data}}},
  author = {Huang, Shuai and Li, Jing and Ye, Jieping and Fleisher, Adam and Chen, Kewei and Wu, Teresa and Reiman, Eric},
  date = {2013-06},
  journaltitle = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
  shortjournal = {IEEE Trans. Pattern Anal. Mach. Intell.},
  volume = {35},
  pages = {1328--1342},
  issn = {0162-8828, 2160-9292},
  doi = {10.1109/TPAMI.2012.129},
  url = {http://ieeexplore.ieee.org/document/6212515/},
  urldate = {2020-07-20},
  abstract = {Structure learning of Bayesian Networks (BNs) is an important topic in machine learning. Driven by modern applications in genetics and brain sciences, accurate and efficient learning of large-scale BN structures from high-dimensional data becomes a challenging problem. To tackle this challenge, we propose a Sparse Bayesian Network (SBN) structure learning algorithm that employs a novel formulation involving one L1-norm penalty term to impose sparsity and another penalty term to ensure that the learned BN is a Directed Acyclic Graph (DAG)—a required property of BNs. Through both theoretical analysis and extensive experiments on 11 moderate and large benchmark networks with various sample sizes, we show that SBN leads to improved learning accuracy, scalability, and efficiency as compared with 10 existing popular BN learning algorithms. We apply SBN to a real-world application of brain connectivity modeling for Alzheimer’s disease (AD) and reveal findings that could lead to advancements in AD research.},
  file = {/Users/hyan46/Dropbox (ASU)/ZoteroData/Huang et al_2013_A Sparse Structure Learning Algorithm for Gaussian Bayesian Network.pdf},
  keywords = {Application: Health,Method: Bayesian,Method: Causal,Method: Sparse},
  langid = {english},
  number = {6}
}

@article{huangStatistical2011,
  title = {Statistical {{Weight Kinetics Modeling}} and {{Estimation}} for {{Silica Nanowire Growth Catalyzed}} by {{Pd Thin Film}}},
  author = {Huang, Qiang and Wang, Li and Dasgupta, Tirthankar and Zhu, Li and Sekhar, Praveen K. and Bhansali, Shekhar and An, Yu},
  date = {2011-04},
  journaltitle = {IEEE Transactions on Automation Science and Engineering},
  shortjournal = {IEEE Trans. Automat. Sci. Eng.},
  volume = {8},
  pages = {303--310},
  issn = {1545-5955, 1558-3783},
  doi = {10.1109/TASE.2010.2070493},
  url = {http://ieeexplore.ieee.org/document/5580014/},
  urldate = {2020-07-04},
  abstract = {This work intends to understand and model the kinetic aspect or the change of substrate weight over time in the selective growth of silica nanowires (NWs) catalyzed through Pd thin film. Various adsorption-induced, diffusion-induced, or unified vapor-liquid-solid (VLS) growth models have been developed to describe the NW length varying with time. Since NW length has been difficult to be measured, substrate weight change is therefore used as an alternative in this study to investigate growth kinetics of NWs. We investigate six different weight kinetics models in predicting weight changes during growth. Model estimation and comparison are conducted using both maximum-likelihood estimation (MLE) and Bayesian approaches. Owing to the embedded kinetics information in the nonlinear growth models, the Bayesian hierarchical model is shown to be more desirable when process data is limited.},
  file = {/Users/hyan46/Dropbox (ASU)/ZoteroData/Huang et al_2011_Statistical Weight Kinetics Modeling and Estimation for Silica Nanowire Growth.pdf},
  keywords = {Application: Manufacturing,Application: Nano,Method: Physics,People: Qiang Huang},
  langid = {english},
  number = {2}
}

@article{huangStatistical2014,
  title = {Statistical {{Predictive Modeling}} and {{Compensation}} of {{Geometric Deviations}} of {{Three}}-{{Dimensional Printed Products}}},
  author = {Huang, Qiang and Nouri, Hadis and Xu, Kai and Chen, Yong and Sosina, Sobambo and Dasgupta, Tirthankar},
  date = {2014-12-01},
  journaltitle = {Journal of Manufacturing Science and Engineering},
  volume = {136},
  pages = {061008},
  issn = {1087-1357, 1528-8935},
  doi = {10.1115/1.4028510},
  url = {https://asmedigitalcollection.asme.org/manufacturingscience/article/doi/10.1115/1.4028510/377617/Statistical-Predictive-Modeling-and-Compensation},
  urldate = {2020-07-04},
  abstract = {Geometric fidelity of 3D printed products is critical for additive manufacturing (AM) to be a direct manufacturing technology. Shape deviations of AM built products can be attributed to multiple variation sources such as substrate geometry defect, disturbance in process variables, and material phase change. Three strategies have been reported to improve geometric quality in AM: (1) control process variables x based on the observed disturbance of process variables Δx, (2) control process variables x based on the observed product deviation Δy, and (3) control input product geometry y based on the observed product deviation Δy. This study adopts the third strategy which changes the computer-aided design (CAD) design by optimally compensating the product deviations. To accomplish the goal, a predictive model is desirable to forecast the quality of a wide class of product shapes, particularly considering the vast library of AM built products with complex geometry. Built upon our previous optimal compensation study of cylindrical products, this work aims at a novel statistical predictive modeling and compensation approach to predict and improve the quality of both cylindrical and prismatic parts. Experimental investigation and validation of polyhedrons a indicates the promise of predicting and compensating a wide class of products built through 3D printing technology.},
  file = {/Users/hyan46/Dropbox (ASU)/ZoteroData/Huang et al_2014_Statistical Predictive Modeling and Compensation of Geometric Deviations of.pdf},
  keywords = {Application: Additive Manufacturing,Application: Manufacturing,People: Qiang Huang},
  langid = {english},
  number = {6}
}

@article{huangTransfer2012,
  title = {A Transfer Learning Approach for Network Modeling},
  author = {Huang, Shuai and Li, Jing and Chen, Kewei and Wu, Teresa and Ye, Jieping and Wu, Xia and Yao, Li},
  date = {2012-11},
  journaltitle = {IIE Transactions},
  shortjournal = {IIE Transactions},
  volume = {44},
  pages = {915--931},
  issn = {0740-817X, 1545-8830},
  doi = {10.1080/0740817X.2011.649390},
  url = {https://www.tandfonline.com/doi/full/10.1080/0740817X.2011.649390},
  urldate = {2020-07-20},
  abstract = {Networks models have been widely used in many domains to characterize the interacting relationship between physical entities. A typical problem faced is to identify the networks of multiple related tasks that share some similarities. In this case, a transfer learning approach that can leverage the knowledge gained during the modeling of one task to help better model another task is highly desirable. In this paper, we propose a transfer learning approach, which adopts a Bayesian hierarchical model framework to characterize task relatedness and additionally uses the L1-regularization to ensure robust learning of the networks with limited sample sizes. A method based on the Expectation-Maximization (EM) algorithm is further developed to learn the networks from data. Simulation studies are performed, which demonstrate the superiority of the proposed transfer learning approach over single task learning that learns the network of each task in isolation. The proposed approach is also applied to identification of brain connectivity networks of Alzheimer’s disease (AD) from functional magnetic resonance image (fMRI) data. The findings are consistent with the AD literature.},
  file = {/Users/hyan46/Dropbox (ASU)/ZoteroData/Huang et al_2012_A transfer learning approach for network modeling.pdf},
  keywords = {Application: Health,Data: Network,Method: Sparse,Method: Transfer Learning},
  langid = {english},
  number = {11}
}

@article{huDeep,
  title = {Deep {{Generative Models}} with {{Learnable Knowledge Constraints}}},
  author = {Hu, Zhiting and Yang, Zichao and Salakhutdinov, Russ R and Qin, LIANHUI and Liang, Xiaodan and Dong, Haoye and Xing, Eric P},
  pages = {12},
  abstract = {The broad set of deep generative models (DGMs) has achieved remarkable advances. However, it is often difficult to incorporate rich structured domain knowledge with the end-to-end DGMs. Posterior regularization (PR) offers a principled framework to impose structured constraints on probabilistic models, but has limited applicability to the diverse DGMs that can lack a Bayesian formulation or even explicit density evaluation. PR also requires constraints to be fully specified a priori, which is impractical or suboptimal for complex knowledge with learnable uncertain parts. In this paper, we establish mathematical correspondence between PR and reinforcement learning (RL), and, based on the connection, expand PR to learn constraints as the extrinsic reward in RL. The resulting algorithm is modelagnostic to apply to any DGMs, and is flexible to adapt arbitrary constraints with the model jointly. Experiments on human image generation and templated sentence generation show models with learned knowledge constraints by our algorithm greatly improve over base generative models.},
  file = {/Users/hyan46/Zotero/storage/NLZWBQAZ/Hu et al. - Deep Generative Models with Learnable Knowledge Co.pdf},
  langid = {english}
}

@article{huPrivacyPreserving2020,
  title = {Privacy-{{Preserving Data Mining}} for {{Smart Manufacturing}}},
  author = {Hu, Qianyu and Chen, Ruimin and Yang, Hui and Kumara, Soundar},
  date = {2020-02-01},
  journaltitle = {Smart and Sustainable Manufacturing Systems},
  shortjournal = {Smart Sustain. Manuf. Syst.},
  volume = {4},
  pages = {20190043},
  issn = {25206478},
  doi = {10.1520/SSMS20190043},
  url = {http://www.astm.org/doiLink.cgi?SSMS20190043},
  urldate = {2020-07-07},
  abstract = {Internet of Things (IoT) and data mining techniques have laid the foundation for the next generation of smart and secure manufacturing systems where big data are leveraged to extract useful information about the manufacturing processes and further help optimize decisions. The threat of data breach exists especially for nonpersonal, yet sensitive data, which are pertinent to every aspect of manufacturing. Data breach and privacy leakages can significantly impede the manufacturer’s business and lead to damaging a company’s reputation. With a comprehensive case study in the manufacturing setting, we show that adversaries can utilize accessible shop floor predictive models and other available background information to make inferences about sensitive attributes that were used as inputs to the original model and use that information for their own purposes. From this view, this article presents a privacy-preserving data mining framework to build a smart and secure manufacturing system. First, we introduce differential privacy (DP), an emerging approach to preserve the individual’s privacy in the data mining process. Second, we present a privacy-preserving system where DP mechanisms and queries are enforced to obtain differentially private results. Third, we propose to optimize the selection of DP mechanisms and privacy parameters by balancing the model utility and the robustness to attack. Further, we evaluate and validate the proposed privacy-preserving data mining framework with a realworld case study on the modeling of cutting power consumption in computer numerical control turning processes. Experimental results show that the performance gain, i.e., the trade-off between model utility and the robustness to attack, is improved from the nonprivate model by 5.6, 9.4, and 13.1 \% for privacy-preserving Laplace, Gaussian, and sensitive mechanisms, respectively. This article is among the first to investigate and present a privacy-preserving data mining framework for smart manufacturing. The proposed methodology shows great potential to be generally applicable in industry for data-enabled smart and sustainable manufacturing.},
  file = {/Users/hyan46/Dropbox (ASU)/ZoteroData/Hu et al_2020_Privacy-Preserving Data Mining for Smart Manufacturing.pdf},
  langid = {english},
  number = {2}
}

@incollection{huTextual2019,
  title = {Textual {{Indicator Extraction}} from {{Aviation Accident Reports}}},
  booktitle = {{{AIAA Aviation}} 2019 {{Forum}}},
  author = {Hu, Xue and Wu, Jun and He, Jingrui},
  date = {2019-06-14},
  publisher = {{American Institute of Aeronautics and Astronautics}},
  doi = {10.2514/6.2019-2939},
  url = {https://arc.aiaa.org/doi/10.2514/6.2019-2939},
  urldate = {2021-02-24},
  file = {/Users/hyan46/Zotero/storage/GWXGI9FD/6.html},
  series = {{{AIAA AVIATION Forum}}},
  volumes = {0}
}

@book{hutterAutomated2019,
  title = {Automated {{Machine Learning}}: {{Methods}}, {{Systems}}, {{Challenges}}},
  shorttitle = {Automated {{Machine Learning}}},
  editor = {Hutter, Frank and Kotthoff, Lars and Vanschoren, Joaquin},
  date = {2019},
  publisher = {{Springer International Publishing}},
  location = {{Cham}},
  doi = {10.1007/978-3-030-05318-5},
  url = {http://link.springer.com/10.1007/978-3-030-05318-5},
  urldate = {2020-09-09},
  file = {/Users/hyan46/Dropbox (ASU)/ZoteroData/Hutter et al_2019_Automated Machine Learning.pdf},
  isbn = {978-3-030-05317-8 978-3-030-05318-5},
  langid = {english},
  series = {The {{Springer Series}} on {{Challenges}} in {{Machine Learning}}}
}

@inproceedings{huynhShared2020,
  title = {A {{Shared Multi}}-{{Attention Framework}} for {{Multi}}-{{Label Zero}}-{{Shot Learning}}},
  booktitle = {2020 {{IEEE}}/{{CVF Conference}} on {{Computer Vision}} and {{Pattern Recognition}} ({{CVPR}})},
  author = {Huynh, Dat and Elhamifar, Ehsan},
  date = {2020-06},
  pages = {8773--8783},
  publisher = {{IEEE}},
  location = {{Seattle, WA, USA}},
  doi = {10.1109/CVPR42600.2020.00880},
  url = {https://ieeexplore.ieee.org/document/9157745/},
  urldate = {2021-06-04},
  abstract = {In this work, we develop a shared multi-attention model for multi-label zero-shot learning. We argue that designing attention mechanism for recognizing multiple seen and unseen labels in an image is a non-trivial task as there is no training signal to localize unseen labels and an image only contains a few present labels that need attentions out of thousands of possible labels. Therefore, instead of generating attentions for unseen labels which have unknown behaviors and could focus on irrelevant regions due to the lack of any training sample, we let the unseen labels select among a set of shared attentions which are trained to be label-agnostic and to focus on only relevant/foreground regions through our novel loss. Finally, we learn a compatibility function to distinguish labels based on the selected attention. We further propose a novel loss function that consists of three components guiding the attention to focus on diverse and relevant image regions while utilizing all attention features. By extensive experiments, we show that our method improves the state of the art by 2.9\% and 1.4\% F1 score on the NUS-WIDE and the large scale Open Images datasets, respectively.},
  eventtitle = {2020 {{IEEE}}/{{CVF Conference}} on {{Computer Vision}} and {{Pattern Recognition}} ({{CVPR}})},
  file = {/Users/hyan46/Dropbox (ASU)/ZoteroData/Huynh_Elhamifar_2020_A Shared Multi-Attention Framework for Multi-Label Zero-Shot Learning.pdf},
  isbn = {978-1-72817-168-5},
  langid = {english}
}

@article{hwangboSpline2018,
  title = {Spline Model for Wake Effect Analysis: {{Characteristics}} of a Single Wake and Its Impacts on Wind Turbine Power Generation},
  shorttitle = {Spline Model for Wake Effect Analysis},
  author = {Hwangbo, Hoon and Johnson, Andrew L. and Ding, Yu},
  date = {2018-02},
  journaltitle = {IISE Transactions},
  shortjournal = {IISE Transactions},
  volume = {50},
  pages = {112--125},
  issn = {2472-5854, 2472-5862},
  doi = {10.1080/24725854.2017.1370176},
  url = {https://www.tandfonline.com/doi/full/10.1080/24725854.2017.1370176},
  urldate = {2020-07-04},
  file = {/Users/hyan46/Dropbox (ASU)/ZoteroData/Hwangbo et al_2018_Spline model for wake effect analysis.pdf},
  keywords = {Application: Wind Turbine,Method: Functional,Method: Regularization,Method: Spline,People: Yu Ding},
  langid = {english},
  number = {2}
}

@online{Illustrated,
  title = {The {{Illustrated Transformer}} – {{Jay Alammar}} – {{Visualizing}} Machine Learning One Concept at a Time.},
  url = {http://jalammar.github.io/illustrated-transformer/},
  urldate = {2020-07-10},
  file = {/Users/hyan46/Zotero/storage/LN9RQD5J/illustrated-transformer.html}
}

@article{imaniDeep2019,
  title = {Deep {{Learning}} of {{Variant Geometry}} in {{Layerwise Imaging Profiles}} for {{Additive Manufacturing Quality Control}}},
  author = {Imani, Farhad and Chen, Ruimin and Diewald, Evan and Reutzel, Edward and Yang, Hui},
  date = {2019-11-01},
  journaltitle = {Journal of Manufacturing Science and Engineering},
  volume = {141},
  pages = {111001},
  issn = {1087-1357, 1528-8935},
  doi = {10.1115/1.4044420},
  url = {https://asmedigitalcollection.asme.org/manufacturingscience/article/doi/10.1115/1.4044420/956249/Deep-Learning-of-Variant-Geometry-in-Layerwise},
  urldate = {2020-07-07},
  abstract = {Abstract             Additive manufacturing (AM) is a new paradigm in design-driven build of customized products. Nonetheless, mass customization and low-volume production make the AM quality assurance extremely challenging. Advanced imaging provides an unprecedented opportunity to increase information visibility, cope with the product complexity, and enable on-the-fly quality control in AM. However, in situ images of a customized AM build show a high level of layer-to-layer geometry variation, which hampers the use of powerful image-based learning methods such as deep neural networks (DNNs) for flaw detection. Very little has been done on deep learning of variant geometry for image-guided process monitoring and control. The proposed research is aimed at filling this gap by developing a novel machine learning approach that is focused on variant geometry in each layer of the AM build, namely region of interests, for the characterization and detection of layerwise flaws. Specifically, we leverage the computer-aided design (CAD) file to perform shape-to-image registration and to delineate the regions of interest in layerwise images. Next, a hierarchical dyadic partitioning methodology is developed to split layer-to-layer regions of interest into subregions with the same number of pixels to provide freeform geometry analysis. Then, we propose a semiparametric model to characterize the complex spatial patterns in each customized subregion and boost the computational speed. Finally, a DNN model is designed to learn variant geometry in layerwise imaging profiles and detect fine-grained information of flaws. Experimental results show that the proposed deep learning methodology is highly effective to detect flaws in each layer with an accuracy of 92.50 ± 1.03\%. This provides a significant opportunity to reduce interlayer variation in AM prior to completion of a build. The proposed methodology can also be generally applicable in a variety of engineering and medical domains that entail customized design, variant geometry, and image-guided process control.},
  file = {/Users/hyan46/Dropbox (ASU)/ZoteroData/Imani et al_2019_Deep Learning of Variant Geometry in Layerwise Imaging Profiles for Additive.pdf},
  langid = {english},
  number = {11}
}

@article{imaniJoint2019,
  title = {Joint {{Multifractal}} and {{Lacunarity Analysis}} of {{Image Profiles}} for {{Manufacturing Quality Control}}},
  author = {Imani, Farhad and Yao, Bing and Chen, Ruimin and Rao, Prahalad and Yang, Hui},
  date = {2019-04-01},
  journaltitle = {Journal of Manufacturing Science and Engineering},
  volume = {141},
  pages = {044501},
  issn = {1087-1357, 1528-8935},
  doi = {10.1115/1.4042579},
  url = {https://asmedigitalcollection.asme.org/manufacturingscience/article/doi/10.1115/1.4042579/474922/Joint-Multifractal-and-Lacunarity-Analysis-of},
  urldate = {2020-07-07},
  abstract = {The modern manufacturing industry faces increasing demands to customize products according to personal needs, thereby leading to the proliferation of complex designs. To cope with design complexity, manufacturing systems are increasingly equipped with advanced sensing and imaging capabilities. However, traditional statistical process control methods are not concerned with the stream of in-process imaging data. Also, very little has been done to investigate nonlinearity, irregularity, and inhomogeneity in the image stream collected from manufacturing processes. This paper presents the joint multifractal and lacunarity analysis to characterize irregular and inhomogeneous patterns of image profiles, as well as detect the hidden dynamics in the manufacturing process. Experimental studies show that the proposed method not only effectively characterizes surface finishes for quality control of ultraprecision machining but also provides an effective model to link process parameters with fractal characteristics of in-process images acquired from additive manufacturing. This, in turn, will allow a swift response to processes changes and consequently reduce the number of defective products. The proposed multifractal method shows strong potentials to be applied for process monitoring and control in a variety of domains such as ultraprecision machining and additive manufacturing.},
  file = {/Users/hyan46/Dropbox (ASU)/ZoteroData/Imani et al_2019_Joint Multifractal and Lacunarity Analysis of Image Profiles for Manufacturing.pdf},
  langid = {english},
  number = {4}
}

@article{imaniProcess2018,
  title = {Process {{Mapping}} and {{In}}-{{Process Monitoring}} of {{Porosity}} in {{Laser Powder Bed Fusion Using Layerwise Optical Imaging}}},
  author = {Imani, Farhad and Gaikwad, Aniruddha and Montazeri, Mohammad and Rao, Prahalada and Yang, Hui and Reutzel, Edward},
  date = {2018-10-01},
  journaltitle = {Journal of Manufacturing Science and Engineering},
  volume = {140},
  pages = {101009},
  issn = {1087-1357, 1528-8935},
  doi = {10.1115/1.4040615},
  url = {https://asmedigitalcollection.asme.org/manufacturingscience/article/doi/10.1115/1.4040615/366215/Process-Mapping-and-InProcess-Monitoring-of},
  urldate = {2020-07-07},
  abstract = {The goal of this work is to understand the effect of process conditions on lack of fusion porosity in parts made using laser powder bed fusion (LPBF) additive manufacturing (AM) process, and subsequently, to detect the onset of process conditions that lead to lack of fusion-related porosity from in-process sensor data. In pursuit of this goal, the objectives of this work are twofold: (1) quantify the count (number), size and location of pores as a function of three LPBF process parameters, namely, the hatch spacing (H), laser velocity (V), and laser power (P); and (2) monitor and identify process conditions that are liable to cause porosity through analysis of in-process layer-by-layer optical images of the build invoking multifractal and spectral graph theoretic features. These objectives are important because porosity has a significant impact on the functional integrity of LPBF parts, such as fatigue life. Furthermore, linking process conditions to defects via sensor signatures is the first step toward in-process quality assurance in LPBF. To achieve the first objective, titanium alloy (Ti–6Al–4V) test cylinders of 10\,mm diameter\,×\,25\,mm height were built under differing H, V, and P settings on a commercial LPBF machine (EOS M280). The effect of these process parameters on count, size, and location of pores was quantified based on X-ray computed tomography (XCT) images. To achieve the second objective, layerwise optical images of the powder bed were acquired as the parts were being built. Spectral graph theoretic and multifractal features were extracted from the layer-by-layer images for each test part. Subsequently, these features were linked to the process parameters using machine learning approaches. Through these image-based features, process conditions under which the parts were built were identified with the statistical fidelity over 80\% (F-score).},
  file = {/Users/hyan46/Dropbox (ASU)/ZoteroData/Imani et al_2018_Process Mapping and In-Process Monitoring of Porosity in Laser Powder Bed.pdf},
  langid = {english},
  number = {10}
}

@article{Iquebal:2014eu,
  title = {Enhancement of {{Mahalanobis}}–{{Taguchi}} System via Rough Sets Based Feature Selection},
  author = {Iquebal, Ashif Sikandar and Pal, Avishek and Ceglarek, Dariusz and Tiwari, Manoj Kumar},
  date = {2014-12},
  journaltitle = {Expert Systems with Applications},
  volume = {41},
  pages = {8003--8015},
  publisher = {{Pergamon}},
  doi = {10.1016/j.eswa.2014.06.019},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0957417414003601},
  abstract = {The current research presents a methodology for classification based on Mahalanobis Distance (MD) and Association Mining using Rough Sets Theory (RST)…},
  date-added = {2020-07-03T22:28:21GMT},
  date-modified = {2020-07-04T00:26:51GMT},
  file = {/Users/hyan46/Dropbox (ASU)/ZoteroData/Iquebal et al_2014_Enhancement of Mahalanobis–Taguchi system via rough sets based feature selection2.pdf},
  keywords = {Application: Health,Application: Social,Method: Classification,People: Cerek,Problem: Classification},
  langid = {english},
  number = {17},
  rating = {0},
  uri = {papers3://publication/doi/10.1016/j.eswa.2014.06.019}
}

@article{iquebalLearning2020,
  title = {Learning Acoustic Emission Signatures from a Nanoindentation-Based Lithography Process: {{Towards}} Rapid Microstructure Characterization},
  author = {Iquebal, Ashif Sikandar and Pandagare, Shirish and Bukkapatnam, Satish},
  date = {2020},
  journaltitle = {Tribology International},
  volume = {143},
  pages = {106074},
  issn = {0301-679X}
}

@article{iquebalRapid2020,
  title = {Towards Rapid, in Situ Characterization for Materials-on-Demand Manufacturing},
  author = {Iquebal, Ashif Sikandar and Botcha, Bhaskar and Bukkapatnam, Satish},
  date = {2020},
  journaltitle = {Manufacturing Letters},
  volume = {23},
  pages = {29--33},
  issn = {2213-8463}
}

@article{iquebalSurface2019,
  title = {Surface Plastic Flow in Polishing of Rough Surfaces},
  author = {Iquebal, A. S. and Sagapuram, D. and Bukkapatnam, Satish},
  date = {2019-07-23},
  journaltitle = {Scientific Reports},
  shortjournal = {Sci Rep-Uk Sci Rep-Uk},
  volume = {9},
  issn = {2045-2322},
  url = {://WOS:000476718900004},
  abstract = {We present experimental evidence for a new mechanism for how smooth surfaces emerge during repetitive sliding contacts, as in polishing. Electron microscopy observations of Ti-6Al-4V surface with a spherical asperity structure-realized via additive manufacturing-during successive polishing stages suggest that asperity-abrasive contacts exhibit viscous behavior, where the asperity material flows in the form of thin (1-10 mu m) fluid-like layers. Subsequent bridging of these layers among neighboring asperities results in progressive surface smoothening. Using analytical asperity-abrasive contact temperature modeling and microstructural characterization, we show that the sliding contacts encounter flash temperatures of the order of 700-900 K which is in the range of the dynamic recrystallization temperature of the material considered, thus supporting the experimental observations. Besides providing a new perspective on the long-held mechanism of polishing, our observations provide a novel approach based on graph theory to quantitatively characterize the evolution of surface morphology. Results suggest that the graph representation offers a more efficient measure to characterize the surface morphology emerging at various stages of polishing. The research findings and observations are of broad relevance to the understanding of plastic flow behavior of sliding contacts ubiquitous in materials processing, tribology, and natural geological processes as well as present unique opportunities to tailor the microstructures by controlling the thermomechanics of the asperity-abrasive contacts.},
  keywords = {bands,contact,deformation},
  langid = {english}
}

@article{j.nagoorkaniReducedOrder2019,
  title = {Reduced-{{Order Modeling}} of {{Subsurface Multi}}-Phase {{Flow Models Using Deep Residual Recurrent Neural Networks}}},
  author = {{J. Nagoor Kani} and Elsheikh, Ahmed H.},
  date = {2019-02},
  journaltitle = {Transport in Porous Media},
  shortjournal = {Transp Porous Med},
  volume = {126},
  pages = {713--741},
  issn = {0169-3913, 1573-1634},
  doi = {10.1007/s11242-018-1170-7},
  url = {http://link.springer.com/10.1007/s11242-018-1170-7},
  urldate = {2020-09-02},
  abstract = {We present a reduced-order modeling technique for subsurface multi-phase flow problems building on the recently introduced deep residual recurrent neural network (DRRNN) (Nagoor Kani et al. in DR-RNN: a deep residual recurrent neural network for model reduction. ArXiv e-prints, 2017). DR-RNN is a physics-aware recurrent neural network for modeling the evolution of dynamical systems. The DR-RNN architecture is inspired by iterative update techniques of line search methods where a fixed number of layers are stacked together to minimize the residual (or reduced residual) of the physical model under consideration. In this manuscript, we combine DR-RNN with proper orthogonal decomposition (POD) and discrete empirical interpolation method (DEIM) to reduce the computational complexity associated with high-fidelity numerical simulations. In the presented formulation, POD is used to construct an optimal set of reduced basis functions and DEIM is employed to evaluate the nonlinear terms independent of the full-order model size. We demonstrate the proposed reduced model on two uncertainty quantification test cases using Monte Carlo simulation of subsurface flow with random permeability field. The obtained results demonstrate that DR-RNN combined with POD–DEIM provides an accurate and stable reduced model with a fixed computational budget that is much less than the computational cost of standard POD–Galerkin reduced model combined with DEIM for nonlinear dynamical systems.},
  file = {/Users/hyan46/Zotero/storage/PH6S5MKN/J. Nagoor Kani and Elsheikh - 2019 - Reduced-Order Modeling of Subsurface Multi-phase F.pdf},
  langid = {english},
  number = {3}
}

@online{jacquierNonIntrusive2020,
  title = {Non-{{Intrusive Reduced}}-{{Order Modeling Using Uncertainty}}-{{Aware Deep Neural Networks}} and {{Proper Orthogonal Decomposition}}: {{Application}} to {{Flood Modeling}}},
  shorttitle = {Non-{{Intrusive Reduced}}-{{Order Modeling Using Uncertainty}}-{{Aware Deep Neural Networks}} and {{Proper Orthogonal Decomposition}}},
  author = {Jacquier, Pierre and Abdedou, Azzedine and Delmas, Vincent and Soulaimani, Azzeddine},
  date = {2020-06-04},
  url = {http://arxiv.org/abs/2005.13506},
  urldate = {2020-09-02},
  abstract = {Deep Learning research is advancing at a fantastic rate, and there is much to gain from transferring this knowledge to older fields like Computational Fluid Dynamics in practical engineering contexts. This work compares state-of-the-art methods that address uncertainty quantification in Deep Neural Networks, pushing forward the reduced-order modeling approach of Proper Orthogonal Decomposition-Neural Networks (POD-NN) with Deep Ensembles and Variational Inference-based Bayesian Neural Networks on two-dimensional problems in space. These are first tested on benchmark problems, and then applied to a real-life application: flooding predictions in the Mille Îles river in the Montreal, Quebec, Canada metropolitan area. Our setup involves a set of input parameters, with a potentially noisy distribution, and accumulates the simulation data resulting from these parameters. The goal is to build a non-intrusive surrogate model that is able to know when it doesn’t know, which is still an open research area in Neural Networks (and in AI in general). With the help of this model, probabilistic flooding maps are generated, aware of the model uncertainty. These insights on the unknown are also utilized for an uncertainty propagation task, allowing for flooded area predictions that are broader and safer than those made with a regular uncertainty-uninformed surrogate model. Our study of the time-dependent and highly nonlinear case of a dam break is also presented. Both the ensembles and the Bayesian approach lead to reliable results for multiple smooth physical solutions, providing the correct warning when going out-of-distribution. However, the former, referred to as POD-EnsNN, proved much easier to implement and showed greater flexibility than the latter in the case of discontinuities, where standard algorithms may oscillate or fail to converge.},
  archiveprefix = {arXiv},
  eprint = {2005.13506},
  eprinttype = {arxiv},
  file = {/Users/hyan46/Zotero/storage/7MZ2YVJY/Jacquier et al. - 2020 - Non-Intrusive Reduced-Order Modeling Using Uncerta.pdf},
  keywords = {Physics - Computational Physics,Physics - Data Analysis; Statistics and Probability},
  langid = {english},
  primaryclass = {physics}
}

@inproceedings{jenattonLatent2012,
  title = {A Latent Factor Model for Highly Multi-Relational Data},
  booktitle = {Advances in {{Neural Information Processing Systems}} 25 ({{NIPS}} 2012)},
  author = {Jenatton, Rodolphe and Roux, Nicolas Le and Bordes, Antoine and Obozinski, Guillaume},
  date = {2012-12},
  pages = {3176--3184},
  abstract = {Many data such as social networks, movie preferences or knowledge bases are multi-relational, in that they describe multiple relations between entities. While there is a large body of work focused on modeling these data, modeling these multiple types of relations jointly remains challenging. Further, existing approaches tend to breakdown when the number of these types grows. In this paper, we propose a method for modeling large multi-relational datasets, with possibly thousands of relations. Our model is based on a bilinear structure, which captures various orders of interaction of the data, and also shares sparse latent factors across different relations. We illustrate the performance of our approach on standard tensor-factorization datasets where we attain, or outperform, state-of-the-art results. Finally, a NLP application demonstrates our scalability and the ability of our model to learn efficient and semantically meaningful verb representations.},
  file = {/Users/hyan46/Dropbox (ASU)/ZoteroData/Jenatton et al_A latent factor model for highly multi-relational data.pdf},
  langid = {english}
}

@article{jensen502018,
  title = {50 Years of the {{{\emph{Journal}}}}{\emph{ of }}{{{\emph{Quality Technology}}}}},
  author = {Jensen, Willis A. and Montgomery, Douglas C. and Tsung, Fugee and Vining, Geoffery G.},
  date = {2018-01-02},
  journaltitle = {Journal of Quality Technology},
  shortjournal = {Journal of Quality Technology},
  volume = {50},
  pages = {2--16},
  issn = {0022-4065, 2575-6230},
  doi = {10.1080/00224065.2018.1404881},
  url = {https://www.tandfonline.com/doi/full/10.1080/00224065.2018.1404881},
  urldate = {2020-07-20},
  abstract = {In celebration of the 50th anniversary of the Journal of Quality Technology, we take a historical look at the articles that have appeared in the journal. We highlight some of the key articles across the decades and provide some historical analysis on those that have appeared. This analysis illustrates some trends in the quality technology field and gives some insight about its future focus.},
  file = {/Users/hyan46/Dropbox (ASU)/ZoteroData/Jensen et al_2018_50 years of the iJournal of Quality Technology-i.pdf},
  langid = {english},
  number = {1}
}

@article{jeong2021two,
  title = {Two-Dimensional Variable Selection and Its Applications in the Diagnostics of Product Quality Defects},
  author = {Jeong, Cheoljoon and Fang, Xiaolei},
  date = {2021},
  journaltitle = {IISE Transactions},
  pages = {1--29},
  publisher = {{Taylor \& Francis}},
  file = {/Users/hyan46/Dropbox (ASU)/ZoteroData/Not_Two-Dimensional Variable Selection and Its Applications in the Diagnostics of.pdf},
  issue = {just-accepted}
}

@inproceedings{ji2008refining,
  title = {Refining Event Extraction through Cross-Document Inference},
  booktitle = {Proceedings of {{ACL}}-08: {{Hlt}}},
  author = {Ji, Heng and Grishman, Ralph},
  date = {2008},
  pages = {254--262}
}

@article{jiangMonitoring2014,
  title = {Monitoring Multi-Mode Plant-Wide Processes by Using Mutual Information-Based Multi-Block {{PCA}}, Joint Probability, and {{Bayesian}} Inference},
  author = {Jiang, Qingchao and Yan, Xuefeng},
  date = {2014-08-15},
  journaltitle = {Chemometrics and Intelligent Laboratory Systems},
  shortjournal = {Chemometrics and Intelligent Laboratory Systems},
  volume = {136},
  pages = {121--137},
  issn = {0169-7439},
  doi = {10.1016/j.chemolab.2014.05.012},
  url = {http://www.sciencedirect.com/science/article/pii/S0169743914001178},
  urldate = {2020-05-25},
  abstract = {A multi-mode plant-wide process monitoring scheme that integrates mutual information (MI)-based multi-block principal component analysis (PCA), joint probability, and Bayesian inference is developed. Given that the prior process is not always available, an MI-based block division method is proposed to divide blocks automatically by considering both cross-relations and high-order statistical information among variables. The PCA monitoring model is established in each sub-block and each mode, and a joint probability based on T2 statistics is defined to identify running-on mode. Then, the statistics in different sub-blocks are combined by using Bayesian inference to provide an intuitive indication. Finally, an improved contribution plot method is proposed to identify the root cause of faults. The feasibility and efficiency of the proposed method are evaluated by case studies on a numerical process and the Tennessee Eastman benchmark process. Monitoring results and comparisons with conventional PCA methods indicate the superiority of the proposed method.},
  file = {/Users/hyan46/Zotero/storage/CRFVK67V/S0169743914001178.html},
  keywords = {Bayesian inference,Joint probability,Multi-block principal component analysis,Multi-mode plant-wide process,multimode,Mutual information,Problem: Process Monitoring},
  langid = {english}
}

@article{jinDiagnostic2017,
  title = {Diagnostic Monitoring of High-Dimensional Networked Systems via a {{LASSO}}-{{BN}} Formulation},
  author = {Jin, Yan and Huang, Shuai and Wang, Guan and Deng, Houtao},
  date = {2017-09-02},
  journaltitle = {IISE Transactions},
  shortjournal = {IISE Transactions},
  volume = {49},
  pages = {874--884},
  issn = {2472-5854, 2472-5862},
  doi = {10.1080/24725854.2017.1301692},
  url = {https://www.tandfonline.com/doi/full/10.1080/24725854.2017.1301692},
  urldate = {2020-07-04},
  abstract = {Quality control of multivariate processes has been extensively studied in the past decades; however, fundamental challenges still remain due to the complexity and the decision-making challenges that require not only sensitive fault detection but also identification of the truly out-of-control variables. In existing approaches, fault detection and diagnosis are considered as two separate tasks. Recent developments have revealed that selective monitoring of the potentially out-of-control variables, identified by a variable selection procedure combined with the process monitoring method, could lead to promising performances. Following this line, we propose the diagnostic monitoring that takes an additional step on from the selective monitoring idea and directs the monitoring effort on the potentially out-of-control variables. The identification of the truly out-of-control variables can be achieved by integrating the process monitoring formulation with process cascade knowledge represented by a Bayesian Network. Computationally efficient algorithms are developed for solving the optimization formulation with connection to the Least Absolute Shrinkage and Selection Operator (LASSO) problem being identified. Both theoretical analysis and extensive experiments on a simulated data set and real-world applications are conducted that show the superior performance.},
  file = {/Users/hyan46/Dropbox (ASU)/ZoteroData/Jin et al_2017_Diagnostic monitoring of high-dimensional networked systems via a LASSO-BN.pdf},
  keywords = {Application: Chemical,Application: Manufacturing,Method: Causal,Method: Regularization,Method: Sparse,People: Shuai Huang,Problem: Process Monitoring},
  langid = {english},
  number = {9}
}

@article{jinGaussian2020,
  ids = {jinGaussian2020a},
  title = {A {{Gaussian Process Model}}-{{Guided Surface Polishing Process}} in {{Additive Manufacturing}}},
  author = {Jin, Shilan and Iquebal, Ashif and Bukkapatnam, Satish and Gaynor, Andrew and Ding, Yu},
  date = {2020-01-01},
  journaltitle = {Journal of Manufacturing Science and Engineering},
  volume = {142},
  pages = {011003},
  issn = {1087-1357, 1528-8935},
  doi = {10.1115/1.4045334},
  url = {https://asmedigitalcollection.asme.org/manufacturingscience/article/doi/10.1115/1.4045334/1066156/A-Gaussian-Process-ModelGuided-Surface-Polishing},
  urldate = {2020-07-04},
  abstract = {Abstract             Polishing of additively manufactured products is a multi-stage process, and a different combination of polishing pad and process parameters is employed at each stage. Pad change decisions and endpoint determination currently rely on practitioners’ experience and subjective visual inspection of surface quality. An automated and objective decision process is more desired for delivering consistency and reducing variability. Toward that objective, a model-guided decision-making scheme is developed in this article for the polishing process of a titanium alloy workpiece. The model used is a series of Gaussian process models, each established for a polishing stage at which surface data are gathered. The series of Gaussian process models appear capable of capturing surface changes and variation over the polishing process, resulting in a decision protocol informed by the correlation characteristics over the sample surface. It is found that low correlations reveal the existence of extreme roughness that may be deemed surface defects. Making judicious use of the change pattern in surface correlation provides insights enabling timely actions. Physical polishing of titanium alloy samples and a simulation of this process are used together to demonstrate the merit of the proposed method.},
  file = {/Users/hyan46/Dropbox (ASU)/ZoteroData/Jin et al_2020_A Gaussian Process Model-Guided Surface Polishing Process in Additive.pdf},
  keywords = {Application: Additive Manufacturing,Application: Manufacturing,Application: Surface Scanning,correlation parameters,end-point detection,endpoint,gaussian process,Method: Functional,Method: Gaussian Process,modeling and simulation,pad change,People: Yu Ding,polishing process},
  langid = {english},
  number = {1}
}

@article{jinMultimode2013,
  title = {Multimode Variation Modeling and Process Monitoring for Serial-Parallel Multistage Manufacturing Processes},
  author = {Jin, Ran and Liu, Kaibo},
  date = {2013-06},
  journaltitle = {IIE Transactions},
  shortjournal = {IIE Transactions},
  volume = {45},
  pages = {617--629},
  issn = {0740-817X, 1545-8830},
  doi = {10.1080/0740817X.2012.728729},
  url = {http://www.tandfonline.com/doi/abs/10.1080/0740817X.2012.728729},
  urldate = {2020-07-04},
  abstract = {A Serial-Parallel Multistage Manufacturing Process (SP-MMP) may have multiple variation propagation modes in its production runs when process routes vary from part to part. Conventional methods that ignore such multimode variation may not be able to effectively model and monitor the variation streams. It is also very challenging to model such a process when the available engineering domain knowledge is insufficient to characterize the variation streams. This article proposes a data-driven method, piecewise linear regression trees, to interrelate the variables for an SP-MMP with multimode variation. A unified control chart system is developed to monitor the process considering modeling uncertainty. The application to a more generic multistage multimode process is discussed. Finally, the effectiveness of the proposed procedure is demonstrated in an application involving a wafer manufacturing process.},
  file = {/Users/hyan46/Dropbox (ASU)/ZoteroData/Jin_Liu_2013_Multimode variation modeling and process monitoring for serial-parallel.pdf},
  keywords = {Application: Semiconductor,Method: Tree,People: Kaibo Liu,Problem: Process Monitoring},
  langid = {english},
  number = {6}
}

@article{jinOffline2016,
  title = {Offline {{Predictive Control}} of {{Out}}-of-{{Plane Shape Deformation}} for {{Additive Manufacturing}}},
  author = {Jin, Yuan and Joe Qin, S. and Huang, Qiang},
  date = {2016-12-01},
  journaltitle = {Journal of Manufacturing Science and Engineering},
  volume = {138},
  pages = {121005},
  issn = {1087-1357, 1528-8935},
  doi = {10.1115/1.4033444},
  url = {https://asmedigitalcollection.asme.org/manufacturingscience/article/doi/10.1115/1.4033444/473142/Offline-Predictive-Control-of-OutofPlane-Shape},
  urldate = {2020-07-04},
  abstract = {Additive manufacturing (AM) is a promising direct manufacturing technology, and the geometric accuracy of AM built products is crucial to fulfill the promise of AM. Prediction and control of three-dimensional (3D) shape deformation, particularly out-of-plane geometric errors of AM built products, have been a challenging task. Although finite-element modeling has been extensively applied to predict 3D deformation and distortion, improving part accuracy based purely on such simulation still needs significant methodology development. We have been establishing an alternative strategy that can be predictive and transparent to specific AM processes based on a limited number of test cases. Successful results have been accomplished in our previous work to control in-plane (x–y plane) shape deformation through offline compensation. In this study, we aim to establish an offline out-of-plane shape deformation control approach based on limited trials of test shapes. We adopt a novel spatial deformation formulation in which both in-plane and out-of-plane geometric errors are placed under a consistent mathematical framework to enable 3D accuracy control. Under this new formulation of 3D shape deformation, we develop a prediction and offline compensation method to reduce out-of-plane geometric errors. Experimental validation is successfully conducted to validate the developed 3D shape accuracy control approach.},
  file = {/Users/hyan46/Dropbox (ASU)/ZoteroData/Jin et al_2016_Offline Predictive Control of Out-of-Plane Shape Deformation for Additive.pdf},
  keywords = {Application: Additive Manufacturing,Application: Manufacturing,People: Qiang Huang},
  langid = {english},
  number = {12}
}

@article{kanDynamic2017,
  title = {Dynamic Network Monitoring and Control of in Situ Image Profiles from Ultraprecision Machining and Biomanufacturing Processes},
  author = {Kan, Chen and Yang, Hui},
  date = {2017-12},
  journaltitle = {Quality and Reliability Engineering International},
  shortjournal = {Qual Reliab Engng Int},
  volume = {33},
  pages = {2003--2022},
  issn = {07488017},
  doi = {10.1002/qre.2163},
  url = {http://doi.wiley.com/10.1002/qre.2163},
  urldate = {2020-07-07},
  abstract = {In modern industries, advanced imaging technology has been more and more invested to cope with the ever‐increasing complexity of systems, to improve the visibility of information and enhance operational quality and integrity. As a result, large amounts of imaging data are readily available. This presents great challenges on the state‐of‐the‐art practices in process monitoring and quality control. Conventional statistical process control (SPC) focuses on key characteristics of the product or process and is rather limited to handle complex structures of high‐dimensional imaging data. New SPC methods and tools are urgently needed to extract useful information from in situ image profiles for process monitoring and quality control. In this study, we developed a novel dynamic network scheme to represent, model, and control time‐varying image profiles. Potts model Hamiltonian approach is introduced to characterize community patterns and organizational behaviors in the dynamic network. Further, new statistics are extracted from network communities to characterize and quantify dynamic structures of image profiles. Finally, we design and develop a new control chart, namely, network‐generalized likelihood ratio chart, to detect the change point of the underlying dynamics of complex processes. The proposed methodology is implemented and evaluated for real‐world applications in ultraprecision machining and biomanufacturing processes. Experimental results show that the proposed approach effectively characterize and monitor the variations in complex structures of time‐varying image data. The new dynamic network SPC method is shown to have strong potentials for general applications in a diverse set of domains with in situ imaging data.},
  file = {/Users/hyan46/Dropbox (ASU)/ZoteroData/Kan_Yang_2017_Dynamic network monitoring and control of in situ image profiles from.pdf},
  langid = {english},
  number = {8}
}

@article{kangOptimizingInReview,
  title = {Optimizing {{Multiple Condition Policy}} Based on {{Real}}-Time {{Degradation Signals}} via {{Model}}-Based {{Reinforcement Learning}}},
  author = {Kang, Yunyi and Zhao, Xinyu and Yan, Hao and Ju, Feng},
  year = {In Review},
  journaltitle = {IISE Transactions},
  keywords = {Application: Manufacturing,Problem: Control}
}

@article{kangPerformance2020,
  title = {Performance {{Evaluation}} of {{Production Systems Using Real}}-{{Time Machine Degradation Signals}}},
  author = {Kang, Yunyi and Yan, Hao and Ju, Feng},
  date = {2020-01},
  journaltitle = {IEEE Transactions on Automation Science and Engineering},
  volume = {17},
  pages = {273--283},
  publisher = {{Institute of Electrical and Electronics Engineers Inc.}},
  issn = {15583783},
  doi = {10.1109/TASE.2019.2920874},
  abstract = {A machine's degradation status directly influences the operational performance of the production system, such as productivity and product quality. For example, machines associated with different health states may have different remaining life before failure, thus impacting the system throughput. Therefore, it is critical to analyze the coupling between the overall system performance and the machine degradation to better production decision-making, such as maintenance and product dispatch decisions. In this paper, we propose a novel model to evaluate the production performance of a two-machine-and-one-buffer line, given the real-time machine degradation signals. Specifically, a phase-type distribution-based continuous-time Markov chain model is formulated to estimate the system throughput by utilizing the remaining life prediction from the degradation signals. A case study is provided to demonstrate the applicability and effectiveness of the proposed method.Note to Practitioners - Machine degradation is commonly observed in many industries, such as automotive, semiconductor, and food production, which gradually deteriorates the machine conditions in different operating processes and affects the production system performance. In practice, sensors are largely deployed on the factory floor to monitor the machine's operating condition. However, a gap still exists between machine operating conditions and system performance. In this paper, we develop an analytical model to predict the machine remaining lifetime and estimate the system performance of a small scale production system, using the machine degradation signals from sensors. Furthermore, a Bayesian updating scheme is provided, which enables online evaluation by utilizing the real-time signals. Such a method provides an effective tool for production engineers to analyze the real-time system performance, and further conduct system improvements and control.},
  file = {/Users/hyan46/Dropbox (ASU)/ZoteroData/Kang et al_2020_Performance Evaluation of Production Systems Using Real-Time Machine2.pdf},
  keywords = {Application: Manufacturing,Method: Bayesian,Problem: Control},
  number = {1}
}

@inproceedings{kangRealtime2018,
  title = {Real-Time {{Production Performance Analysis Using Machine Degradation Signals}}: {{A Two}}-{{Machine Case}}},
  booktitle = {2018 {{IEEE}} 14th {{International Conference}} on {{Automation Science}} and {{Engineering}} ({{CASE}})},
  author = {Kang, Yunyi and Yan, Hao and Ju, Feng},
  date = {2018-12},
  volume = {2018-Augus},
  pages = {1501--1506},
  publisher = {{IEEE Computer Society}},
  issn = {21618089},
  doi = {10.1109/COASE.2018.8560385},
  abstract = {Ahstract- Machine degradation has significant impact on the production system performance. Its variation might lead to large deviation from the steady state performance of the whole system. In this work, we build up a model to estimate the long-term production performance of the two-machine-and-one-buffer production systems, given the real-time machine degradation signals. A phase-type distribution is generated to mimic the remaining life distribution of each machine given the degradation signal. Then a continuous Markovian model is formulated to predict longterm system throughput rate for a two-machine-and-one-buffer system. With the fluctuation of machine degradation signals, such a model can effectively estimate the expected system performance in real-time.},
  file = {/Users/hyan46/Dropbox (ASU)/ZoteroData/Kang et al_2018_Real-time Production Performance Analysis Using Machine Degradation Signals2.pdf},
  isbn = {978-1-5386-3593-3},
  keywords = {Application: Manufacturing,Method: Bayesian,Problem: Control,Problem: Prognostics}
}

@article{kanHeterogeneous2016,
  title = {Heterogeneous Recurrence Monitoring of Dynamic Transients in Ultraprecision Machining Processes},
  author = {Kan, Chen and Cheng, Changqing and Yang, Hui},
  date = {2016-10},
  journaltitle = {Journal of Manufacturing Systems},
  shortjournal = {Journal of Manufacturing Systems},
  volume = {41},
  pages = {178--187},
  issn = {02786125},
  doi = {10.1016/j.jmsy.2016.08.007},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0278612516300541},
  urldate = {2020-07-07},
  abstract = {In situ monitoring and control of process variations are important for quality assurance in ultraprecision machining (UPM) processes. Recent advancements in sensing and communication technology have fueled increasing interests to develop sensor-based monitoring approaches for anomaly detection in the UPM process. However, conventional approaches are limited in their ability to address the complex dynamics hidden in the nonlinear and nonstationary processes. As a result, it is difficult for them to effectively capture the process variations of UPM. This paper presents a new heterogeneous recurrence monitoring approach to detect dynamic transients in UPM processes. First, a high-dimensional state space is reconstructed from in situ sensing signals. A Dirichlet process (DP) driven clustering approach is then developed to automatically segment the state space into local recurrence regions. Furthermore, a fractal representation is designed to characterize state transitions among recurrence regions and extract novel measures to quantify heterogeneous recurrence patterns. Finally, we integrate a multivariate control chart with heterogeneous recurrence features for in situ monitoring and predictive control of the UPM process. Experimental results showed that the proposed approach effectively detects transitions with a small magnitude, i.e., = 28 to = 27 in the Lorenz system, and identifies the shift from stable cutting (Ra = 35 nm) to unstable cutting (Ra = 82 nm) in UPM processes with an average run length of 1.0. This paper presents a novel data-driven DP clustering approach to characterize heterogeneous recurrence variations and link with the quality of surface finishes in UPM processes. This new DP recurrence approach circumvents the need to empirically define local recurrence regions and is shown to have strong potentials for manufacturing process monitoring and control that will increase the surface integrity and reduce rework rates.},
  file = {/Users/hyan46/Dropbox (ASU)/ZoteroData/Kan et al_2016_Heterogeneous recurrence monitoring of dynamic transients in ultraprecision.pdf},
  langid = {english}
}

@online{kaniDRRNN2017,
  title = {{{DR}}-{{RNN}}: {{A}} Deep Residual Recurrent Neural Network for Model Reduction},
  shorttitle = {{{DR}}-{{RNN}}},
  author = {Kani, J. Nagoor and Elsheikh, Ahmed H.},
  date = {2017-09-04},
  url = {http://arxiv.org/abs/1709.00939},
  urldate = {2020-09-02},
  abstract = {We introduce a deep residual recurrent neural network (DR-RNN) as an efficient model reduction technique for nonlinear dynamical systems. The developed DR-RNN is inspired by the iterative steps of line search methods in finding the residual minimiser of numerically discretized differential equations. We formulate this iterative scheme as stacked recurrent neural network (RNN) embedded with the dynamical structure of the emulated differential equations. Numerical examples demonstrate that DR-RNN can effectively emulate the full order models of nonlinear physical systems with a significantly lower number of parameters in comparison to standard RNN architectures. Further, we combined DR-RNN with Proper Orthogonal Decomposition (POD) for model reduction of time dependent partial differential equations. The presented numerical results show the stability of proposed DR-RNN as an explicit reduced order technique. We also show significant gains in accuracy by increasing the depth of proposed DR-RNN similar to other applications of deep learning.},
  archiveprefix = {arXiv},
  eprint = {1709.00939},
  eprinttype = {arxiv},
  file = {/Users/hyan46/Zotero/storage/F368FR95/Kani and Elsheikh - 2017 - DR-RNN A deep residual recurrent neural network f.pdf},
  keywords = {Computer Science - Computational Engineering; Finance; and Science},
  langid = {english},
  primaryclass = {cs}
}

@article{karkusQMDPNet2017,
  title = {{{QMDP}}-{{Net}}: {{Deep Learning}} for {{Planning}} under {{Partial Observability}}},
  shorttitle = {{{QMDP}}-{{Net}}},
  author = {Karkus, Peter and Hsu, David and Lee, Wee Sun},
  date = {2017},
  journaltitle = {Advances in Neural Information Processing Systems},
  volume = {30},
  url = {https://proceedings.neurips.cc/paper/2017/hash/e9412ee564384b987d086df32d4ce6b7-Abstract.html},
  urldate = {2021-06-15},
  file = {/Users/hyan46/Dropbox (ASU)/ZoteroData/Karkus et al_2017_QMDP-Net.pdf;/Users/hyan46/Zotero/storage/UVRUIQTD/e9412ee564384b987d086df32d4ce6b7-Abstract.html},
  langid = {english}
}

@article{kimBayesian2020,
  title = {A {{Bayesian}} Deep Learning Framework for Interval Estimation of Remaining Useful Life in Complex Systems by Incorporating General Degradation Characteristics},
  author = {Kim, Minhee and Liu, Kaibo},
  date = {2020-06-24},
  journaltitle = {IISE Transactions},
  shortjournal = {IISE Transactions},
  pages = {1--15},
  issn = {2472-5854, 2472-5862},
  doi = {10.1080/24725854.2020.1766729},
  url = {https://www.tandfonline.com/doi/full/10.1080/24725854.2020.1766729},
  urldate = {2020-07-04},
  abstract = {Deep learning has emerged as a powerful tool to model complicated relationships between inputs and outputs in various fields including degradation modeling and prognostics. Existing deep learning-based prognostic approaches are often used in a black-box manner and provide only point estimations of remaining useful life. However, accurate interval estimations of the remaining useful life are crucial to understand the stochastic nature of degradation processes and perform reliable risk analysis and maintenance decision making. This study proposes a novel Bayesian deep learning framework that incorporates general characteristics of degradation processes and provides the interval estimations of remaining useful life. The proposed method enjoys several unique advantages: (i) providing a general approach by not assuming any particular type of degradation processes nor the availability of domain-specific prior knowledge such as a failure threshold; (ii) offering the interval estimations of the remaining useful life; (iii) systematically modeling two types of uncertainties embedded in prognostics; and (iv) exhibiting great prognostic performance and wide applicability to complex systems that may involve multiple sensor signals, multiple failure modes, and multiple operational conditions. Numerical studies demonstrate improved prognostic performance and practicality of the proposed method over benchmark approaches. Additional numerical results including the analysis of sensitivity and computational costs are given in the online supplemental materials.},
  file = {/Users/hyan46/Dropbox (ASU)/ZoteroData/Kim_Liu_2020_A Bayesian deep learning framework for interval estimation of remaining useful.pdf},
  keywords = {Application: Engine,Data: Profiles,Method: Deep Learning,People: Kaibo Liu,Problem: Prognostics},
  langid = {english}
}

@article{kimGeneric2019,
  title = {A {{Generic Health Index Approach}} for {{Multisensor Degradation Modeling}} and {{Sensor Selection}}},
  author = {Kim, Minhee and Song, Changyue and Liu, Kaibo},
  date = {2019-07},
  journaltitle = {IEEE Transactions on Automation Science and Engineering},
  shortjournal = {IEEE Trans. Automat. Sci. Eng.},
  volume = {16},
  pages = {1426--1437},
  issn = {1545-5955, 1558-3783},
  doi = {10.1109/TASE.2018.2890608},
  url = {https://ieeexplore.ieee.org/document/8612943/},
  urldate = {2020-07-04},
  abstract = {With recent development in sensor technology, multiple sensors have been widely adopted to monitor the degradation of a single unit simultaneously. The challenge of multisensor degradation modeling lies in that the sensor signals are often correlated and may contain only partial or even no information on the degradation status of a unit. To address these issues, this paper proposes a novel data fusion method that constructs a 1-D health index (HI) via automatically selecting and combining multiple sensor signals to better characterize the degradation process. In particular, this paper develops a new latent linear model that constructs the HI and selects informative sensors in a unified manner. Compared to the existing literature, the proposed method enjoys several unique advantages: 1) being able to derive the best linear unbiased estimator of the fusion coefficients; 2) offering high computational efficiency; 3) not requiring to know the exact value of the failure threshold; and 4) exhibiting general applicability in practice by not imposing restrictive assumptions on the degradation process. Simulation studies are presented to illustrate the effectiveness and evaluate the sensitivity of the proposed method. A case study on the degradation of aircraft gas turbine engines is also performed which shows a better prognostic performance of the proposed method compared with existing approaches.},
  file = {/Users/hyan46/Dropbox (ASU)/ZoteroData/Kim et al_2019_A Generic Health Index Approach for Multisensor Degradation Modeling and Sensor.pdf},
  keywords = {Application: Engine,Data: Profiles,Method: Health Index,People: Kaibo Liu,Problem: Prognostics},
  langid = {english},
  number = {3}
}

@inproceedings{kimNonnegative2007,
  title = {Nonnegative Tucker Decomposition},
  booktitle = {2007 {{IEEE Conference}} on {{Computer Vision}} and {{Pattern Recognition}}},
  author = {Kim, Yong-Deok and Choi, Seungjin},
  date = {2007},
  pages = {1--8},
  publisher = {{IEEE}},
  isbn = {1-4244-1179-3}
}

@article{kimOnline2006,
  title = {Online {{Multichannel Forging Tonnage Monitoring}} and {{Fault Pattern Discrimination Using Principal Curve}}},
  author = {Kim, Jihyun and Huang, Qiang and Shi, Jianjun and Chang, Tzyy-Shuh},
  date = {2006-11-01},
  journaltitle = {Journal of Manufacturing Science and Engineering},
  shortjournal = {J. Manuf. Sci. Eng},
  volume = {128},
  pages = {944--950},
  publisher = {{American Society of Mechanical Engineers Digital Collection}},
  issn = {1087-1357},
  doi = {10.1115/1.2193552},
  url = {https://asmedigitalcollection.asme.org/manufacturingscience/article/128/4/944/475644/Online-Multichannel-Forging-Tonnage-Monitoring-and},
  urldate = {2020-08-13},
  file = {/Users/hyan46/Dropbox (ASU)/ZoteroData/Kim et al_2006_Online Multichannel Forging Tonnage Monitoring and Fault Pattern Discrimination.pdf},
  langid = {english},
  number = {4}
}

@article{kimOptimal2005,
  title = {Optimal {{Engineering System Design Guided}} by {{Data}}-{{Mining Methods}}},
  author = {Kim, Pansoo and Ding, Yu},
  date = {2005-08},
  journaltitle = {Technometrics},
  shortjournal = {Technometrics},
  volume = {47},
  pages = {336--348},
  issn = {0040-1706, 1537-2723},
  doi = {10.1198/004017005000000157},
  url = {http://www.tandfonline.com/doi/abs/10.1198/004017005000000157},
  urldate = {2020-07-04},
  file = {/Users/hyan46/Dropbox (ASU)/ZoteroData/Kim_Ding_2005_Optimal Engineering System Design Guided by Data-Mining Methods.pdf},
  keywords = {Application: Assembly,Application: Manufacturing,Method: Classification,People: Yu Ding,Problem: Classification,Problem: Optimal Design},
  langid = {english},
  number = {3}
}

@article{kimRNNBased2020,
  title = {{{RNN}}-{{Based}} Online Anomaly Detection in Nuclear Reactors for Highly Imbalanced Datasets with Uncertainty},
  author = {Kim, Minhee and Ou, Elisa and Loh, Po-Ling and Allen, Todd and Agasie, Robert and Liu, Kaibo},
  date = {2020-08},
  journaltitle = {Nuclear Engineering and Design},
  shortjournal = {Nuclear Engineering and Design},
  volume = {364},
  pages = {110699},
  issn = {00295493},
  doi = {10.1016/j.nucengdes.2020.110699},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S002954932030193X},
  urldate = {2020-07-04},
  abstract = {Accurate online condition monitoring and anomaly detection are crucial in nuclear applications to optimize economic performance and minimize safety risks. To achieve this goal, several major challenges exist which must be addressed. First, multi-sensor signals are often collected in the form of complex, multivariate time series. Second, relatively few anomaly records are available to train detection models. Lastly, the recorded data may contain uncertainties resulting from various sources, such as operator-induced variability and measurement error. In this paper, a recurrent neural network-based approach is proposed to tackle these issues by effectively utilizing historical data obtained during both normal and abnormal operations. Several advanced data preprocessing techniques are developed to improve the training process of the proposed neural network. The efficiency and sensitivity of the proposed method are evaluated on the multi-sensor signal measurements and operational reports obtained from a real case study. The results demonstrate much improved detection accuracy and practicality of the proposed method over conventional approaches.},
  file = {/Users/hyan46/Dropbox (ASU)/ZoteroData/Kim et al_2020_RNN-Based online anomaly detection in nuclear reactors for highly imbalanced.pdf},
  keywords = {Application: Nuclear,Method: Deep Learning,People: Kaibo Liu,Problem: Process Monitoring},
  langid = {english}
}

@article{koldaTensor2009,
  title = {Tensor {{Decompositions}} and {{Applications}}},
  author = {Kolda, Tamara G. and Bader, Brett W.},
  date = {2009-08-05},
  journaltitle = {SIAM Review},
  shortjournal = {SIAM Rev.},
  volume = {51},
  pages = {455--500},
  publisher = {{Society for Industrial and Applied Mathematics}},
  issn = {0036-1445},
  doi = {10.1137/07070111X},
  url = {https://epubs.siam.org/doi/abs/10.1137/07070111X},
  urldate = {2020-06-03},
  abstract = {This survey provides an overview of higher-order tensor decompositions, their applications, and available software. A tensor is a multidimensional or N-way array. Decompositions of higher-order tensors (i.e., N-way arrays with \$N \textbackslash geq 3\$) have applications in psycho-metrics, chemometrics, signal processing, numerical linear algebra, computer vision, numerical analysis, data mining, neuroscience, graph analysis, and elsewhere. Two particular tensor decompositions can be considered to be higher-order extensions of the matrix singular value decomposition: CANDECOMP/PARAFAC (CP) decomposes a tensor as a sum of rank-one tensors, and the Tucker decomposition is a higher-order form of principal component analysis. There are many other tensor decompositions, including INDSCAL, PARAFAC2, CANDELINC, DEDICOM, and PARATUCK2 as well as nonnegative variants of all of the above. The N-way Toolbox, Tensor Toolbox, and Multilinear Engine are examples of software packages for working with tensors.},
  file = {/Users/hyan46/Dropbox (ASU)/ZoteroData/Kolda_Bader_2009_Tensor Decompositions and Applications.pdf},
  keywords = {Method: Tensor},
  number = {3}
}

@article{kongNonlinear2011,
  title = {Nonlinear {{Sequential Bayesian Analysis}}-{{Based Decision Making}} for {{End}}-{{Point Detection}} of {{Chemical Mechanical Planarization}} ({{CMP}}) {{Processes}}},
  author = {Kong, Z. Y. and Beyca, O. and Bukkapatnam, Satish and Komanduri, R.},
  date = {2011-11},
  journaltitle = {Ieee Transactions on Semiconductor Manufacturing},
  shortjournal = {Ieee T Semiconduct M Ieee T Semiconduct M},
  volume = {24},
  pages = {523--532},
  issn = {0894-6507},
  url = {://WOS:000296468000008},
  abstract = {Chemical mechanical planarization (CMP) process has been widely used in the semiconductor manufacturing industry for realizing highly polished (surface roughness Ra similar to 1 nm) and planar [WIWNU similar to 1\%, thickness variation standard deviation similar to 3 nm] surfaces of an in-process wafer. In CMP, accurate and timely decisions for end-point detection (EPD) are extremely important to enable the process to effectively respond to demand variations and disruptions. In this paper, we apply nonlinear sequential Bayesian analysis and decision theory to establish a quantitative relationship that connects the features (inputs) extracted from on-line wireless vibration sensor signals with the process performance measures, such as material removal (outputs) for EPD in copper CMP process. A case study with actual CMP data is provided to demonstrate the effectiveness of the present approach. Note to practitioners. The semiconductor industry widely uses CMP process for realizing highly polished planar surfaces on inter-level dielectrics and metallic interconnects in the fabrication of integrated circuits. Accurate and timely detection of the end-point (EPD) of the CMP process is critical to prevent over-polishing or under-polishing of wafer surfaces, and thus meet the wafer yield requirements under growing demands on wafer density and performance. An EPD system uses information from in-process sensors and/or inspection instruments to facilitate decisions on when to stop the polishing process, and adjust process settings for optimal performance. However, the issue of developing cost-effective sensors, and addressing the uncertainty in the sensor information remains a challenge. We have developed an EPD system based on deriving and sequentially updating a cost-function using the uncertain information from wireless MEMS vibration sensors mounted on a CMP apparatus. Decisions on EPD are made based on optimizing the updated cost function at every time-step. Our experimental investigations suggest that the sensor information can be effectively used for implementing EPD, and it can minimize the costs of over-polishing and under-polishing of wafers during CMP process. As part of future work, we are investigating the robustness of the EPD system to different forms of uncertainty in the sensor information, and much wider configurations of sensors and CMP setups.},
  keywords = {integrated circuit manufacture,intelligent sensors,manufacturing automation,mrr,particle filters,sequential decision procedures,simulation},
  langid = {english},
  number = {4}
}

@article{kongProcess2010,
  title = {Process {{Performance Prediction}} for {{Chemical Mechanical Planarization}} ({{CMP}}) by {{Integration}} of {{Nonlinear Bayesian Analysis}} and {{Statistical Modeling}}},
  author = {Kong, Z. Y. and Oztekin, A. and Beyca, O. F. and Phatak, U. and Bukkapatnam, Satish and Komanduri, R.},
  date = {2010-05},
  journaltitle = {Ieee Transactions on Semiconductor Manufacturing},
  shortjournal = {Ieee T Semiconduct M Ieee T Semiconduct M},
  volume = {23},
  pages = {316--327},
  issn = {0894-6507},
  url = {://WOS:000277342400020},
  abstract = {Chemical mechanical planarization (CMP) process has been widely used in the semiconductor manufacturing industry for realizing highly finished (Ra similar to nm) and planar surfaces (WIWNU similar to 1\%, thickness standard deviation (SD) similar to 3 nm) of in-process wafer polishing. The CMP process is rather complex with nonlinear and non-Gaussian process dynamics, which brings significant challenges for process monitoring and control. As an attempt to address this issue, a method is presented in this paper that integrates nonlinear Bayesian analysis and statistical modeling to estimate and predict process state variables, and therewith to predict the performance measures, such as material removal rate (MRR), surface finish, surface defects, etc. As an example of performance measure, MRR is chosen to demonstrate the performance prediction. A sequential Monte Carlo (SMC) method, namely, particle filtering (PF) method is utilized for nonlinear Bayesian analysis to predict the CMP process-state and for tackling the process nonlinearity. Vibration signals from both wired and wireless vibration sensors are adopted in the experimental study conducted using the CMP apparatus. The process states captured by the sensor signals are related to MRR using design of experiments and statistical regression analysis. A case study was conducted using actual CMP processing data by comparing the PF method with other widely used prediction approaches. This comparison demonstrates the effectiveness of the proposed approach, especially for nonlinear dynamic processes.},
  keywords = {bayesian analysis,chemical mechanical planarization (cmp),contact,copper,design of experiments,dielectric films,filters,material removal rate,parameter,particle filtering,process performance prediction,silicon-wafers,slurry,tracking,vibration sensors},
  langid = {english},
  number = {2}
}

@incollection{kulldorffSpatial1999,
  title = {Spatial {{Scan Statistics}}: {{Models}}, {{Calculations}}, and {{Applications}}},
  shorttitle = {Spatial {{Scan Statistics}}},
  booktitle = {Scan {{Statistics}} and {{Applications}}},
  author = {Kulldorff, Martin},
  editor = {Glaz, Joseph and Balakrishnan, N.},
  date = {1999},
  pages = {303--322},
  publisher = {{Birkhäuser}},
  location = {{Boston, MA}},
  doi = {10.1007/978-1-4612-1578-3_14},
  url = {https://doi.org/10.1007/978-1-4612-1578-3_14},
  urldate = {2020-05-25},
  abstract = {A common problem in spatial statistics is whether a set of points are randomly distributed or if they show signs of clusters or clustering. When the locations of clusters are of interest, it is natural to use a spatial scan statistic.Different spatial scan statistics have been proposed. These are discussed and presented in a general framework that incorporates two-dimensional scan statistics on the plane or on a sphere, as well as three-dimensional scan statistics in space or in space—time. Computational issues are then looked at, presenting efficient algorithms that can be used for different scan statistics in connection with Monte Carlo-based hypothesis testing. It is shown that the computational requirements are reasonable even for very large data sets. Which scan statistic to use will depend on the application at hand, which is discussed in terms of past as well as possible future practical applications in areas such as epidemiology, medical imaging, astronomy, archaeology, urban and regional planning, and reconnaissance.},
  file = {/Users/hyan46/Dropbox (ASU)/ZoteroData/Kulldorff_1999_Spatial Scan Statistics.pdf;/Users/hyan46/Zotero/storage/GBUUZD9G/SpatialScan.lyx},
  isbn = {978-1-4612-1578-3},
  keywords = {geography,likelihood ratio test,maximum likelihood,space—time clusters,spatial clusters,Spatial statistics},
  langid = {english},
  series = {Statistics for {{Industry}} and {{Technology}}}
}

@article{kumarComputerVisionBased2008,
  title = {Computer-{{Vision}}-{{Based Fabric Defect Detection}}: {{A Survey}}},
  shorttitle = {Computer-{{Vision}}-{{Based Fabric Defect Detection}}},
  author = {Kumar, A.},
  date = {2008-01},
  journaltitle = {IEEE Transactions on Industrial Electronics},
  shortjournal = {IEEE Trans. Ind. Electron.},
  volume = {55},
  pages = {348--363},
  issn = {0278-0046, 1557-9948},
  doi = {10.1109/TIE.1930.896476},
  url = {http://ieeexplore.ieee.org/document/4418522/},
  urldate = {2020-07-15},
  abstract = {The investment in an automated fabric defect detection system is more than economical when reduction in labor cost and associated benefits are considered. The development of a fully automated web inspection system requires robust and efficient fabric defect detection algorithms. The inspection of real fabric defects is particularly challenging due to the large number of fabric defect classes, which are characterized by their vagueness and ambiguity. Numerous techniques have been developed to detect fabric defects and the purpose of this paper is to categorize and/or describe these algorithms. This paper attempts to present the first survey on fabric defect detection techniques presented in about 160 references. Categorization of fabric defect detection techniques is useful in evaluating the qualities of identified features. The characterization of real fabric surfaces using their structure and primitive set has not yet been successful. Therefore, on the basis of the nature of features from the fabric surfaces, the proposed approaches have been characterized into three categories; statistical, spectral and model-based. In order to evaluate the state-of-the-art, the limitations of several promising techniques are identified and performances are analyzed in the context of their demonstrated results and intended application. The conclusions from this paper also suggest that the combination of statistical, spectral and model-based approaches can give better results than any single approach, and is suggested for further research.},
  file = {/Users/hyan46/Dropbox (ASU)/ZoteroData/Kumar_2008_Computer-Vision-Based Fabric Defect Detection.pdf},
  langid = {english},
  number = {1}
}

@article{kumarDefect2002,
  title = {Defect Detection in Textured Materials Using {{Gabor}} Filters},
  author = {Kumar, A. and Pang, G.K.H.},
  year = {March-April/2002},
  journaltitle = {IEEE Transactions on Industry Applications},
  shortjournal = {IEEE Trans. on Ind. Applicat.},
  volume = {38},
  pages = {425--440},
  issn = {00939994},
  doi = {10.1109/28.993164},
  url = {http://ieeexplore.ieee.org/document/993164/},
  urldate = {2020-07-15},
  abstract = {This paper investigates various approaches for automated inspection of textured materials using Gabor wavelet features. A new supervised defect detection approach to detect a class of defects in textile webs is proposed. Unsupervised web inspection using multichannel filtering scheme is investigated. A new data fusion scheme to multiplex the information from the different channels is proposed. Various factors interacting the tradeoff for performance and computational load are discussed. This scheme establishes high computational savings over the previously proposed approaches and results in high quality of defect detection. Final acceptance of visual inspection systems depends on economical aspects as well. Therefore, a new low-cost solution for fast web inspection is also included in this paper. The experimental results conducted on real fabric defects for various approaches proposed in this paper confirm their usefulness.},
  file = {/Users/hyan46/Dropbox (ASU)/ZoteroData/Kumar_Pang_2002_Defect detection in textured materials using Gabor filters.pdf},
  langid = {english},
  number = {2}
}

@article{kuniyaMultigroup2016,
  title = {A Multi-Group {{SIR}} Epidemic Model with Age Structure},
  author = {Kuniya, Toshikazu and Wang, Jinliang and Inaba, Hisashi},
  date = {2016-11},
  journaltitle = {Discrete and Continuous Dynamical Systems - Series B},
  shortjournal = {DCDS-B},
  volume = {21},
  pages = {3515--3550},
  issn = {1531-3492},
  doi = {10.3934/dcdsb.2016109},
  url = {http://www.aimsciences.org/journals/displayArticlesnew.jsp?paperID=13337},
  urldate = {2021-01-07},
  abstract = {This paper provides the first detailed analysis of a multi-group SIR epidemic model with age structure, which is given by a nonlinear system of 3n partial differential equations. The basic reproduction number R0 is obtained as the spectral radius of the next generation operator, and it is shown that if R0 {$<$} 1, then the disease-free equilibrium is globally asymptotically stable, while if R0 {$>$} 1, then an endemic equilibrium exists. The global asymptotic stability of the endemic equilibrium is also shown under additional assumptions such that the transmission coefficient is independent from the age of infective individuals and the mortality and removal rates are constant. To our knowledge, this is the first paper which applies the method of Lyapunov functional and graph theory to a multi-dimensional PDE system.},
  file = {/Users/hyan46/Zotero/storage/ZCA9R7XL/Kuniya et al. - 2016 - A multi-group SIR epidemic model with age structur.pdf},
  langid = {english},
  number = {10}
}

@article{lahotiImage2021,
  title = {Image Decomposition-Based Sparse Extreme Pixel-Level Feature Detection Model with Application to Medical Images},
  author = {Lahoti, Geet and Chen, Jialei and Yue, Xiaowei and Yan, Hao and Ranjan, Chitta and Qian, Zhen and Zhang, Chuck and Wang, Ben},
  date = {2021-04-07},
  journaltitle = {IISE Transactions on Healthcare Systems Engineering},
  volume = {0},
  pages = {1--17},
  publisher = {{Taylor \& Francis}},
  issn = {2472-5579},
  doi = {10.1080/24725579.2021.1910599},
  url = {https://doi.org/10.1080/24725579.2021.1910599},
  urldate = {2021-07-05},
  abstract = {Pixel-level feature detection from images is an essential but challenging task encountered in domains such as detecting defects in manufacturing systems and detecting tumors in medical imaging. Often, the real image contains multiple feature types. The types with higher pixel intensities are termed as positive (extreme) features and the ones with lower pixel intensities as negative (extreme) features. For example, when planning a medical treatment, it is important to identify, (a) calcification (a pathological feature which can result in a post-surgical complications) as positive features, and (b) soft tissues (organ morphology, knowledge of which can support pre-surgical planning) as negative features, from a preoperative computed tomography image of the human heart. However, this is not an easy task because (a) conventional segmentation techniques require manual intervention and post-processing, and (b) existing automatic approaches do not distinguish positive features from negative. In this work, we propose a novel, automatic image decomposition-based sparse extreme pixel-level feature detection model to decompose an image into mean and extreme features. To estimate model parameters, a high-dimensional least squares regression with regularization and constraints is utilized. An efficient algorithm based on the alternating direction method of multipliers and the proximal gradient method is developed to solve the large-scale optimization problem. The effectiveness of the proposed model is demonstrated using synthetic tests and a real-world case study, where the model exhibits superior performance over existing methods.},
  annotation = {\_eprint: https://doi.org/10.1080/24725579.2021.1910599},
  file = {/Users/hyan46/Zotero/storage/5Q6MMSAM/24725579.2021.html},
  keywords = {feature detection,high-dimensional regression,Image segmentation,large-scale convex optimization,medical image analysis},
  number = {0}
}

@online{laubHawkes2015,
  title = {Hawkes {{Processes}}},
  author = {Laub, Patrick J. and Taimre, Thomas and Pollett, Philip K.},
  date = {2015-07-10},
  url = {http://arxiv.org/abs/1507.02822},
  urldate = {2020-08-08},
  abstract = {Hawkes processes are a particularly interesting class of stochastic process that have been applied in diverse areas, from earthquake modelling to financial analysis. They are point processes whose defining characteristic is that they ‘self-excite’, meaning that each arrival increases the rate of future arrivals for some period of time. Hawkes processes are well established, particularly within the financial literature, yet many of the treatments are inaccessible to one not acquainted with the topic. This survey provides background, introduces the field and historical developments, and touches upon all major aspects of Hawkes processes.},
  archiveprefix = {arXiv},
  eprint = {1507.02822},
  eprinttype = {arxiv},
  file = {/Users/hyan46/Dropbox (ASU)/ZoteroData/Laub et al_2015_Hawkes Processes.pdf},
  keywords = {Mathematics - Probability,Quantitative Finance - Statistical Finance,Statistics - Applications},
  langid = {english},
  primaryclass = {math, q-fin, stat}
}

@article{LDC2005a,
  title = {Linguistic Data Consortium ({{LDC}}).2005a. {{English}} Annotation Guidelines for Entities.},
  url = {https://www.ldc.upenn.edu/sites/www.ldc.upenn.edu/files/english-entities-guidelines-v5.6.6.pdf}
}

@article{lecunDeep2015,
  title = {Deep Learning},
  author = {LeCun, Yann and Bengio, Yoshua and Hinton, Geoffrey},
  date = {2015-05},
  journaltitle = {Nature},
  volume = {521},
  pages = {436--444},
  issn = {1476-4687},
  doi = {10.1038/nature14539},
  url = {https://www.nature.com/articles/nature14539},
  urldate = {2020-07-03},
  abstract = {Deep learning allows computational models that are composed of multiple processing layers to learn representations of data with multiple levels of abstraction. These methods have dramatically improved the state-of-the-art in speech recognition, visual object recognition, object detection and many other domains such as drug discovery and genomics. Deep learning discovers intricate structure in large data sets by using the backpropagation algorithm to indicate how a machine should change its internal parameters that are used to compute the representation in each layer from the representation in the previous layer. Deep convolutional nets have brought about breakthroughs in processing images, video, speech and audio, whereas recurrent nets have shone light on sequential data such as text and speech.},
  langid = {english},
  number = {7553}
}

@article{leeBayesian2013,
  title = {Bayesian Spline Method for Assessing Extreme Loads on Wind Turbines},
  author = {Lee, Giwhyun and Byon, Eunshin and Ntaimo, Lewis and Ding, Yu},
  date = {2013-12},
  journaltitle = {The Annals of Applied Statistics},
  shortjournal = {Ann. Appl. Stat.},
  volume = {7},
  pages = {2034--2061},
  issn = {1932-6157},
  doi = {10.1214/13-AOAS670},
  url = {https://projecteuclid.org/euclid.aoas/1387823309},
  urldate = {2020-07-04},
  file = {/Users/hyan46/Dropbox (ASU)/ZoteroData/Lee et al_2013_Bayesian spline method for assessing extreme loads on wind turbines.pdf},
  keywords = {Application: Wind Turbine,Method: Bayesian,Method: Functional,Method: Spline,People: Yu Ding,Problem: Unsupervised},
  langid = {english},
  number = {4}
}

@article{leeKernel2015,
  title = {A Kernel plus Method for Quantifying Wind Turbine Performance Upgrades: {{Kernel}} plus Method},
  shorttitle = {A Kernel plus Method for Quantifying Wind Turbine Performance Upgrades},
  author = {Lee, Giwhyun and Ding, Yu and Xie, Le and Genton, Marc G.},
  date = {2015-07},
  journaltitle = {Wind Energy},
  shortjournal = {Wind Energ.},
  volume = {18},
  pages = {1207--1219},
  issn = {10954244},
  doi = {10.1002/we.1755},
  url = {http://doi.wiley.com/10.1002/we.1755},
  urldate = {2020-07-04},
  abstract = {Power curves are commonly estimated using the binning method recommended by the International Electrotechnical Commission, which primarily incorporates wind speed information. When such power curves are used to quantify a turbine’s upgrade, the results may not be accurate because many other environmental factors in addition to wind speed, such as temperature, air pressure, turbulence intensity, wind shear and humidity, all potentially affect the turbine’s power output. Wind industry practitioners are aware of the need to filter out effects from environmental conditions. Toward that objective, we developed a kernel plus method that allows incorporation of multivariate environmental factors in a power curve model, thereby controlling the effects from environmental factors while comparing power outputs. We demonstrate that the kernel plus method can serve as a useful tool for quantifying a turbine’s upgrade because it is sensitive to small and moderate changes caused by certain turbine upgrades. Although we demonstrate the utility of the kernel plus method in this specific application, the resulting method is a general, multivariate model that can connect other physical factors, as long as their measurements are available, with a turbine’s power output, which may allow us to explore new physical properties associated with wind turbine performance. Copyright © 2014 John Wiley \& Sons, Ltd.},
  file = {/Users/hyan46/Dropbox (ASU)/ZoteroData/Lee et al_2015_A kernel plus method for quantifying wind turbine performance upgrades.pdf},
  keywords = {Application: Wind Turbine,Method: Functional,Method: Kernel,People: Yu Ding},
  langid = {english},
  number = {7}
}

@inproceedings{leeMultilabel2018,
  title = {Multi-Label {{Zero}}-{{Shot Learning}} with {{Structured Knowledge Graphs}}},
  booktitle = {2018 {{IEEE}}/{{CVF Conference}} on {{Computer Vision}} and {{Pattern Recognition}}},
  author = {Lee, Chung-Wei and Fang, Wei and Yeh, Chih-Kuan and Wang, Yu-Chiang Frank},
  date = {2018-06},
  pages = {1576--1585},
  publisher = {{IEEE}},
  location = {{Salt Lake City, UT}},
  doi = {10.1109/CVPR.2018.00170},
  url = {https://ieeexplore.ieee.org/document/8578268/},
  urldate = {2021-06-02},
  abstract = {In this paper, we propose a novel deep learning architecture for multi-label zero-shot learning (ML-ZSL), which is able to predict multiple unseen class labels for each input instance. Inspired by the way humans utilize semantic knowledge between objects of interests, we propose a framework that incorporates knowledge graphs for describing the relationships between multiple labels. Our model learns an information propagation mechanism from the semantic label space, which can be applied to model the interdependencies between seen and unseen class labels. With such investigation of structured knowledge graphs for visual reasoning, we show that our model can be applied for solving multi-label classification and ML-ZSL tasks. Compared to state-of-the-art approaches, comparable or improved performances can be achieved by our method.},
  eventtitle = {2018 {{IEEE}}/{{CVF Conference}} on {{Computer Vision}} and {{Pattern Recognition}} ({{CVPR}})},
  file = {/Users/hyan46/Dropbox (ASU)/ZoteroData/Lee et al_2018_Multi-label Zero-Shot Learning with Structured Knowledge Graphs.pdf},
  isbn = {978-1-5386-6420-9},
  langid = {english}
}

@article{leePower2015,
  title = {Power {{Curve Estimation With Multivariate Environmental Factors}} for {{Inland}} and {{Offshore Wind Farms}}},
  author = {Lee, Giwhyun and Ding, Yu and Genton, Marc G. and Xie, Le},
  date = {2015-01-02},
  journaltitle = {Journal of the American Statistical Association},
  shortjournal = {Journal of the American Statistical Association},
  volume = {110},
  pages = {56--67},
  issn = {0162-1459, 1537-274X},
  doi = {10.1080/01621459.2014.977385},
  url = {http://www.tandfonline.com/doi/full/10.1080/01621459.2014.977385},
  urldate = {2020-07-04},
  file = {/Users/hyan46/Dropbox (ASU)/ZoteroData/Lee et al_2015_Power Curve Estimation With Multivariate Environmental Factors for Inland and.pdf},
  keywords = {Application: Wind Turbine,Method: Functional,Method: Kernel,People: Yu Ding,Problem: Unsupervised},
  langid = {english},
  number = {509}
}

@article{leiAutomatic2010,
  title = {Automatic {{Tonnage Monitoring}} for {{Missing Part Detection}} in {{Multi}}-{{Operation Forging Processes}}},
  author = {Lei, Yong and Zhang, Zhisheng and Jin, Jionghua},
  date = {2010-10-01},
  journaltitle = {Journal of Manufacturing Science and Engineering},
  volume = {132},
  pages = {051010},
  issn = {1087-1357, 1528-8935},
  doi = {10.1115/1.4002531},
  url = {https://asmedigitalcollection.asme.org/manufacturingscience/article/doi/10.1115/1.4002531/456247/Automatic-Tonnage-Monitoring-for-Missing-Part},
  urldate = {2020-08-13},
  abstract = {In multi-operation forging processes, the process fault due to missing parts from dies is a critical concern. The objective of this paper is to develop an effective method for detecting missing parts by using automatic classification of tonnage signals during continuous production. In this paper, a new feature selection and hierarchical classification method is developed to improve the classification performance for multiclass faults. In the development of the methodology, the signal segmentation is conducted at the first step based on an offline station-by-station test in a forging process. Afterwards, the principal component analysis is conducted on the segmented tonnage signals to generate the principal component (PC) features to be selected for designing the classifier. Finally, the optimal selection of PC features is integrated with the design of a hierarchical classifier by using the criterion of minimizing the probabilities of misclassification among classes. A case study using a real-world forging process is provided in the paper, which demonstrates the effectiveness of the developed methodology for detecting and diagnosing the missing parts faults in the multiple forging operation process. The classifier performance is also validated through the cross-validations to achieve a given average classification error.},
  file = {/Users/hyan46/Dropbox (ASU)/ZoteroData/Lei et al_2010_Automatic Tonnage Monitoring for Missing Part Detection in Multi-Operation.pdf},
  langid = {english},
  number = {5}
}

@article{leTopology2013,
  title = {Topology and {{Random}}-{{Walk Network Representation}} of {{Cardiac Dynamics}} for {{Localization}} of {{Myocardial Infarction}}},
  author = {Le, T. Q. and Bukkapatnam, Satish and Benjamin, B. A. and Wilkins, B. A. and Komanduri, R.},
  date = {2013-08},
  journaltitle = {Ieee Transactions on Biomedical Engineering},
  shortjournal = {Ieee T Bio-Med Eng Ieee T Bio-Med Eng},
  volume = {60},
  pages = {2325--2331},
  issn = {0018-9294},
  url = {://WOS:000322025300030},
  abstract = {While detection of acute cardiac disorders such as myocardial infarction (MI) from electrocardiogram (ECG) and vectorcardiogram (VCG) has been widely reported, identification of MI locations from these signals, pivotal for timely therapeutic and prognostic interventions, remains a standing issue. We present an approach for MI localization based on representing complex spatiotemporal patterns of cardiac dynamics as a random-walk network reconstructed from the evolution of VCG signals across a 3-D state space. Extensive tests with signals from the PTB database of the PhysioNet databank suggest that locations of MI can be determined accurately (sensitivity of similar to 88\% and specificity of similar to 92\%) from tracking certain consistently estimated invariants of this random-walk representation.},
  keywords = {cardiac dynamics,diagnosis,myocardial infarction localization,vectorcardiogram (vcg) octant network,vectorcardiographic criteria},
  langid = {english},
  number = {8}
}

@inproceedings{li2013joint,
  title = {Joint Event Extraction via Structured Prediction with Global Features},
  booktitle = {Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics (Volume 1: {{Long}} Papers)},
  author = {Li, Qi and Ji, Heng and Huang, Liang},
  date = {2013},
  pages = {73--82}
}

@online{liangEnhancing2020,
  title = {Enhancing {{The Reliability}} of {{Out}}-of-Distribution {{Image Detection}} in {{Neural Networks}}},
  author = {Liang, Shiyu and Li, Yixuan and Srikant, R.},
  date = {2020-08-30},
  url = {http://arxiv.org/abs/1706.02690},
  urldate = {2020-09-06},
  abstract = {We consider the problem of detecting out-of-distribution images in neural networks. We propose ODIN, a simple and effective method that does not require any change to a pre-trained neural network. Our method is based on the observation that using temperature scaling and adding small perturbations to the input can separate the softmax score distributions between in- and out-of-distribution images, allowing for more effective detection. We show in a series of experiments that ODIN is compatible with diverse network architectures and datasets. It consistently outperforms the baseline approach (Hendrycks \& Gimpel, 2017) by a large margin, establishing a new state-of-the-art performance on this task. For example, ODIN reduces the false positive rate from the baseline 34.7\% to 4.3\% on the DenseNet (applied to CIFAR-10 and Tiny-ImageNet) when the true positive rate is 95\%.},
  archiveprefix = {arXiv},
  eprint = {1706.02690},
  eprinttype = {arxiv},
  file = {/Users/hyan46/Dropbox (ASU)/ZoteroData/Liang et al_2020_Enhancing The Reliability of Out-of-distribution Image Detection in Neural.pdf},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  langid = {english},
  primaryclass = {cs, stat}
}

@article{liangMonitoring2019,
  title = {Monitoring of User‐generated Reviews via a Sequential Reverse Joint Sentiment‐topic Model},
  author = {Liang, Qiao and Wang, Kaibo},
  date = {2019-06},
  journaltitle = {Quality and Reliability Engineering International},
  shortjournal = {Qual Reliab Engng Int},
  volume = {35},
  pages = {1180--1199},
  issn = {0748-8017, 1099-1638},
  doi = {10.1002/qre.2452},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/qre.2452},
  urldate = {2020-07-04},
  abstract = {User-generated reviews can serve as an efficient tool for evaluating the customer-perceived quality of online products and services. This article proposes a joint control chart for monitoring the quantitative evolution of document-level topics and sentiments in online customer reviews. A sequential model is constructed to convert the temporally correlated document collections to topic and sentiment distributions, which are subsequently used to monitor the topics that users are concerned about and the topic-specific opinions in an ongoing product and service process. Simulation studies on various data scenarios demonstrate the superior performance of the proposed control chart in terms of both detecting shifts and identifying truly out-of-control terms.},
  file = {/Users/hyan46/Dropbox (ASU)/ZoteroData/Liang_Wang_2019_Monitoring of user‐generated reviews via a sequential reverse joint.pdf},
  keywords = {People: Kaibo Wang,Problem: Process Monitoring},
  langid = {english},
  number = {4}
}

@article{liBayesian2016,
  title = {A {{Bayesian}} Variable Selection Method for Joint Diagnosis of Manufacturing Process and Sensor Faults},
  author = {Li, Shan and Chen, Yong},
  date = {2016-04-02},
  journaltitle = {IIE Transactions},
  shortjournal = {IIE Transactions},
  volume = {48},
  pages = {313--323},
  issn = {0740-817X, 1545-8830},
  doi = {10.1080/0740817X.2015.1109739},
  url = {http://www.tandfonline.com/doi/full/10.1080/0740817X.2015.1109739},
  urldate = {2020-07-04},
  abstract = {This article presents a Bayesian variable selection–based diagnosis approach to simultaneously identify both process mean shift faults and sensor mean shift faults in manufacturing processes. The proposed method directly models the probability of fault occurrence and can easily incorporate prior knowledge on the probability of a fault occurrence. Important concepts are introduced to understand the diagnosability of the proposed method. A guideline on how to select the values of hyper-parameters is given. A conditional maximum likelihood method is proposed as an alternative method to provide robustness to the selection of some key model parameters. Systematic simulation studies are used to provide insights on the relationship between the success of the diagnosis method and related system structure characteristics. A real assembly example is used to demonstrate the effectiveness of the proposed diagnosis method.},
  file = {/Users/hyan46/Dropbox (ASU)/ZoteroData/Li_Chen_2016_A Bayesian variable selection method for joint diagnosis of manufacturing.pdf},
  keywords = {Application: Assembly,Application: Manufacturing,Method: Bayesian,Method: Sparse,People: Chen Yong,Problem: Process Monitoring},
  langid = {english},
  number = {4}
}

@article{liCausationbased2017,
  title = {Causation-Based Process Monitoring and Diagnosis for Multivariate Categorical Processes},
  author = {Li, Jian and Liu, Kaibo and Xian, Xiaochen},
  date = {2017-03-04},
  journaltitle = {IISE Transactions},
  shortjournal = {IISE Transactions},
  volume = {49},
  pages = {332--343},
  issn = {2472-5854, 2472-5862},
  doi = {10.1080/0740817X.2016.1241455},
  url = {https://www.tandfonline.com/doi/full/10.1080/0740817X.2016.1241455},
  urldate = {2020-07-04},
  abstract = {As many manufacturing and service processes nowadays involve multiple categorical quality characteristics, statistical surveillance for multivariate categorical processes has attracted increasing attention recently. However, in the literature there are only a few research papers that focus on the monitoring and diagnosis of such processes. This may be partly due to the challenges and limitations in describing the correlation relationships among categorical variables. In many applications, causal relationships may exist among categorical variables, in which the shifts at upstream, or cause, variables will propagate to their downstream, or effect, variables based on the causal structure. In such cases, a causation-based rather than correlationbased description would better account for the relationship among multiple categorical variables. This provides a new opportunity to establish improved monitoring and diagnosis schemes. In this article, we employ a Bayesian network to characterize such causal relationships and integrate it with a statistical process control technique. We propose two control charts for detecting shifts in the conditional probabilities of the multiple categorical variables that are embedded in the Bayesian network. The first chart provides a general tool, and the second chart integrates directional information, which also leads to a diagnostic prescription of shift locations. Both simulation and real case studies are used to demonstrate the effectiveness of the proposed monitoring and diagnostic schemes.},
  file = {/Users/hyan46/Dropbox (ASU)/ZoteroData/Li et al_2017_Causation-based process monitoring and diagnosis for multivariate categorical.pdf},
  keywords = {Application: Rolling,Method: Causal,People: Kaibo Liu,Problem: Process Monitoring},
  langid = {english},
  number = {3}
}

@article{liGlobally2013,
  title = {A Globally Attractive Cycle Driven by Sequential Bifurcations Containing Ghost Effects in a 3-Node Yeast Cell Cycle Model},
  author = {Li, Fangting and Hu, Mingyang and Zhao, Bo and Yan, Hao and Wu, Bin and Ouyang, Qi},
  date = {2013-12},
  url = {http://arxiv.org/abs/1312.5204},
  abstract = {Yeast cells produce daughter cells through a DNA replication and mitosis cycle associated with checkpoints and governed by the cell cycle regulatory network. To ensure genome stability and genetic information inheritance, this regulatory network must be dynamically robust against various fluctuations. Here we construct a simplified cell cycle model for a budding yeast to investigate the underlying mechanism that ensures robustness in this process containing sequential tasks (DNA replication and mitosis). We first establish a three-variable model and select a parameter set that qualitatively describes the yeast cell cycle process. Then, through nonlinear dynamic analysis, we demonstrate that the yeast cell cycle process is an excitable system driven by a sequence of saddle-node bifurcations with ghost effects. We further show that the yeast cell cycle trajectory is globally attractive with modularity in both state and parameter space, while the convergent manifold provides a suitable control state for cell cycle checkpoints. These results not only highlight a regulatory mechanism for executing successive cell cycle processes, but also provide a possible strategy for the synthetic network design of sequential-task processes.},
  annotation = {\_eprint: 1312.5204},
  file = {/Users/hyan46/Dropbox (ASU)/ZoteroData/Li et al_2013_A globally attractive cycle driven by sequential bifurcations containing ghost2.pdf}
}

@article{lihAdaptive2008,
  ids = {lihAdaptive2008a,lihAdaptive2008b},
  title = {Adaptive Neuro-Fuzzy Inference System Modeling of {{MRR}} and {{WIWNU}} in {{CMP}} Process with Sparse Experimental Data},
  author = {Lih, W. C. and Bukkapatnam, Satish and Rao, P. and Chandrasekharan, N. and Komanduri, R.},
  date = {2008-01},
  journaltitle = {Ieee Transactions on Automation Science and Engineering},
  shortjournal = {Ieee T Autom Sci Eng Ieee T Autom Sci Eng},
  volume = {5},
  pages = {71--83},
  issn = {1545-5955},
  url = {://WOS:000252337000008},
  abstract = {Availability of only limited or sparse experimental data impedes the ability of current models of chemical mechanical planarization (CMP) to accurately capture and predict the underlying complex chemomechanical interactions. Modeling approaches that can effectively interpret such data are therefore necessary. In this paper, a new approach to predict the material removal rate (MRR) and within wafer nonuniformity (WIWNU) in CMP of silicon wafers using sparse-data sets is presented. The approach involves utilization of an adaptive neuro-fuzzy inference system (ANFIS) based on subtractive clustering (SC) of the input parameter space. Linear statistical models were used to assess the relative significance of process input parameters and their interactions. Substantial improvements in predicting CMP behaviors under sparse-data conditions can be achieved from fine-tuning membership functions of statistically less significant input parameters. The approach was also found to perform better than alternative neural network (NN) and neuro-fuzzy modeling methods for capturing the complex relationships that connect the machine and material parameters in CMP with MRR and WIWNU, as well as for predicting MRR and WIWNU in CMP. Note to Practitioners-In many microelectronics and other industrial applications, the cost of experimentation tends to be prohibitively high. Consequently, only a limited or sparse set of data is available for modeling and optimization of the process. Under such circumstances, the present approach based on ANFIS with SC was found to perform better than the alternative NN or neuro-fuzzy modeling methods for capturing the complex relationships that connect the machine and material parameters in the process performance variables, such as the MRR and WIWNU in the CMP process. These are considered as critical factors for improving wafer yield.},
  keywords = {adaptive neuro-fuzzy inference system (anfis),chemical mechanical planarization (cmp),chemical-mechanical planarization,contact,neural network (nn),optimization,polishing process,profile},
  langid = {english},
  number = {1}
}

@article{liLongShort2020,
  ids = {liLongShort2020a},
  title = {Long-{{Short Term Spatiotemporal Tensor Prediction}} for {{Passenger Flow Profile}}},
  author = {Li, Ziyue and Yan, Hao and Zhang, Chen and Tsung, Fugee},
  date = {2020},
  journaltitle = {IEEE Robotics and Automation Letters},
  shortjournal = {IEEE Robot. Autom. Lett.},
  pages = {1--1},
  issn = {2377-3766, 2377-3774},
  doi = {10.1109/LRA.2020.3004785},
  url = {https://ieeexplore.ieee.org/document/9126133/},
  urldate = {2020-07-08},
  abstract = {Spatiotemporal data are very common in many applications, such as manufacturing systems and transportation systems. Given the intrinsic complex spatial and temporal correlations of such data, short-term and long-term prediction for spatiotemporal data is often very challenging. Most of the traditional statistical models fail to preserve innate features in data alongside their complex correlations. In this paper, we focus on a tensorbased prediction method and propose several practical techniques to improve both long-term and short-term prediction accuracy. For long-term prediction, we propose the “tensor decomposition + 2-Dimensional Auto-Regressive Moving Average (2D-ARMA)” model, and an effective way to update prediction in real-time; For short-term prediction, we propose to conduct tensor completion based on tensor clustering to avoid oversimplification and ensure accuracy. A case study based on the metro passenger flow data is conducted to demonstrate the improved performance.},
  file = {/Users/hyan46/Dropbox (ASU)/ZoteroData/Li et al_2020_Long-Short Term Spatiotemporal Tensor Prediction for Passenger Flow Profile.pdf},
  langid = {english}
}

@article{liMultitaskInReview,
  title = {Multi-Task {{Learning}} with {{Latent Variation Decomposition}} for {{Multivariate Responses}} in a {{Manufacturing Network}}},
  author = {Li, Yifu and Yan, Hao and {Jin, Ran}},
  year = {In Review},
  journaltitle = {Technometrics},
  abstract = {Modeling multiple similar-but-non-identical systems in a manufacturing network is extensively used when data are collected from a single system only carries a limited amount of information. One popular statistical learning framework for jointly modeling multiple systems is multi-task learning (MTL), which treats the modeling of one system as one task of learning. Multi-task learning benefits from the similarities among systems and use the common features or model parameters to reflect such similarities. However, existing MTL becomes much less effective if the information in data is insufficient to model the relationship between the input and output variables. This is mainly because important latent factors are missing or unmeasurable in the MTL. In this work, we proposed an MTL framework for multivariate or profile responses by decomposing the variation among systems into explainable variation, associated with variables with data, and latent variation unobserved in the model, associated with latent basis functions. The proposed method can both improve the prediction accuracy and interpretability of modeling. The results from the simulation and a silicon ingot manufacturing case study demonstrate the benefit of incorporating the latent variation term to explain the variation uncaptured/unexplained by the observable variables in system modeling.}
}

@article{linCollaborative2018,
  title = {A {{Collaborative Learning Framework}} for {{Estimating Many Individualized Regression Models}} in a {{Heterogeneous Population}}},
  author = {Lin, Ying and Liu, Kaibo and Byon, Eunshin and Qian, Xiaoning and Liu, Shan and Huang, Shuai},
  date = {2018-03},
  journaltitle = {IEEE Transactions on Reliability},
  shortjournal = {IEEE Trans. Rel.},
  volume = {67},
  pages = {328--341},
  issn = {0018-9529, 1558-1721},
  doi = {10.1109/TR.2017.2767941},
  url = {http://ieeexplore.ieee.org/document/8169076/},
  urldate = {2020-07-04},
  abstract = {Mixed-effect models (MEMs) have been found very useful for modeling complex dataset where many similar individualized regression models should be estimated. Like many statistical models, the success of these models builds on the assumption that a central tendency can effectively establish the population-level characteristics and covariates are sufficient to characterize the individual variation as derivation from the center. In many real-world problems, however, the dataset is collected from a rather heterogeneous population, where each individual has a distinct model. To fill in this gap, we propose a collaborative learning framework that provides a generic methodology for estimating a heterogeneous population of individualized regression models by exploiting the idea of “canonical models” and model regularization. By using a set of canonical models to represent the heterogeneous population characteristics, the canonical models span the modeling space for the individuals’ models, e.g., although each individual model is distinct, its model parameter vector can be represented by the parameter vectors of the canonical models. Theoretical analysis is also conducted to reveal a connection between the proposed method and the MEMs. Both simulation studies and applications on Alzheimer’s disease and degradation modeling of turbofan engines demonstrate the efficacy of the proposed method.},
  file = {/Users/hyan46/Dropbox (ASU)/ZoteroData/Lin et al_2018_A Collaborative Learning Framework for Estimating Many Individualized2.pdf},
  keywords = {Data: Profiles,People: Kaibo Liu,Problem: Prognostics},
  langid = {english},
  number = {1}
}

@article{linPrincipal2008,
  title = {Principal {{Component Analysis Based}} on {{Wavelet Characteristics Applied}} to {{Automated Surface Defect Inspection}}},
  author = {Lin, Hong-Dar and Chung, Chung-Yu and Lin, Wan-Ting},
  date = {2008},
  volume = {3},
  pages = {10},
  abstract = {Automated visual inspection, a crucial manufacturing step, has been replacing the more time-consuming and less accurate human inspection. This research explores automated visual inspection of surface defects in a light-emitting diode (LED) chip. Commonly found on chip surface are water-spot blemishes which impair the appearance and functionality of LEDs. Automated inspection of water-spot defects is difficult because they have a semi-opaque appearance and a low intensity contrast with the rough exterior of the LED chip. Moreover, the defect may fall across two different background textures, which further increases detection difficulties. The one-level Haar wavelet transform is first used to decompose a chip image and extract four wavelet characteristics. Then, wavelet-based principal component analysis (WPCA) and Hotelling statistic (WHS) approaches are respectively applied to integrate the multiple wavelet characteristics. Finally, the principal component analysis of WPCA and the Hotelling control limit of WHS individually judge the existence of defects. Experimental results show that the proposed WPCA method achieves detection rates of above 93.8\% and false alarm rates of below 3.6\%, and outperforms other methods. A valid computer-aided visual defect inspection system is contributed to help meet the quality control needs of LED chip manufacturers.},
  file = {/Users/hyan46/Dropbox (ASU)/ZoteroData/Lin et al_2008_Principal Component Analysis Based on Wavelet Characteristics Applied to.pdf},
  langid = {english},
  number = {4}
}

@article{linSelective2018,
  title = {Selective Sensing of a Heterogeneous Population of Units with Dynamic Health Conditions},
  author = {Lin, Ying and Liu, Shan and Huang, Shuai},
  date = {2018-12-02},
  journaltitle = {IISE Transactions},
  shortjournal = {IISE Transactions},
  volume = {50},
  pages = {1076--1088},
  issn = {2472-5854, 2472-5862},
  doi = {10.1080/24725854.2018.1470357},
  url = {https://www.tandfonline.com/doi/full/10.1080/24725854.2018.1470357},
  urldate = {2020-07-04},
  abstract = {Monitoring a large number of units whose health conditions follow complex dynamic evolution is a challenging problem in many healthcare and engineering applications. For instance, a unit may represent a patient in a healthcare application or a machine in a manufacturing process. Challenges mainly arise from: (i) insufficient data collection that results in limited measurements for each unit to build an accurate personalized model in the prognostic modeling stage; and (ii) limited capacity to further collect surveillance measurement of the units in the monitoring stage. In this study, we develop a selective sensing method that integrates prognostic models, collaborative learning, and sensing resource allocation to efficiently and economically monitor a large number of units by exploiting the similarity between them. We showcased the effectiveness of the proposed method using two real-world applications; one on depression monitoring and another with cognitive degradation monitoring for Alzheimer’s disease. Comparing with existing benchmark methods such as the ranking-and-selection method, our fully integrated prognosis-driven selective sensing method enables more accurate and faster identification of high-risk individuals.},
  file = {/Users/hyan46/Dropbox (ASU)/ZoteroData/Lin et al_2018_Selective sensing of a heterogeneous population of units with dynamic health.pdf},
  keywords = {Application: Health,Method: Adaptive Sampling,People: Shuai Huang,Problem: Process Monitoring,Problem: Prognostics},
  langid = {english},
  number = {12}
}

@article{liOptimal2010,
  title = {Optimal Sensor Allocation by Integrating Causal Models and Set-Covering Algorithms},
  author = {Li, Jing and Jin, Jionghua},
  date = {2010-05-28},
  journaltitle = {IIE Transactions},
  volume = {42},
  pages = {564--576},
  publisher = {{Taylor \& Francis}},
  issn = {0740-817X},
  doi = {10.1080/07408170903232597},
  url = {https://doi.org/10.1080/07408170903232597},
  urldate = {2020-07-04},
  abstract = {Massive amounts of data are generated in Distributed Sensor Networks (DSNs), posing challenges to effective and efficient detection of system abnormality through data analysis. This article proposes a new method for optimal sensor allocation in a DSN with the objective of timely detection of the abnormalities in a underlying physical system. This method involves two steps: first, a Bayesian Network (BN) is built to represent the causal relationships among the physical variables in the system; second, an integrated algorithm by combining the BN and a set-covering algorithm is developed to determine which physical variables should be sensed, in order to minimize the total sensing cost as well as satisfy a prescribed detectability requirement. Case studies are performed on a hot forming process and a large-scale cap alignment process, showing that the developed algorithm satisfies both the cost and detectability requirements.},
  annotation = {\_eprint: https://doi.org/10.1080/07408170903232597},
  file = {/Users/hyan46/Dropbox (ASU)/ZoteroData/Li_Jin_2010_Optimal sensor allocation by integrating causal models and set-covering.pdf;/Users/hyan46/Zotero/storage/SWVQ5DI8/07408170903232597.html},
  keywords = {Method: Causal,People: Judy Jin},
  number = {8}
}

@article{liPairwise2018,
  title = {Pairwise {{Estimation}} of {{Multivariate Gaussian Process Models With Replicated Observations}}: {{Application}} to {{Multivariate Profile Monitoring}}},
  shorttitle = {Pairwise {{Estimation}} of {{Multivariate Gaussian Process Models With Replicated Observations}}},
  author = {Li, Yongxiang and Zhou, Qiang and Huang, Xiaohu and Zeng, Li},
  date = {2018-01-02},
  journaltitle = {Technometrics},
  shortjournal = {Technometrics},
  volume = {60},
  pages = {70--78},
  issn = {0040-1706, 1537-2723},
  doi = {10.1080/00401706.2017.1305298},
  url = {https://www.tandfonline.com/doi/full/10.1080/00401706.2017.1305298},
  urldate = {2020-07-07},
  abstract = {Profile monitoring is often conducted when the product quality is characterized by profiles. Although existing methods almost exclusively deal with univariate profiles, observations of multivariate profile data are increasingly encountered in practice. These data are seldom analyzed in the area of statistical process control due to lack of effective modeling tools. In this article, we propose to analyze them using the multivariate Gaussian process model, which offers a natural way to accommodate both within-profile and betweenprofile correlations. To mitigate the prohibitively high computation in building such models, a pairwise estimation strategy is adopted. Asymptotic normality of the parameter estimates from this approach has been established. Comprehensive simulation studies are conducted. In the case study, the method has been demonstrated using transmittance profiles from low-emittance glass. Supplementary materials for this article are available online.},
  file = {/Users/hyan46/Zotero/storage/28FNPLCA/Li et al. - 2018 - Pairwise Estimation of Multivariate Gaussian Proce.pdf},
  keywords = {Data: Profiles,Method: Functional,Method: Kernel,Problem: Process Monitoring},
  langid = {english},
  number = {1}
}

@inproceedings{liTensor2020,
  title = {Tensor {{Completion}} for {{Weakly}}-Dependent {{Data}} on {{Graph}} for {{Metro Passenger Flow Prediction}}},
  booktitle = {Thirty-{{Fourth AAAI Conference}} on {{Artificial Intelligence}}},
  author = {Li, Ziyue and Sergin, Nurettin Dorukhan and Yan, Hao and Zhang, Chen and Tsung, Fugee},
  date = {2020-12},
  doi = {10.1609/aaai.v34i04.5915},
  url = {http://arxiv.org/abs/1912.05693},
  abstract = {Low-rank tensor decomposition and completion have attracted significant interest from academia given the ubiquity of tensor data. However, the low-rank structure is a global property, which will not be fulfilled when the data presents complex and weak dependencies given specific graph structures. One particular application that motivates this study is the spatiotemporal data analysis. As shown in the preliminary study, weakly dependencies can worsen the low-rank tensor completion performance. In this paper, we propose a novel low-rank CANDECOMP / PARAFAC (CP) tensor decomposition and completion framework by introducing the \$L\_\{1\}\$-norm penalty and Graph Laplacian penalty to model the weakly dependency on graph. We further propose an efficient optimization algorithm based on the Block Coordinate Descent for efficient estimation. A case study based on the metro passenger flow data in Hong Kong is conducted to demonstrate improved performance over the regular tensor completion methods.},
  annotation = {\_eprint: 1912.05693},
  file = {/Users/hyan46/Dropbox (ASU)/ZoteroData/Li et al_2020_Tensor Completion for Weakly-dependent Data on Graph for Metro Passenger Flow3.pdf},
  keywords = {Application: Traffic,Data: Time Series,Method: Tensor,Problem: Forecasting}
}

@article{liuAdaptive2014,
  title = {Adaptive {{Sensor Allocation Strategy}} for {{Process Monitoring}} and {{Diagnosis}} in a {{Bayesian Network}}},
  author = {Liu, Kaibo and Zhang, Xi and Shi, Jianjun},
  date = {2014-04},
  journaltitle = {IEEE Transactions on Automation Science and Engineering},
  shortjournal = {IEEE Trans. Automat. Sci. Eng.},
  volume = {11},
  pages = {452--462},
  issn = {1545-5955, 1558-3783},
  doi = {10.1109/TASE.2013.2287101},
  url = {http://ieeexplore.ieee.org/document/6676856/},
  urldate = {2020-07-04},
  abstract = {Multivariate process control in Distributed Sensor Networks (DSNs) is an important and challenging topic. Although a fully deployed sensor network will minimize information loss, the associated sensing cost can be overwhelming. Many efforts have been made to investigate the optimal sensor allocation strategy for different process control applications; however, most of them assume that the sensor layout is fixed once sensors are deployed in the system. This paper proposes a novel approach to adaptively reallocate sensor resources based on online observations, which can enhance both monitoring and diagnosis capabilities. The proposed adaptive sensor allocation strategy addresses two fundamental issues: when to reallocate sensors and how to update sensor layout. A max–min criterion is developed to manage sensor reallocation and process change detection in an integrated manner. To investigate the adaptive strategy, a Bayesian Network (BN) model is assumed available to represent the causal relationships among a set of variables. Case studies are performed on a hot forming process and a cap alignment process to illustrate the procedure and evaluate the performance of the proposed method under different fault scenarios.},
  file = {/Users/hyan46/Dropbox (ASU)/ZoteroData/Liu et al_2014_Adaptive Sensor Allocation Strategy for Process Monitoring and Diagnosis in a.pdf},
  keywords = {Application: Hot Foaming,Method: Adaptive Sampling,Method: Causal,People: Kaibo Liu,Problem: Process Monitoring},
  langid = {english},
  number = {2}
}

@article{liuAdaptive2015,
  title = {An {{Adaptive Sampling Strategy}} for {{Online High}}-{{Dimensional Process Monitoring}}},
  author = {Liu, Kaibo and Mei, Yajun and Shi, Jianjun},
  date = {2015-07-03},
  journaltitle = {Technometrics},
  shortjournal = {Technometrics},
  volume = {57},
  pages = {305--319},
  issn = {0040-1706, 1537-2723},
  doi = {10.1080/00401706.2014.947005},
  url = {http://www.tandfonline.com/doi/full/10.1080/00401706.2014.947005},
  urldate = {2020-07-04},
  file = {/Users/hyan46/Dropbox (ASU)/ZoteroData/Liu et al_2015_An Adaptive Sampling Strategy for Online High-Dimensional Process Monitoring.pdf},
  keywords = {Application: Solar Flare,Method: Adaptive Sampling,People: Kaibo Liu,Problem: Process Monitoring},
  langid = {english},
  number = {3}
}

@article{liuDataLevel2013,
  title = {A {{Data}}-{{Level Fusion Model}} for {{Developing Composite Health Indices}} for {{Degradation Modeling}} and {{Prognostic Analysis}}},
  author = {Liu, Kaibo and Gebraeel, Nagi Z. and Shi, Jianjun},
  date = {2013-07},
  journaltitle = {IEEE Transactions on Automation Science and Engineering},
  shortjournal = {IEEE Trans. Automat. Sci. Eng.},
  volume = {10},
  pages = {652--664},
  issn = {1545-5955, 1558-3783},
  doi = {10.1109/TASE.2013.2250282},
  url = {https://ieeexplore.ieee.org/document/6496166/},
  urldate = {2020-07-04},
  abstract = {Prognostics involves the effective utilization of condition or performance-based sensor signals to accurately estimate the remaining lifetime of partially degraded systems and components. The rapid development of sensor technology, has led to the use of multiple sensors to monitor the condition of an engineering system. It is therefore important to develop methodologies capable of integrating data from multiple sensors with the goal of improving the accuracy of predicting remaining lifetime. Although numerous efforts have focused on developing feature-level and decision-level fusion methodologies for prognostics, little research has targeted the development of “data-level” fusion models. In this paper, we present a methodology for constructing a composite health index for characterizing the performance of a system through the fusion of multiple degradation-based sensor data. This methodology includes data selection, data processing, and data fusion steps that lead to an improved degradation-based prognostic model. Our goal is that the composite health index provides a much better characterization of the condition of a system compared to relying solely on data from an individual sensor. Our methodology was evaluated through a case study involving a degradation dataset of an aircraft gas turbine engine that was generated by the Commercial Modular Aero-Propulsion System Simulation (C-MAPSS).},
  file = {/Users/hyan46/Dropbox (ASU)/ZoteroData/Liu et al_2013_A Data-Level Fusion Model for Developing Composite Health Indices for.pdf},
  keywords = {Application: Engine,Method: Health Index,People: Kaibo Liu},
  langid = {english},
  number = {3}
}

@article{liuDiagnosing2013,
  title = {Diagnosing {{Multistage Manufacturing Processes With Engineering}}-{{Driven Factor Analysis Considering Sampling Uncertainty}}},
  author = {Liu, Jian and Jin, Jionghua},
  date = {2013-08-01},
  journaltitle = {Journal of Manufacturing Science and Engineering},
  volume = {135},
  pages = {041020},
  issn = {1087-1357, 1528-8935},
  doi = {10.1115/1.4024661},
  url = {https://asmedigitalcollection.asme.org/manufacturingscience/article/doi/10.1115/1.4024661/694765/Diagnosing-Multistage-Manufacturing-Processes-With},
  urldate = {2020-07-04},
  abstract = {A new engineering-driven factor analysis (EDFA) method has been developed to assist the variation source identification for multistage manufacturing processes (MMPs). The proposed method investigated how to fully utilize qualitative engineering knowledge of the spatial variation patterns to guide the factor rotation. It is shown that ideal identification can be achieved by matching the rotated factor loading vectors with the qualitative indicator vectors (IV) that are defined according to spatial variation patterns based on the design constraints. However, the random sampling variability may significantly affect the estimation of the rotated factor loading vectors, leading to the deviations from their true values. These deviations may change the matching results and cause misidentification of the actual variation sources. By using implicit differentiation approach, this paper derives the asymptotic distribution and the associated variance-covariance matrix of the rotated factor loading vectors. Therefore, by considering the effect of sample estimation variability, the variation sources identification problem is reformulated as an asymptotic statistical test of the hypothesized match between the rotated factor loading vectors and the indicator vectors. A real-world case study is provided to demonstrate the effectiveness of the proposed matching method and its robustness to the sample uncertainty.},
  file = {/Users/hyan46/Dropbox (ASU)/ZoteroData/Liu_Jin_2013_Diagnosing Multistage Manufacturing Processes With Engineering-Driven Factor.pdf},
  keywords = {Application: Assembly,Application: Manufacturing,People: Judy Jin,Problem: Process Monitoring},
  langid = {english},
  number = {4}
}

@article{liuDirichlet2017,
  ids = {liuDirichlet2017a},
  title = {Dirichlet {{Process Gaussian Mixture Models}} for {{Real}}-{{Time Monitoring}} and {{Their Application}} to {{Chemical Mechanical Planarization}}},
  author = {Liu, J. and Beyca, O. F. and Rao, P. K. and Kong, Z. and Bukkapatnam, Satish},
  date = {2017-01},
  journaltitle = {Ieee Transactions on Automation Science and Engineering},
  shortjournal = {Ieee T Autom Sci Eng Ieee T Autom Sci Eng},
  volume = {14},
  pages = {208--221},
  issn = {1545-5955},
  url = {://WOS:000391382700019},
  abstract = {The goal of this work is to use sensor data for online detection and identification of process anomalies (faults). In pursuit of this goal, we propose Dirichlet process Gaussian mixture (DPGM) models. The proposed DPGM models have two novel outcomes: 1) DP-based statistical process control (SPC) chart for anomaly detection and 2) unsupervised recurrent hierarchical DP clustering model for identification of specific process anomalies. The presented DPGM models are validated using numerical simulation studies as well as wireless vibration signals acquired from an experimental semiconductor chemical mechanical planarization (CMP) test bed. Through these numerically simulated and experimental sensor data, we test the hypotheses that DPGM models have significantly lower detection delays compared with SPC charts in terms of the average run length (ARL1) and higher defect identification accuracies (F-score) than popular clustering techniques, such as mean shift. For instance, the DP-based SPC chart detects pad wear anomaly in CMP within 50 ms, as opposed to over 140 ms with conventional control charts. Likewise, DPGM models are able to classify different anomalies in CMP. Note to Practitioners-This paper forwards novel Dirichlet process Gaussian mixture (DPGM) models for online process quality monitoring. The practical outcome is that the deleterious impact of process drifts on product quality is identified in their early stages using the presented DPGM models. For instance, sensor signal patterns from contemporary advanced manufacturing processes rarely follow distribution symmetry or normality assumptions endemic to traditional statistical process control (SPC) methods. These assumptions limit the effectiveness of traditional SPC methods for detection of process anomalies from complex heterogeneous sensor data. In comparison, the proposed DP-based SPC is capable of detecting process changes in the sensor data notwithstanding the characteristics of the underlying distributions. Moreover, we show that the recurrent hierarchical DP clustering model identifies process anomalies with higher fidelity compared with traditional methods, such as mean shift clustering.},
  keywords = {chemical mechanical planarization (cmp),cmp,defect,density-estimation,dirichlet process (dp),dp gaussian mixture (dpgm) models,fault detection,mrr,neural-networks,online process monitoring,recurrent hierarchical dp (rhdp) clustering},
  langid = {english},
  number = {1}
}

@article{liuHigh,
  title = {High {{Dimensional Robust Sparse Regression}}},
  author = {Liu, Liu and Shen, Yanyao and Li, Tianyang and Caramanis, Constantine},
  pages = {10},
  abstract = {We provide a novel – and to the best of our knowledge, the first – algorithm for high dimensional sparse regression with constant fraction of corruptions in explanatory and/or response variables. Our algorithm recovers the true sparse parameters with sub-linear sample complexity, in the presence of a constant fraction of arbitrary corruptions. Our main contribution is a robust variant of Iterative Hard Thresholding. Using this, we provide accurate estimators: when the covariance matrix in sparse regression is identity, our error guarantee is near information-theoretically optimal. We then deal with robust sparse regression with unknown structured covariance matrix. We propose a filtering algorithm which consists of a novel randomized outlier removal technique for robust sparse mean estimation that may be of interest in its own right: the filtering algorithm is flexible enough to deal with unknown covariance. Also, it is orderwise more efficient computationally than the ellipsoid algorithm. Using sub-linear sample complexity, our algorithm achieves the best known (and first) error guarantee. We demonstrate the effectiveness on large-scale sparse regression problems with arbitrary corruptions.},
  file = {/Users/hyan46/Dropbox (ASU)/ZoteroData/Liu et al_High Dimensional Robust Sparse Regression.pdf},
  langid = {english}
}

@article{liuIntegration2016,
  title = {Integration of {{Data Fusion Methodology}} and {{Degradation Modeling Process}} to {{Improve Prognostics}}},
  author = {Liu, Kaibo and Huang, Shuai},
  date = {2016-01},
  journaltitle = {IEEE Transactions on Automation Science and Engineering},
  shortjournal = {IEEE Trans. Automat. Sci. Eng.},
  volume = {13},
  pages = {344--354},
  issn = {1545-5955, 1558-3783},
  doi = {10.1109/TASE.2014.2349733},
  url = {https://ieeexplore.ieee.org/document/6902828/},
  urldate = {2020-07-04},
  abstract = {The rapid development of sensing and computing technologies has enabled multiple sensors embedded in a system to simultaneously monitor the degradation status of an operation unit. This creates a data-rich environment for degradation modeling and prognostics that could potentially lead to an accurate inference about the remaining lifetime of the degraded unit. However, as data collected from multiple sensors are often correlated and each sensor data contains only partial information about the same degradation process, there is a pressing need to develop data fusion methodologies that can integrate the data from multiple sensors for better characterizing the stochastic nature of the degradation process. Unlike other existing data fusion methodologies that treat the fusion procedure and the degradation modeling as two separate tasks, this paper aims at solving these two challenging problems in a unified manner. Specifically, we develop a methodology to construct a health index via fusion of multiple degradation-based sensor data. Our goal is that the developed health index provides a much better characterization of the condition of the unit and thus leads to a better prediction of the remaining lifetime. A case study that involves a degradation dataset of an aircraft gas turbine engine is implemented to numerically evaluate and compare the prognostic performance of the developed health index with existing literature.},
  file = {/Users/hyan46/Dropbox (ASU)/ZoteroData/Liu_Huang_2016_Integration of Data Fusion Methodology and Degradation Modeling Process to.pdf},
  keywords = {Application: Engine,Data: Profiles,Method: Health Index,People: Kaibo Liu,Problem: Prognostics},
  langid = {english},
  number = {1}
}

@article{liuIntegration2019,
  ids = {liuIntegration2019a},
  title = {Integration of Biological and Statistical Models toward Personalized Radiation Therapy of Cancer},
  author = {Liu, Xiaonan and Fatyga, Mirek and Wu, Teresa and Li, Jing},
  date = {2019-03-04},
  journaltitle = {IISE Transactions},
  shortjournal = {IISE Transactions},
  volume = {51},
  pages = {311--321},
  issn = {2472-5854, 2472-5862},
  doi = {10.1080/24725854.2018.1486054},
  url = {https://www.tandfonline.com/doi/full/10.1080/24725854.2018.1486054},
  urldate = {2020-07-04},
  abstract = {Radiation Therapy (RT) is one of the most common treatments for cancer. To understand the impact of radiation toxicity on normal tissue, a Normal Tissue Complication Probability (NTCP) model is needed to link RT dose with radiation-induced complications. There are two types of NTCP models: biological and statistical models. Biological models have good generalizability but low accuracy, as they cannot factor in patient-specific information. Statistical models can incorporate patient-specific variables, but may not generalize well across different studies. We propose an integrated model that borrows strength from both biological and statistical models. Specifically, we propose a novel model formulation followed by an efficient parameter estimation algorithm, and investigate statistical properties of the estimator. We apply the integrated model to a real dataset of prostate cancer patients treated with Intensity Modulated RT at the Mayo Clinic Arizona, who are at risk of developing the grade 2þ acute rectal complication. The integrated model achieves an Area Under the Curve (AUC) level of 0.82 in prediction, whereas the AUCs for the biological and statistical models are only 0.66 and 0.76, respectively. The superior performance of the integrated model is also consistently observed over different simulation experiments.},
  file = {/Users/hyan46/Dropbox (ASU)/ZoteroData/Liu et al_2019_Integration of biological and statistical models toward personalized radiation.pdf},
  keywords = {Application: Health,Method: Physics,People: Jing Li},
  langid = {english},
  number = {3}
}

@article{liuIoTEnabled2015,
  title = {{{IoT}}-{{Enabled System Informatics}} for {{Service Decision Making}}},
  author = {Liu, Kaibo and Shi, Jianjun},
  date = {2015},
  journaltitle = {IEEE Intelligent Systems},
  pages = {3},
  file = {/Users/hyan46/Dropbox (ASU)/ZoteroData/Liu_Shi_2015_IoT-Enabled System Informatics for Service Decision Making.pdf},
  keywords = {Data: Profiles,People: Kaibo Liu,Problem: Prognostics},
  langid = {english}
}

@inproceedings{liuMultimodality2019,
  title = {Multimodality {{Information Fusion}} for {{Aging Pipe Strength}} and {{Toughness Estimation Using Bayesian Networks}}},
  booktitle = {Proceedings of the {{Annual Conference}} of the {{PHM Society}}},
  author = {Liu, Yongming and Chen, Jie},
  date = {2019},
  volume = {11},
  isbn = {2325-0178},
  number = {1}
}

@article{liuObjectiveoriented2013,
  title = {Objective-Oriented Optimal Sensor Allocation Strategy for Process Monitoring and Diagnosis by Multivariate Analysis in a {{Bayesian}} Network},
  author = {Liu, Kaibo and Shi, Jianjun},
  date = {2013-06},
  journaltitle = {IIE Transactions},
  shortjournal = {IIE Transactions},
  volume = {45},
  pages = {630--643},
  issn = {0740-817X, 1545-8830},
  doi = {10.1080/0740817X.2012.725505},
  url = {http://www.tandfonline.com/doi/abs/10.1080/0740817X.2012.725505},
  urldate = {2020-07-04},
  abstract = {Measurement strategy and sensor allocation have a direct impact on the product quality, productivity, and cost. This article studies the couplings or interactions between the optimal design of a sensor system and quality management in a manufacturing system, which can improve cost-effectiveness and production yield by considering sensor cost, process change detection speed, and fault diagnosis accuracy. Based on an established definition of sensor allocation in a Bayesian network, an algorithm named “Best Allocation Subsets by Intelligent Search” (BASIS) is developed in this article to obtain the optimal sensor allocation design at minimum cost under different specified Average Run Length (ARL) requirements. Unlike previous approaches reported in the literature, the BASIS algorithm is developed based on investigating a multivariate T2 control chart when only partial observations are available. After implementing the derived optimal sensor solution, a diagnosis ranking method is proposed to find the root cause variables by ranking all of the identified potential faults. Two case studies are conducted on a hot forming process and a cap alignment process to illustrate and evaluate the developed methods.},
  file = {/Users/hyan46/Dropbox (ASU)/ZoteroData/Liu_Shi_2013_Objective-oriented optimal sensor allocation strategy for process monitoring.pdf},
  keywords = {Application: Hot Foaming,Method: Adaptive Sampling,People: Kaibo Liu,Problem: Process Monitoring},
  langid = {english},
  number = {6}
}

@article{liuOptimize2017,
  title = {Optimize the {{Signal Quality}} of the {{Composite Health Index}} via {{Data Fusion}} for {{Degradation Modeling}} and {{Prognostic Analysis}}},
  author = {Liu, Kaibo and Chehade, Abdallah and Song, Changyue},
  date = {2017-07},
  journaltitle = {IEEE Transactions on Automation Science and Engineering},
  shortjournal = {IEEE Trans. Automat. Sci. Eng.},
  volume = {14},
  pages = {1504--1514},
  issn = {1545-5955, 1558-3783},
  doi = {10.1109/TASE.2015.2446752},
  url = {http://ieeexplore.ieee.org/document/7165684/},
  urldate = {2020-07-04},
  abstract = {Due to the rapid development of sensing and computing technologies, multiple sensors have been widely used in a system to simultaneously monitor the health status of an operating unit. Such a data-rich environment creates an unprecedented opportunity to better understand the degradation behavior of the system and make accurate inferences about the remaining lifetime. Since data collected from multiple sensors are often correlated and each sensor data contains only partial information about the degraded unit, data fusion methodologies that integrate the data from multiple sensors provide an essential tool for degradation modeling and prognostics. To achieve this goal, a fundamental question needs to be answered first is how to measure the signal quality of a degradation signal. If such a question can be addressed, then the data fusion approach can be simplified as a mission-specific task: to construct a composite health index with the goal of optimizing its signal quality. In this paper, a new signal-to-noise ratio (SNR) metric that is tailored to the needs of degradation signals is proposed. Then, based on the new quality metric, we develop a data-level fusion model to construct a health index via fusion of multiple degradation-based sensor data. Our goal is that the developed health index provides a much better characterization of the health condition of the unit and thus leads to a better prediction of the remaining lifetime. A case study that involves the degradation dataset of aircraft gas turbine engines is conducted to numerically evaluate the performance of the developed health index regarding prognostics and further compare the result with existing literature.},
  file = {/Users/hyan46/Dropbox (ASU)/ZoteroData/Liu et al_2017_Optimize the Signal Quality of the Composite Health Index via Data Fusion for.pdf},
  keywords = {Application: Engine,Data: Profiles,Method: Health Index,People: Kaibo Liu,Problem: Prognostics},
  langid = {english},
  number = {3}
}

@article{liuRealtime2019,
  title = {Real-Time Quality Monitoring and Diagnosis for Manufacturing Process Profiles Based on Deep Belief Networks},
  author = {Liu, Yumin and Zhou, Haofei and Tsung, Fugee and Zhang, Shuai},
  date = {2019-10},
  journaltitle = {Computers \& Industrial Engineering},
  shortjournal = {Computers \& Industrial Engineering},
  volume = {136},
  pages = {494--503},
  issn = {03608352},
  doi = {10.1016/j.cie.2019.07.042},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0360835219304334},
  urldate = {2020-07-20},
  abstract = {A large number of real-time quality data are collected through various sensors in the manufacturing process. However, most process data are high-dimension, nonlinear and high-correlated, so that it is difficult to model the process profiles, which restricts the application of conventional statistical process control technique. Motivated by the powerful ability of deep belief network (DBN) to extract the essential features of input data, this paper develops a real-time quality monitoring and diagnosis scheme for manufacturing process profiles based on DBN. The profiles collected from a manufacturing process are mapped into quality spectra. A novel DBN recognition model for quality spectra is established in the off-line learning phase, which can be applied to monitor and diagnose the process profiles in the on-line phase. The effectiveness of DBN recognition model for manufacturing process profiles is demonstrated by simulation experiment, and a real injection molding process example is applied to analyze the performance. The results show that the proposed DBN model outperforms alternative methods.},
  file = {/Users/hyan46/Dropbox (ASU)/ZoteroData/Liu et al_2019_Real-time quality monitoring and diagnosis for manufacturing process profiles.pdf},
  keywords = {Application: Manufacturing,Method: Deep Learning},
  langid = {english}
}

@online{liuStein2019,
  title = {Stein {{Variational Gradient Descent}}: {{A General Purpose Bayesian Inference Algorithm}}},
  shorttitle = {Stein {{Variational Gradient Descent}}},
  author = {Liu, Qiang and Wang, Dilin},
  date = {2019-09-09},
  url = {http://arxiv.org/abs/1608.04471},
  urldate = {2021-03-02},
  abstract = {We propose a general purpose variational inference algorithm that forms a natural counterpart of gradient descent for optimization. Our method iteratively transports a set of particles to match the target distribution, by applying a form of functional gradient descent that minimizes the KL divergence. Empirical studies are performed on various real world models and datasets, on which our method is competitive with existing state-of-the-art methods. The derivation of our method is based on a new theoretical result that connects the derivative of KL divergence under smooth transforms with Stein’s identity and a recently proposed kernelized Stein discrepancy, which is of independent interest.},
  archiveprefix = {arXiv},
  eprint = {1608.04471},
  eprinttype = {arxiv},
  file = {/Users/hyan46/Dropbox (ASU)/ZoteroData/Liu_Wang_2019_Stein Variational Gradient Descent.pdf},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  langid = {english},
  primaryclass = {cs, stat}
}

@article{liuWafer2018,
  title = {Wafer Quality Monitoring Using Spatial {{Dirichlet}} Process Based Mixed-Effect Profile Modeling Scheme},
  author = {Liu, Jia Peter and Jin, Ran and Kong, Zhenyu James},
  date = {2018-07},
  journaltitle = {Journal of Manufacturing Systems},
  shortjournal = {Journal of Manufacturing Systems},
  volume = {48},
  pages = {21--32},
  issn = {02786125},
  doi = {10.1016/j.jmsy.2018.05.012},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0278612518300815},
  urldate = {2020-07-04},
  abstract = {The objective of this work is to develop a profile-based statistical process control scheme for efficaciously monitoring wafer thickness profiles with non-normality in an industrial wafer slicing process. This is an important research area because the geometric quality of semiconductor wafers in a slicing process has a direct impact on the functional integrity of semiconductor parts and the efficiency of the production. Since non-normality in profiles indicates the existence of inter-cluster variations (i.e., the profiles cannot be represented by a single mean profile with normally-distributed random noise), it deteriorates the effectiveness of many traditional statistical process control methods with normality assumption. To realize the objective of this work, a mixedeffect profile monitoring (MEPM) scheme is proposed. The MEPM scheme adaptively groups profile data into clusters and models the inter-cluster variations, consequently, enabling a robust statistical process control scheme for detecting deviant profile data. Capturing the clustering information of the profile data leads to a deep understanding and an accurate modeling of the spatial data. It is a significant improvement over the current practice of monitoring the geometric product quality by summary quality features (such as total thickness variation) or by profiles neglecting inter-cluster variations. In this paper, the MEPM scheme is tested for detecting the out-of-control wafers from a wafer slicing process. Based on wafer thickness profiles, the MEPM scheme outperforms other benchmark methods and identifies the deviant wafers with low average type II error (missed detection rate) as 0.039. This profile monitoring scheme is extensible to geometrical quality assurance for products in other processes.},
  file = {/Users/hyan46/Dropbox (ASU)/ZoteroData/Liu et al_2018_Wafer quality monitoring using spatial Dirichlet process based mixed-effect.pdf},
  keywords = {Application: Manufacturing,Application: Semiconductor,Data: Profiles,Method: Functional,People: James Kong,Problem: Process Monitoring},
  langid = {english}
}

@article{luanPrescriptive2017,
  title = {Prescriptive {{Modeling}} and {{Compensation}} of {{In}}-{{Plane Shape Deformation}} for 3-{{D Printed Freeform Products}}},
  author = {Luan, He and Huang, Qiang},
  date = {2017-01},
  journaltitle = {IEEE Transactions on Automation Science and Engineering},
  shortjournal = {IEEE Trans. Automat. Sci. Eng.},
  volume = {14},
  pages = {73--82},
  issn = {1545-5955, 1558-3783},
  doi = {10.1109/TASE.2016.2608955},
  url = {http://ieeexplore.ieee.org/document/7588128/},
  urldate = {2020-07-04},
  abstract = {Although 3-D printing or additive manufacturing (AM) holds great promise as a direct manufacturing technology, the geometric accuracy of AM built products remains a critical issue, especially for freeform products with complex geometric shapes. Efforts have long been attempted to improve the accuracy of AM built freeform products. But there is a lack of generic and prescriptive methodology transparent to specific designs and AM processes. This paper fills the gap by establishing the methodology to predict and compensate the in-plane (x − y plane) geometric deformation of AM built freeform products based on a limited number of simple trial shapes. Built upon our previous predictive model and optimal compensation study for the cylinder and polyhedron shapes, this paper makes a breakthrough by directly controlling arbitrary freeform shape deformation from computer-aided design. Experimental investigation using stereolithography process successfully validates the proposed prescriptive modeling and compensation methodology. This paper provides the prospect of proactively improving printing accuracy of arbitrary products built by a variety of AM processes.},
  file = {/Users/hyan46/Dropbox (ASU)/ZoteroData/Luan_Huang_2017_Prescriptive Modeling and Compensation of In-Plane Shape Deformation for 3-D.pdf},
  keywords = {Application: Additive Manufacturing,Application: Manufacturing,People: Qiang Huang},
  langid = {english},
  number = {1}
}

@article{lucasUsing2018,
  title = {Using {{Deep Neural Networks}} for {{Inverse Problems}} in {{Imaging}}: {{Beyond Analytical Methods}}},
  shorttitle = {Using {{Deep Neural Networks}} for {{Inverse Problems}} in {{Imaging}}},
  author = {Lucas, Alice and Iliadis, Michael and Molina, Rafael and Katsaggelos, Aggelos K.},
  date = {2018-01},
  journaltitle = {IEEE Signal Processing Magazine},
  shortjournal = {IEEE Signal Process. Mag.},
  volume = {35},
  pages = {20--36},
  issn = {1053-5888},
  doi = {10.1109/MSP.2017.2760358},
  url = {http://ieeexplore.ieee.org/document/8253590/},
  urldate = {2020-09-16},
  file = {/Users/hyan46/Zotero/storage/AU6RJBRA/Lucas et al. - 2018 - Using Deep Neural Networks for Inverse Problems in.pdf},
  langid = {english},
  number = {1}
}

@article{luDefect2004,
  title = {Defect Inspection of Patterned Thin Film Transistor-Liquid Crystal Display Panels Using a Fast Sub-Image-Based Singular Value Decomposition},
  author = {Lu, C.-J. and Tsai *, D.-M.},
  date = {2004-10-15},
  journaltitle = {International Journal of Production Research},
  shortjournal = {International Journal of Production Research},
  volume = {42},
  pages = {4331--4351},
  issn = {0020-7543, 1366-588X},
  doi = {10.1080/00207540410001716480},
  url = {https://www.tandfonline.com/doi/full/10.1080/00207540410001716480},
  urldate = {2020-07-15},
  file = {/Users/hyan46/Dropbox (ASU)/ZoteroData/Lu_Tsai _2004_Defect inspection of patterned thin film transistor-liquid crystal display.pdf},
  langid = {english},
  number = {20}
}

@article{lundbergUnified,
  title = {A {{Unified Approach}} to {{Interpreting Model Predictions}}},
  author = {Lundberg, Scott M and Lee, Su-In},
  pages = {10},
  abstract = {Understanding why a model makes a certain prediction can be as crucial as the prediction’s accuracy in many applications. However, the highest accuracy for large modern datasets is often achieved by complex models that even experts struggle to interpret, such as ensemble or deep learning models, creating a tension between accuracy and interpretability. In response, various methods have recently been proposed to help users interpret the predictions of complex models, but it is often unclear how these methods are related and when one method is preferable over another. To address this problem, we present a unified framework for interpreting predictions, SHAP (SHapley Additive exPlanations). SHAP assigns each feature an importance value for a particular prediction. Its novel components include: (1) the identification of a new class of additive feature importance measures, and (2) theoretical results showing there is a unique solution in this class with a set of desirable properties. The new class unifies six existing methods, notable because several recent methods in the class lack the proposed desirable properties. Based on insights from this unification, we present new methods that show improved computational performance and/or better consistency with human intuition than previous approaches.},
  file = {/Users/hyan46/Dropbox (ASU)/ZoteroData/Lundberg_Lee_A Unified Approach to Interpreting Model Predictions.pdf},
  langid = {english}
}

@article{mackaydavidjcBayesian1992,
  title = {Bayesian Interpolation},
  author = {{MacKay, David JC}},
  date = {1992},
  journaltitle = {Neural computation},
  volume = {4},
  pages = {415--447},
  file = {/Users/hyan46/Dropbox (ASU)/ZoteroData/MacKay, David JC_1992_Bayesian interpolation.pdf},
  number = {3}
}

@article{malladiGeneralized1999,
  title = {A {{Generalized Shiryayev Sequential Probability Ratio Test}} for {{Change Detection}} and {{Isolation}}},
  author = {Malladi, Durga P and Speyer, Jason L},
  date = {1999},
  journaltitle = {IEEE TRANSACTIONS ON AUTOMATIC CONTROL},
  volume = {44},
  pages = {13},
  abstract = {The authors derive an online multiple hypothesis Shiryayev Sequential Probability Ratio Test (SSPRT) by adopting a dynamic programming approach. It is shown that for a certain criterion of optimality, this generalized Shiryayev SPRT detects and isolates a change in hypothesis in the conditionally independent measurement sequence in minimum time, unlike the Wald SPRT, which assumes the entire measurement sequence to correspond to a single hypothesis. They consider the measurement cost, the cost of a false alarm, and the cost of a miss-alarm in our dynamic programming analysis. The algorithm is shown to be optimal in the infinite time case. Finally, the performance of the algorithm is evaluated by using a few examples. In particular, they implement the algorithm in a fault detection and identification scheme for advanced vehicle control systems.},
  file = {/Users/hyan46/Dropbox (ASU)/ZoteroData/Malladi_Speyer_1999_A Generalized Shiryayev Sequential Probability Ratio Test for Change Detection.pdf},
  langid = {english},
  number = {8}
}

@article{malsheAccurate2009,
  ids = {malsheAccurate2009a},
  title = {Accurate Prediction of Higher-Level Electronic Structure Energies for Large Databases Using Neural Networks, {{Hartree}}-{{Fock}} Energies, and Small Subsets of the Database},
  author = {Malshe, M. and Pukrittayakamee, A. and Raff, L. M. and Hagan, M. and Bukkapatnam, Satish and Komanduri, R.},
  date = {2009-09-28},
  journaltitle = {Journal of Chemical Physics},
  shortjournal = {J Chem Phys J Chem Phys},
  volume = {131},
  issn = {0021-9606},
  url = {://WOS:000270380300031},
  abstract = {A novel method is presented that significantly reduces the computational bottleneck of executing high-level, electronic structure calculations of the energies and their gradients for a large database that adequately samples the configuration space of importance for systems containing more than four atoms that are undergoing multiple, simultaneous reactions in several energetically open channels. The basis of the method is the high-degree of correlation that generally exists between the Hartree-Fock (HF) and higher-level electronic structure energies. It is shown that if the input vector to a neural network (NN) includes both the configuration coordinates and the HF energies of a small subset of the database, MP4(SDQ) energies with the same basis set can be predicted for the entire database using only the HF and MP4(SDQ) energies for the small subset and the HF energies for the remainder of the database. The predictive error is shown to be less than or equal to the NN fitting error if a NN is fitted to the entire database of higher-level electronic structure energies. The general method is applied to the computation of MP4(SDQ) energies of 68 308 configurations that comprise the database for the simultaneous, unimolecular decomposition of vinyl bromide into six different reaction channels. The predictive accuracy of the method is investigated by employing successively smaller subsets of the database to train the NN to predict the MP4(SDQ) energies of the remaining configurations of the database. The results indicate that for this system, the subset can be as small as 8\% of the total number of configurations in the database without loss of accuracy beyond that expected if a NN is employed to fit the higher-level energies for the entire database. The utilization of this procedure is shown to save about 78\% of the total computational time required for the execution of the MP4(SDQ) calculations. The sampling error involved with selection of the subset is shown to be about 10\% of the predictive error for the higher-level energies. A practical procedure for utilization of the method is outlined. It is suggested that the method will be equally applicable to the prediction of electronic structure energies computed using even higher-level methods than MP4(SDQ). (C) 2009 American Institute of Physics. [doi:10.1063/1.3231686]},
  keywords = {h-3(+)((1)a(1)'),interpolation,least-squares methods,reaction dynamics,representation,surfaces,system},
  langid = {english},
  number = {12}
}

@article{malsheDevelopment2009,
  ids = {malsheDevelopment2009a},
  title = {Development of Generalized Potential-Energy Surfaces Using Many-Body Expansions, Neural Networks, and Moiety Energy Approximations},
  author = {Malshe, M. and Narulkar, R. and Raff, L. M. and Hagan, M. and Bukkapatnam, Satish and Agrawal, P. M. and Komanduri, R.},
  date = {2009-05-14},
  journaltitle = {Journal of Chemical Physics},
  shortjournal = {J Chem Phys J Chem Phys},
  volume = {130},
  issn = {0021-9606},
  url = {://WOS:000266263200003},
  abstract = {A general method for the development of potential-energy hypersurfaces is presented. The method combines a many-body expansion to represent the potential-energy surface with two-layer neural networks (NN) for each M-body term in the summations. The total number of NNs required is significantly reduced by employing a moiety energy approximation. An algorithm is presented that efficiently adjusts all the coupled NN parameters to the database for the surface. Application of the method to four different systems of increasing complexity shows that the fitting accuracy of the method is good to excellent. For some cases, it exceeds that available by other methods currently in literature. The method is illustrated by fitting large databases of ab initio energies for Si-n (n=3,4,...,7) clusters obtained from density functional theory calculations and for vinyl bromide (C2H3Br) and all products for dissociation into six open reaction channels (12 if the reverse reactions are counted as separate open channels) that include C-H and C-Br bond scissions, three-center HBr dissociation, and three-center H-2 dissociation. The vinyl bromide database comprises the ab initio energies of 71 969 configurations computed at MP4(SDQ) level with a 6-31G(d,p) basis set for the carbon and hydrogen atoms and Huzinaga's (4333/433/4) basis set augmented with split outer s and p orbitals (43321/4321/4) and a polarization f orbital with an exponent of 0.5 for the bromine atom. It is found that an expansion truncated after the three-body terms is sufficient to fit the Si-5 system with a mean absolute testing set error of 5.693x10(-4) eV. Expansions truncated after the four-body terms for Si-n (n=3,4,5) and Si-n (n=3,4,...,7) provide fits whose mean absolute testing set errors are 0.0056 and 0.0212 eV, respectively. For vinyl bromide, a many-body expansion truncated after the four-body terms provides fitting accuracy with mean absolute testing set errors that range between 0.0782 and 0.0808 eV. These errors correspond to mean percent errors that fall in the range 0.98\%-1.01\%. Our best result using the present method truncated after the four-body summation with 16 NNs yields a testing set error that is 20.3\% higher than that obtained using a 15-dimensional (15-140-1) NN to fit the vinyl bromide database. This appears to be the price of the added simplicity of the many-body expansion procedure.},
  keywords = {ab-initio data,atom potentials,atomic clusters,atomic forces,classical dynamics calculations,component functions,dimensional model representations,dissociation energies,functional-approach,interpolation,intramolecular forces,least-squares methods,many-body problems,neural nets,organic compounds,potential energy functions,potential energy surfaces,rs-hdmr,silicon,vibrational energies},
  langid = {english},
  number = {18}
}

@article{malsheInput2010,
  ids = {malsheInput2010a},
  title = {Input Vector Optimization of Feed-Forward Neural Networks for Fitting Ab Initio Potential-Energy Databases},
  author = {Malshe, M. and Raff, L. M. and Hagan, M. and Bukkapatnam, Satish and Komanduri, R.},
  date = {2010-05-28},
  journaltitle = {Journal of Chemical Physics},
  shortjournal = {J Chem Phys J Chem Phys},
  volume = {132},
  issn = {0021-9606},
  url = {://WOS:000278183100004},
  abstract = {The variation in the fitting accuracy of neural networks (NNs) when used to fit databases comprising potential energies obtained from ab initio electronic structure calculations is investigated as a function of the number and nature of the elements employed in the input vector to the NN. Ab initio databases for H2O2, HONO, Si-5, and H2C=CHBr were employed in the investigations. These systems were chosen so as to include four-, five-, and six-body systems containing first, second, third, and fourth row elements with a wide variety of chemical bonding and whose conformations cover a wide range of structures that occur under high-energy machining conditions and in chemical reactions involving cis-trans isomerizations, six different types of two-center bond ruptures, and two different three-center dissociation reactions. The ab initio databases for these systems were obtained using density functional theory/B3LYP, MP2, and MP4 methods with extended basis sets. A total of 31 input vectors were investigated. In each case, the elements of the input vector were chosen from interatomic distances, inverse powers of the interatomic distance, three-body angles, and dihedral angles. Both redundant and nonredundant input vectors were investigated. The results show that among all the input vectors investigated, the set employed in the Z-matrix specification of the molecular configurations in the electronic structure calculations gave the lowest NN fitting accuracy for both Si-5 and vinyl bromide. The underlying reason for this result appears to be the discontinuity present in the dihedral angle for planar geometries. The use of trigometric functions of the angles as input elements produced significantly improved fitting accuracy as this choice eliminates the discontinuity. The most accurate fitting was obtained when the elements of the input vector were taken to have the form R-ij(-n), where the R-ij are the interatomic distances. When the Levenberg-Marquardt procedure was modified to permit error minimization with respect to n as well as the weights and biases of the NN, the optimum powers were all found to lie in the range of 1.625-2.38 for the four systems studied. No statistically significant increase in fitting accuracy was achieved for vinyl bromide when a different value of n was employed and optimized for each bond type. The rate of change in the fitting error with n is found to be very small when n is near its optimum value. Consequently, good fitting accuracy can be achieved by employing a value of n in the middle of the above range. The use of interparticle distances as elements of the input vector rather than the Z-matrix variables employed in the electronic structure calculations is found to reduce the rms fitting errors by factors of 8.86 and 1.67 for Si-5 and vinyl bromide, respectively. If the interparticle distances are replaced with input elements of the form R-ij(-n) with n optimized, further reductions in the rms error by a factor of 1.31 to 2.83 for the four systems investigated are obtained. A major advantage of using this procedure to increase NN fitting accuracy rather than increasing the number of neurons or the size of the database is that the required increase in computational effort is very small. (C) 2010 American Institute of Physics. [doi: 10.1063/1.3431624]},
  keywords = {ab initio calculations,bond angles,bond lengths,bonds (chemical),chemistry computing,density functional theory,dissociation,feedforward neural nets,hydrogen compounds,isomerisation,molecular configurations,molecular electronic states,optimisation,organic compounds,perturbation theory,physics computing,potential energy surfaces,silicon,surfaces},
  langid = {english},
  number = {20}
}

@article{malsheParametrization2008,
  ids = {malsheParametrization2008a},
  title = {Parametrization of Analytic Interatomic Potential Functions Using Neural Networks},
  author = {Malshe, M. and Narulkar, R. and Raff, L. M. and Hagan, M. and Bukkapatnam, Satish and Komanduri, R.},
  date = {2008-07-28},
  journaltitle = {Journal of Chemical Physics},
  shortjournal = {J Chem Phys J Chem Phys},
  volume = {129},
  issn = {0021-9606},
  url = {://WOS:000258171500016},
  abstract = {A generalized method that permits the parameters of an arbitrary empirical potential to be efficiently and accurately fitted to a database is presented. The method permits the values of a subset of the potential parameters to be considered as general functions of the internal coordinates that define the instantaneous configuration of the system. The parameters in this subset are computed by a generalized neural network (NN) with one or more hidden layers and an input vector with at least 3n-6 elements, where n is the number of atoms in the system. The Levenberg-Marquardt algorithm is employed to efficiently affect the optimization of the weights and biases of the NN as well as all other potential parameters being treated as constants rather than as functions of the input coordinates. In order to effect this minimization, the usual Jacobian employed in NN operations is modified to include the Jacobian of the computed errors with respect to the parameters of the potential function. The total Jacobian employed in each epoch of minimization is the concatenation of two Jacobians, one containing derivatives of the errors with respect to the weights and biases of the network, and the other with respect to the constant parameters of the potential function. The method provides three principal advantages. First, it obviates the problem of selecting the form of the functional dependence of the parameters upon the system's coordinates by employing a NN. If this network contains a sufficient number of neurons, it will automatically find something close to the best functional form. This is the case since Hornik , [Neural Networks 2, 359 (1989)] have shown that two-layer NNs with sigmoid transfer functions in the first hidden layer and linear functions in the output layer are universal approximators for analytic functions. Second, the entire fitting procedure is automated so that excellent fits are obtained rapidly with little human effort. Third, the method provides a procedure to avoid local minima in the multidimensional parameter hyperspace. As an illustrative example, the general method has been applied to the specific case of fitting the ab initio energies of Si-5 clusters that are observed in a molecular dynamics (MD) simulation of the machining of a silicon workpiece. The energies of the Si-5 configurations obtained in the MD calculations are computed using the B3LYP procedure with a 6-31G(**) basis set. The final ab initio database, which comprises the density functional theory energies of 10 202 Si-5 clusters, is fitted to an empirical Tersoff potential containing nine adjustable parameters, two of which are allowed to be the functions of the Si-5 configuration. The fitting error averaged over all 10 202 points is 0.0148 eV (1.43 kJ mol(-1)). This result is comparable to the accuracy achieved by more general fitting methods that do not rely on an assumed functional form for the potential surface. (C) 2008 American Institute of Physics.},
  keywords = {classical dynamics,feedforward networks,intramolecular energy-transfer,least-squares methods,molecular-dynamics simulations,representation,state,surfaces,unimolecular decomposition,vinyl bromide},
  langid = {english},
  number = {4}
}

@article{manDatadriven2018,
  title = {Data-Driven Predictive Analytics of Unexpected Wind Turbine Shut-Downs},
  author = {Man, Jianing and Zhang, Zijun and Zhou, Qiang},
  date = {2018-11-19},
  journaltitle = {IET Renewable Power Generation},
  volume = {12},
  pages = {1833--1842},
  issn = {1752-1416, 1752-1424},
  doi = {10.1049/iet-rpg.2018.5520},
  url = {https://digital-library.theiet.org/content/journals/10.1049/iet-rpg.2018.5520},
  urldate = {2020-07-07},
  abstract = {In this study, a novel data-driven framework is proposed to offer predictive analytics of wind turbine (WT) unexpected shut-downs based on data collected by the supervisory control and data acquisition (SCADA) system. A new parameter, the remaining functional life (RFL), is introduced to describe the length of a period until the next WT shut-down and a binary target parameter is created based on the RFL for indicating impending unexpected WT shut-downs. A two-stage data-driven framework is proposed to develop the predictive analytics model of the unexpected WT shut-downs based on SCADA data. The first stage employs clustering methods to automatically cluster WT SCADA data through unsupervised learning. In the second stage, based on clusters of SCADA data, famous classification methods are applied to develop models for inferring the binary target parameter. To validate the proposed data-driven framework, case studies and intensive computational experiments are conducted. Computational results confirm that meaningful predictive analytics of unexpected WT shut-downs can be produced through the proposed data-driven framework.},
  file = {/Users/hyan46/Dropbox (ASU)/ZoteroData/Man et al_2018_Data-driven predictive analytics of unexpected wind turbine shut-downs.pdf},
  keywords = {Data: Profiles,Problem: Supervised Learning},
  langid = {english},
  number = {15}
}

@inproceedings{maoDimensionality2015,
  title = {Dimensionality {{Reduction Via Graph Structure Learning}}},
  booktitle = {Proceedings of the 21th {{ACM SIGKDD International Conference}} on {{Knowledge Discovery}} and {{Data Mining}} - {{KDD}} '15},
  author = {Mao, Qi and Wang, Li and Goodison, Steve and Sun, Yijun},
  date = {2015},
  pages = {765--774},
  publisher = {{ACM Press}},
  location = {{Sydney, NSW, Australia}},
  doi = {10.1145/2783258.2783309},
  url = {http://dl.acm.org/citation.cfm?doid=2783258.2783309},
  urldate = {2020-10-26},
  abstract = {We present a new dimensionality reduction setting for a large family of real-world problems. Unlike traditional methods, the new setting aims to explicitly represent and learn an intrinsic structure from data in a high-dimensional space, which can greatly facilitate data visualization and scientific discovery in downstream analysis. We propose a new dimensionality-reduction framework that involves the learning of a mapping function that projects data points in the original high-dimensional space to latent points in a lowdimensional space that are then used directly to construct a graph. Local geometric information of the projected data is naturally captured by the constructed graph. As a showcase, we develop a new method to obtain a discriminative and compact feature representation for clustering problems. In contrast to assumptions used in traditional clustering methods, we assume that centers of clusters should be close to each other if they are connected in a learned graph, and other cluster centers should be distant. Extensive experiments are performed that demonstrate that the proposed method is able to obtain discriminative feature representations yielding superior clustering performance, and correctly recover the intrinsic structures of various real-world datasets including curves, hierarchies and a cancer progression path.},
  eventtitle = {The 21th {{ACM SIGKDD International Conference}}},
  file = {/Users/hyan46/Zotero/storage/HGZWY5FX/Mao et al. - 2015 - Dimensionality Reduction Via Graph Structure Learn.pdf},
  isbn = {978-1-4503-3664-2},
  langid = {english}
}

@article{masoudPredicting2016,
  ids = {masoudPredicting2016a},
  title = {Predicting {{Subjective Responses From Human Motion}}: {{Application}} to {{Vehicle Ingress Assessment}}},
  shorttitle = {Predicting {{Subjective Responses From Human Motion}}},
  author = {Masoud, Hadi I. and Reed, Matthew P. and Paynabar, Kamran and Wang, Nanxin and Jin, Jionghua and Wan, Jian and Kozak, Ksenia K. and Gomez-Levi, Gianna},
  date = {2016-06-01},
  journaltitle = {Journal of Manufacturing Science and Engineering},
  volume = {138},
  pages = {061001},
  issn = {1087-1357, 1528-8935},
  doi = {10.1115/1.4032191},
  url = {https://asmedigitalcollection.asme.org/manufacturingscience/article/doi/10.1115/1.4032191/392479/Predicting-Subjective-Responses-From-Human-Motion},
  urldate = {2020-07-07},
  abstract = {The ease of entering a car is one of the important ergonomic factors that car manufacturers consider during the process of car design. This has motivated many researchers to investigate factors that affect discomfort during ingress. The patterns of motion during ingress may be related to discomfort, but the analysis of motion is challenging. In this paper, a modeling framework is proposed to use the motions of body landmarks to predict subjectively reported discomfort during ingress. Foot trajectories are used to identify a set of trials with a consistent right-leg-first strategy. The trajectories from 20 landmarks on the limbs and torso are parameterized using B-spline basis functions. Two group selection methods, group non-negative garrote (GNNG) and stepwise group selection (SGS), are used to filter and identify the trajectories that are important for prediction. Finally, a classification and prediction model is built using support vector machine (SVM). The performance of the proposed framework is then evaluated against simpler, more common prediction models.},
  file = {/Users/hyan46/Dropbox (ASU)/ZoteroData/Masoud et al_2016_Predicting Subjective Responses From Human Motion.pdf},
  langid = {english},
  number = {6}
}

@article{mcateeArtificial2019,
  ids = {mcateeArtificial2019a},
  title = {Artificial Neural Network to Estimate the Refractive Index of a Liquid Infiltrating a Chiral Sculptured Thin Film},
  author = {McAtee, P. D. and Bukkapatnam, Satish and Lakhtakia, A.},
  date = {2019-10},
  journaltitle = {Journal of Nanophotonics},
  shortjournal = {J Nanophotonics J Nanophotonics},
  volume = {13},
  issn = {1934-2608},
  url = {://WOS:000541500800006},
  abstract = {We theoretically expanded the capabilities of optical sensing based on surface plasmon resonance in a prism-coupled configuration by incorporating artificial neural networks (ANNs). We used calculations modeling an index-matched substrate with a metal thin film and a porous chiral sculptured thin film (CSTF) deposited successively on it that is affixed to the base of a triangular prism. When a fluid is brought in contact with the exposed face of the CSTF, the latter is infiltrated. As a result of infiltration, the traversal of light entering one slanted face of the prism and exiting the other slanted face of the prism is affected. We trained two ANNs with differing structures using reflectance data generated from simulations to predict the refractive index of the infiltrant fluid. The best predictions were a result of training the ANN with the simpler structure. With realistic simulated-noise, the performance of this ANN is robust. (C) 2019 Society of Photo-Optical Instrumentation Engineers (SPIE)},
  keywords = {artificial neural network,biosensor,biosensors,chiral sculptured thin film,nanoparticles,plasmon resonance band,prism-coupled configuration,sensors,signals,surface plasmon resonance,surface-plasmons},
  langid = {english},
  number = {4}
}

@online{mehtaSparse2019,
  title = {Sparse {{Transfer Learning}} via {{Winning Lottery Tickets}}},
  author = {Mehta, Rahul},
  date = {2019-12-16},
  url = {http://arxiv.org/abs/1905.07785},
  urldate = {2021-02-25},
  abstract = {The recently proposed Lottery Ticket Hypothesis of Frankle and Carbin (2019) suggests that the performance of over-parameterized deep networks is due to the random initialization seeding the network with a small fraction of favorable weights. These weights retain their dominant status throughout training -- in a very real sense, this sub-network "won the lottery" during initialization. The authors find sub-networks via unstructured magnitude pruning with 85-95\% of parameters removed that train to the same accuracy as the original network at a similar speed, which they call winning tickets. In this paper, we extend the Lottery Ticket Hypothesis to a variety of transfer learning tasks. We show that sparse sub-networks with approximately 90-95\% of weights removed achieve (and often exceed) the accuracy of the original dense network in several realistic settings. We experimentally validate this by transferring the sparse representation found via pruning on CIFAR-10 to SmallNORB and FashionMNIST for object recognition tasks.},
  archiveprefix = {arXiv},
  eprint = {1905.07785},
  eprinttype = {arxiv},
  file = {/Users/hyan46/Zotero/storage/NDQ24TRJ/Mehta - 2019 - Sparse Transfer Learning via Winning Lottery Ticke.pdf;/Users/hyan46/Zotero/storage/YDV6BUHI/1905.html},
  keywords = {Computer Science - Machine Learning,Computer Science - Neural and Evolutionary Computing,Statistics - Machine Learning},
  primaryclass = {cs, stat}
}

@article{meiEARLY2011,
  title = {{{EARLY DETECTION OF A CHANGE IN POISSON RATE AFTER ACCOUNTING FOR POPULATION SIZE EFFECTS}}},
  author = {Mei, Yajun and Han, Sung Won and Tsui, Kwok-Leung},
  date = {2011},
  journaltitle = {Statistica Sinica},
  volume = {21},
  pages = {597--624},
  publisher = {{Institute of Statistical Science, Academia Sinica}},
  issn = {1017-0405},
  abstract = {Motivated by applications in bio and syndromic surveillance, this article is concerned with the problem of detecting a change in the mean of Poisson distributions after taking into account the effects of population size. The family of generalized likelihood ratio (GLR) schemes is proposed and its asymptotic optimality properties are established under the classical asymptotic setting. However, numerical simulation studies illustrate that the GLR schemes are at times not as efficient as two families of ad-hoc schemes based on either the weighted likelihood ratios or the adaptive threshold method that adjust the effects of population sizes. To explain this, a further asymptotic optimality analysis is developed under a new asymptotic setting that is more suitable to our finite-sample numerical simulations. In addition, we extend our approaches to a general setting with arbitrary probability distributions, as well as to the continuous-time setting involving the multiplicative intensity models for Poisson processes, but further research is needed.},
  eprint = {24309533},
  eprinttype = {jstor},
  number = {2}
}

@article{mesnilFast2016,
  title = {Fast Wavenumber Measurement for Accurate and Automatic Location and Quantification of Defect in Composite},
  author = {Mesnil, Olivier and Yan, Hao and Ruzzene, Massimo and Paynabar, Kamran and Shi, Jianjun},
  date = {2016-03},
  journaltitle = {Structural Health Monitoring},
  volume = {15},
  pages = {223--234},
  publisher = {{SAGE Publications Ltd}},
  issn = {17413168},
  doi = {10.1177/1475921716636375},
  url = {http://journals.sagepub.com/doi/10.1177/1475921716636375},
  abstract = {As the use of and dependence on composite materials is increasing in all industries, there is a strong need for reliable, accurate, and fast techniques for damage detection and quantification in composite plate-like structures. Among the various nondestructive evaluation and structural health monitoring techniques, many rely on Lamb wave long-range propagation. A wavenumber quantification technique called frequency domain instantaneous wavenumber has been previously proven to be an efficient technique to estimate in-plane (i.e. position) and out-of-plane (i.e. depth) coordinates of defects in composites. This paper further develops this technique by (1) reducing the acquisition time by one order of magnitude while improving the quality of detection, (2) implementing an automatic feature extraction process to automatically assess the geometry and obtain information which can be directly used for decision making, and (3) quantifying the cumulative error of the whole process.},
  file = {/Users/hyan46/Dropbox (ASU)/ZoteroData/Mesnil et al_2016_Fast wavenumber measurement for accurate and automatic location and2.pdf},
  keywords = {Application: Nano,Method: Physics,Problem: Process Monitoring},
  number = {2}
}

@inproceedings{mesnilFrequency2014,
  title = {Frequency {{Domain Instantaneous Wavenumber Estimation}} for {{Damage Quantification}} in {{Layered Plate Structures}}},
  booktitle = {{{EWSHM}} - 7th {{European Workshop}} on {{Structural Health Monitoring}}},
  author = {Mesnil, Olivier and Yan, Hao and Ruzzene, Massimo and Paynabar, Kamran and Shi, Jianjun and Domain, Jianjun Shi Frequency},
  date = {2014-07},
  pages = {1022998},
  location = {{Nantes, France.}},
  url = {https://hal.inria.fr/hal-01022998},
  abstract = {Guided wavefield detection is at the basis of a number of promising techniques for the identification and the characterization of damage in plate structures. Among the processing techniques proposed, the estimation of instantaneous wavenumbers can be used as an effective metric that localize and quantifies delaminations in composite plates. A process able to estimate the in-plane and out-of-plane (depth) coordinate of a feature in a 2D structure using the Frequency Domain Instantaneous Wavenumber (FDIW) damage quan-tification technique is detailed in this paper. A post processing algorithm using a smooth sparse decomposition is used to highlight the studied features. The effectiveness of this method combined to the post processing technique is demonstrated for both numerical and experimental cases. This proposed methodology can be considered as a first step towards a hybrid structural health monitoring/ nondestructive evaluation (SHM/NDE) approach for damage assessment in composites.},
  file = {/Users/hyan46/Dropbox (ASU)/ZoteroData/Mesnil et al_2014_Frequency Domain Instantaneous Wavenumber Estimation for Damage Quantification2.pdf},
  keywords = {Application: Nano,Problem: Process Monitoring}
}

@inproceedings{mesnilGuided2015,
  title = {Guided {{Wavefield Reconstruction}} from {{Sparse Measurements Using Compressed Sensing}}},
  booktitle = {Structural {{Health Monitoring}} 2015},
  author = {Mesnil, O. and Yan, H. and Ruzzene, M. and Paynabar, K. and Shi, J.},
  date = {2015-09-02},
  volume = {0},
  url = {http://www.dpi-proceedings.com/index.php/SHM2015/article/view/894},
  urldate = {2020-07-15},
  abstract = {Wavefields obtained from the measurement of Lamb waves propagating through a solid media by a Laser Doppler Vibrometer (LDV) are very rich in qualitative and quantitative information about structural defects. In this research, Compressed Sens-ing (CS) is used to significantly reduce the number of point measurements necessary to the application of SHM techniques. The process extrapolates the information con-tained in M measurements to reconstruct a wavefield on a grid of P pixels with the condition M {$<$} P, using a basis of functions created from the dispersion relations of the media and the propagation laws of lamb waves. Reconstructions of experimental and analytical uni-dimensional wavefields are detailed to validate the concept. The development of this process is a first step towards fast large scale defect detection techniques by LDV in SHM.doi: 10.12783/SHM2015/232},
  langid = {american},
  number = {0}
}

@article{meyerSpace2012,
  title = {A {{Space}}–{{Time Conditional Intensity Model}} for {{Invasive Meningococcal Disease Occurrence}}},
  author = {Meyer, Sebastian and Elias, Johannes and Höhle, Michael},
  date = {2012},
  journaltitle = {Biometrics},
  volume = {68},
  pages = {607--616},
  issn = {1541-0420},
  doi = {10.1111/j.1541-0420.2011.01684.x},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/j.1541-0420.2011.01684.x},
  urldate = {2020-08-07},
  abstract = {A novel point process model continuous in space–time is proposed for quantifying the transmission dynamics of the two most common meningococcal antigenic sequence types observed in Germany 2002–2008. Modeling is based on the conditional intensity function (CIF), which is described by a superposition of additive and multiplicative components. As an epidemiological interesting finding, spread behavior was shown to depend on type in addition to age: basic reproduction numbers were 0.25 (95\% CI 0.19–0.34) and 0.11 (95\% CI 0.07–0.17) for types B:P1.7–2,4:F1–5 and C:P1.5,2:F3–3, respectively. Altogether, the proposed methodology represents a comprehensive and universal regression framework for the modeling, simulation, and inference of self-exciting spatiotemporal point processes based on the CIF. Usability of the modeling in biometric practice is promoted by an implementation in the R package surveillance.},
  annotation = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1111/j.1541-0420.2011.01684.x},
  file = {/Users/hyan46/Dropbox (ASU)/ZoteroData/Meyer et al_2012_A Space–Time Conditional Intensity Model for Invasive Meningococcal Disease.pdf;/Users/hyan46/Zotero/storage/5FYJVGQJ/j.1541-0420.2011.01684.html},
  keywords = {Conditional intensity function,Infectious disease surveillance data,Spatiotemporal point process,Stochastic epidemic modeling},
  langid = {english},
  number = {2}
}

@article{meyerSpatioTemporal2017,
  title = {Spatio-{{Temporal Analysis}} of {{Epidemic Phenomena Using}} the {{R Package}} Surveillance},
  author = {Meyer, Sebastian and Held, Leonhard and Höhle, Michael},
  date = {2017},
  journaltitle = {Journal of Statistical Software},
  shortjournal = {J. Stat. Soft.},
  volume = {77},
  issn = {1548-7660},
  doi = {10.18637/jss.v077.i11},
  url = {http://arxiv.org/abs/1411.0416},
  urldate = {2020-08-07},
  abstract = {The availability of geocoded health data and the inherent temporal structure of communicable diseases have led to an increased interest in statistical models and software for spatio-temporal data with epidemic features. The open source R package surveillance can handle various levels of aggregation at which infective events have been recorded: individual-level time-stamped geo-referenced data (case reports) in either continuous space or discrete space, as well as counts aggregated by period and region. For each of these data types, the surveillance package implements tools for visualization, likelihoood inference and simulation from recently developed statistical regression frameworks capturing endemic and epidemic dynamics. Altogether, this paper is a guide to the spatio-temporal modeling of epidemic phenomena, exemplified by analyses of public health surveillance data on measles and invasive meningococcal disease.},
  archiveprefix = {arXiv},
  eprint = {1411.0416},
  eprinttype = {arxiv},
  file = {/Users/hyan46/Dropbox (ASU)/ZoteroData/Meyer et al_2017_Spatio-Temporal Analysis of Epidemic Phenomena Using the R Package surveillance.pdf;/Users/hyan46/Zotero/storage/ZGY97XJP/1411.html},
  keywords = {62-04,Computer Science - Computational Engineering; Finance; and Science,G.3,Physics - Data Analysis; Statistics and Probability,Statistics - Applications,Statistics - Computation},
  number = {11}
}

@article{michaelsDetection2008,
  title = {Detection, Localization and Characterization of Damage in Plates with an {\emph{in Situ}} Array of Spatially Distributed Ultrasonic Sensors},
  author = {Michaels, Jennifer E},
  date = {2008-06-01},
  journaltitle = {Smart Materials and Structures},
  shortjournal = {Smart Mater. Struct.},
  volume = {17},
  pages = {035035},
  issn = {0964-1726, 1361-665X},
  doi = {10.1088/0964-1726/17/3/035035},
  url = {https://iopscience.iop.org/article/10.1088/0964-1726/17/3/035035},
  urldate = {2020-07-15},
  abstract = {Permanently attached piezoelectric sensors arranged in a spatially distributed array are under consideration for structural health monitoring systems incorporating active ultrasonic methods. Most damage detection and localization methods that have been proposed are based upon comparing monitored signals to baselines recorded from the structure prior to initiation of damage. To be effective, this comparison process must take into account any conditions other than damage that have changed the ultrasonic signals. Proposed here is a two-step process whereby damage is first detected and is then localized and characterized. The detection strategy considers the long time behavior of the signals in the diffuse-like regime where distinct echoes can no longer be identified. The localization strategy is to generate images of damage based upon the early time regime when discrete echoes from boundary reflections and scattering sites are meaningful. Results are shown for an aluminum plate with artificial damage introduced in combination with temperature variations. The loss of local temporal coherence combined with an optimal baseline selection procedure is shown to be effective for the detection of damage, and a delay-and-sum imaging method applied to the residual signals both localizes the damage and provides characterization information.},
  file = {/Users/hyan46/Dropbox (ASU)/ZoteroData/Michaels_2008_Detection, localization and characterization of damage in plates with an iin.pdf},
  langid = {english},
  number = {3}
}

@article{milanhoracekInverse1997,
  title = {The Inverse Problem of Electrocardiography: {{A}} Solution in Terms of Single- and Double-Layer Sources on the Epicardial Surface},
  shorttitle = {The Inverse Problem of Electrocardiography},
  author = {Milan Horáček, B. and Clements, John C.},
  date = {1997-09},
  journaltitle = {Mathematical Biosciences},
  shortjournal = {Mathematical Biosciences},
  volume = {144},
  pages = {119--154},
  issn = {00255564},
  doi = {10.1016/S0025-5564(97)00024-2},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0025556497000242},
  urldate = {2020-09-09},
  file = {/Users/hyan46/Dropbox (ASU)/ZoteroData/Milan Horáček_Clements_1997_The inverse problem of electrocardiography.pdf},
  keywords = {_tablet},
  langid = {english},
  number = {2}
}

@book{molnarInterpretable,
  title = {Interpretable {{Machine Learning}}},
  author = {Molnar, Christoph},
  url = {https://christophm.github.io/interpretable-ml-book/},
  urldate = {2020-06-09},
  abstract = {Machine learning algorithms usually operate as black boxes and it is unclear how they derived a certain decision. This book is a guide for practitioners to make machine learning decisions interpretable.}
}

@article{mouAdditive,
  title = {Additive {{Tensor Decomposition Considering Structural Data Information}}},
  author = {Mou, Shancong and Wang, Andi and Zhang, Chuck and Shi, Jianjun},
  pages = {12},
  abstract = {Tensor data with rich structural information becomes increasingly important in process modeling, monitoring, and diagnosis. Here structural information is referred to structural properties such as sparsity, smoothness, low-rank, and piecewise constancy. To reveal useful information from tensor data, we propose to decompose the tensor into the summation of multiple components based on different structural information of them. In this paper, we provide a new definition of structural information in tensor data. Based on it, we propose an additive tensor decomposition (ATD) framework to extract useful information from tensor data. This framework specifies a high dimensional optimization problem to obtain the components with distinct structural information. An alternating direction method of multipliers (ADMM) algorithm is proposed to solve it, which is highly parallelable and thus suitable for the proposed optimization problem. Two simulation examples and a real case study in medical image analysis illustrate the versatility and effectiveness of the ATD framework.},
  file = {/Users/hyan46/Dropbox (ASU)/ZoteroData/Mou et al_Additive Tensor Decomposition Considering Structural Data Information.pdf},
  langid = {english}
}

@article{Multisource,
  title = {Multi-Source {{Unsupervised Domain Adaptation}} for {{Machinery Fault Diagnosis}} under {{Different Working Conditions}}}
}

@article{nakkinaIdentification2020,
  title = {Identification of {{Microstructures}} in 3-{{D}}–{{Printed Ti}}-{{6Al}}-{{4V Using Acoustic Emission Cepstrum}}},
  author = {Nakkina, Tapan Ganatma and Iquebal, Ashif Sikandar and Gorthi, Rama Krishna Sai S and Bukkapatnam, Satish},
  date = {2020},
  issn = {2520-6478}
}

@inproceedings{nguyen2016joint,
  title = {Joint Event Extraction via Recurrent Neural Networks},
  booktitle = {Proceedings of the 2016 Conference of the North American Chapter of the Association for Computational Linguistics: {{Human}} Language Technologies},
  author = {Nguyen, Thien Huu and Cho, Kyunghyun and Grishman, Ralph},
  date = {2016},
  pages = {300--309}
}

@article{ningSparse2017,
  ids = {ningsparse2017a},
  title = {A Sparse Partitioned-Regression Model for Nonlinear System–Environment Interactions},
  author = {Ning, Shuluo and Byon, Eunshin and Wu, Teresa and Li, Jing},
  date = {2017-08-03},
  journaltitle = {IISE Transactions},
  shortjournal = {IISE Transactions},
  volume = {49},
  pages = {814--826},
  issn = {2472-5854, 2472-5862},
  doi = {10.1080/24725854.2017.1299955},
  url = {https://www.tandfonline.com/doi/full/10.1080/24725854.2017.1299955},
  urldate = {2020-07-04},
  abstract = {This article focuses on the modeling of nonlinear interactions between the design and operational variables of a system and the multivariate outside environment in predicting the system’s performance. We propose a Sparse Partitioned-Regression (SPR) model that automatically searches for a partition of the environmental variables and fits a sparse regression within each subdivision of the partition, in order to fulfill an optimal criterion. Two optimal criteria are proposed, a penalized and a held-out criterion. We study the theoretical properties of SPR by deriving oracle inequalities to quantify the risks of the penalized and held-out criteria in both prediction and classification problems. An efficient recursive partition algorithm is developed for model estimation. Extensive simulation experiments are conducted to demonstrate the better performance of SPR compared with competing methods. Finally, we present an application of using building design and operational variables, outdoor environmental variables, and their interactions to predict energy consumption based on the Department of Energy’s EnergyPlus data sets. SPR produces a high level of prediction accuracy. The result of the application also provides insights into the design, operation, and management of energy-efficient buildings.},
  file = {/Users/hyan46/Dropbox (ASU)/ZoteroData/Ning et al_2017_A sparse partitioned-regression model for nonlinear system–environment.pdf},
  keywords = {Method: Classification,Method: Regularization,Method: Sparse,People: Jing Li,Problem: Classification},
  langid = {english},
  number = {8}
}

@article{NonlinearInReview,
  title = {Nonlinear {{Degradation Model}} and {{Reliability Analysis}} by {{Integrating Stochastic Image Covariate}}},
  year = {In Review},
  file = {/Users/hyan46/Dropbox (ASU)/ZoteroData/Nonlinear Degradation Model and Reliability Analysis by Integrating Stochastic.pdf}
}

@unpublished{nurretinOutlierAware2021,
  title = {Outlier-{{Aware Applications}} in {{High}}-{{Dimensional Industrial Systems}}},
  author = {Nurretin, Sergin},
  date = {2021-06-17},
  eventtitle = {Defense},
  file = {/Users/hyan46/Zotero/storage/H38YXDCS/Dissertation_Defense_Presentation.key},
  venue = {{Tempe, AZ}}
}

@book{o.mesnilStructural2015,
  title = {Structural {{Health Monitoring}} 2015},
  author = {{O. MESNIL} and {H. YAN} and {M. RUZZENE} and {K. PAYNABAR} and {J. SHI}},
  date = {2015},
  publisher = {{Destech Publications}},
  doi = {10.12783/shm2015}
}

@article{oseledetsTensorTrain2011,
  title = {Tensor-{{Train Decomposition}}},
  author = {Oseledets, I. V.},
  date = {2011-01-01},
  journaltitle = {SIAM Journal on Scientific Computing},
  shortjournal = {SIAM J. Sci. Comput.},
  volume = {33},
  pages = {2295--2317},
  publisher = {{Society for Industrial and Applied Mathematics}},
  issn = {1064-8275},
  doi = {10.1137/090752286},
  url = {https://epubs.siam.org/doi/abs/10.1137/090752286},
  urldate = {2021-02-27},
  abstract = {A simple nonrecursive form of the tensor decomposition in d dimensions is presented. It does not inherently suffer from the curse of dimensionality, it has asymptotically the same number of parameters as the canonical decomposition, but it is stable and its computation is based on low-rank approximation of auxiliary unfolding matrices. The new form gives a clear and convenient way to implement all basic operations efficiently. A fast rounding procedure is presented, as well as basic linear algebra operations. Examples showing the benefits of the decomposition are given, and the efficiency is demonstrated by the computation of the smallest eigenvalue of a 19-dimensional operator.},
  file = {/Users/hyan46/Dropbox (ASU)/ZoteroData/Oseledets_2011_Tensor-Train Decomposition.pdf;/Users/hyan46/Zotero/storage/PUTNXW6W/090752286.html},
  number = {5}
}

@article{Parameterfree,
  title = {A Parameter-Free Exponential Control Chart Based on {{Kullback}}-{{Leibler}} Information for Time-between-Events Monitoring},
  file = {/Users/hyan46/Zotero/storage/I3WW5XED/UIIE-6455_Proof_hi.pdf}
}

@article{parkAutomating2019,
  title = {Automating Material Image Analysis for Material Discovery},
  author = {Park, Chiwoo and Ding, Yu},
  date = {2019-06},
  journaltitle = {MRS Communications},
  shortjournal = {MRC},
  volume = {9},
  pages = {545--555},
  issn = {2159-6859, 2159-6867},
  doi = {10.1557/mrc.2019.48},
  url = {https://www.cambridge.org/core/product/identifier/S215968591900048X/type/journal_article},
  urldate = {2020-07-04},
  abstract = {Abstract                                                                                    ,              Advancements in temporal and spatial resolutions of microscopes promise to expand the frontiers of understanding in materials science. Imaging techniques produce images at a high-frame rate, streaming out a tremendous amount of data. Analysis of all these images is time-consuming and labor intensive, creating a bottleneck in material discovery that needs to be overcome. This paper summarizes recent progresses in machine learning and data science for expediting and automating material image analysis. The discussion covers both static image and dynamic image analyses, followed by remarks concerning ongoing efforts and future needs in automated image analysis that accelerates material discovery.},
  file = {/Users/hyan46/Dropbox (ASU)/ZoteroData/Park_Ding_2019_Automating material image analysis for material discovery.pdf},
  keywords = {Application: Manufacturing,Application: Nano,Data: Image,People: Chiwoo Park},
  langid = {english},
  number = {02}
}

@article{parkDynamic,
  title = {Dynamic {{Data}}-{{Driven Monitoring}} of {{Nanoparticle Self Assembly Processes}}},
  author = {Park, Chiwoo and Ding, Yu},
  pages = {22},
  abstract = {This chapter presents a dynamic, data-driven modeling methodology, capable of tracking and predicting the transient dynamics of nanoparticle selfassembly processes. The proposed methodology is built upon emerging online instrumentation technology, including two different machines of complementing capabilities: a light scattering machine which can operate almost instantaneously at a high temporal resolution but cannot measure nanoparticles at a high spatial resolution, and a transmission electron microscope of a high spatial resolution but a low temporal resolution. To take the full advantage of the multi-resolution instruments, the proposed methodology employs an adaptive data-retrieving strategy of dynamic datadriven application systems, guiding the expensive electron microscope to take measurements only when there is a need to verify the real-time light scattering observations model. The proposed methodology induces a close coupling between modeling and measurement-taking, vesting in a competent strategy that can improve simultaneously both modeling quality and measurement efficiency.},
  file = {/Users/hyan46/Dropbox (ASU)/ZoteroData/Park_Ding_Dynamic Data-Driven Monitoring of Nanoparticle Self Assembly Processes.pdf},
  keywords = {Application: Assembly,Application: Manufacturing,Application: Nano,Data: Image,Method: Spatio-temporal,Method: State Space,People: Chiwoo Park,Problem: Process Monitoring},
  langid = {english}
}

@article{parkMinimum2015,
  title = {Minimum {{Cost Multi}}-{{Way Data Association}} for {{Optimizing Multitarget Tracking}} of {{Interacting Objects}}},
  author = {Park, Chiwoo and Woehl, Taylor J. and Evans, James E. and Browning, Nigel D.},
  date = {2015-03-01},
  journaltitle = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
  shortjournal = {IEEE Trans. Pattern Anal. Mach. Intell.},
  volume = {37},
  pages = {611--624},
  issn = {0162-8828, 2160-9292},
  doi = {10.1109/TPAMI.2014.2346202},
  url = {http://ieeexplore.ieee.org/document/6873308/},
  urldate = {2020-07-04},
  abstract = {This paper presents a general formulation for a minimum cost data association problem which associates data features via one-to-one, m-to-one and one-to-n links with minimum total cost of the links. A motivating example is a problem of tracking multiple interacting nanoparticles imaged on video frames, where particles can aggregate into one particle or a particle can be split into multiple particles. Many existing multitarget tracking methods are capable of tracking non-interacting targets or tracking interacting targets of restricted degrees of interactions. The proposed formulation solves a multitarget tracking problem for general degrees of inter-object interactions. The formulation is in the form of a binary integer programming problem. We propose a polynomial time solution approach that can obtain a good relaxation solution of the binary integer programming, so the approach can be applied for multitarget tracking problems of a moderate size (for hundreds of targets over tens of time frames). The resulting solution is always integral and obtains a better duality gap than the simple linear relaxation solution of the corresponding problem. The proposed method was validated through applications to simulated multitarget tracking problems and a real multitarget tracking problem.},
  file = {/Users/hyan46/Dropbox (ASU)/ZoteroData/Park et al_2015_Minimum Cost Multi-Way Data Association for Optimizing Multitarget Tracking of.pdf},
  keywords = {Application: Manufacturing,Application: Nano,Method: Integer Programming,People: Chiwoo Park,Problem: Tracking},
  langid = {english},
  number = {3}
}

@article{parkSequential2020,
  title = {Sequential {{Adaptive Design}} for {{Jump Regression Estimation}} in {{Materials Discovery}}},
  author = {Park, Chiwoo and Qiu, Peihua and Carpena-Núñez, Jennifer and Rao, Rahul and Susner, Michael and Maruyama, Benji},
  date = {2020},
  pages = {23},
  file = {/Users/hyan46/Dropbox (ASU)/ZoteroData/Park et al_2020_Sequential Adaptive Design for Jump Regression Estimation in Materials Discovery.pdf},
  keywords = {Application: Manufacturing,Application: Nano,Data: Image,Method: Adaptive Sampling,Method: Functional,Method: Kernel,People: Chiwoo Park},
  langid = {english}
}

@article{pathmanathanUncertainty2015,
  title = {Uncertainty Quantification of Fast Sodium Current Steady-State Inactivation for Multi-Scale Models of Cardiac Electrophysiology},
  author = {Pathmanathan, Pras and Shotwell, Matthew S. and Gavaghan, David J. and Cordeiro, Jonathan M. and Gray, Richard A.},
  date = {2015-01-01},
  journaltitle = {Progress in Biophysics and Molecular Biology},
  shortjournal = {Progress in Biophysics and Molecular Biology},
  volume = {117},
  pages = {4--18},
  issn = {0079-6107},
  doi = {10.1016/j.pbiomolbio.2015.01.008},
  url = {http://www.sciencedirect.com/science/article/pii/S0079610715000097},
  urldate = {2020-05-24},
  abstract = {Perhaps the most mature area of multi-scale systems biology is the modelling of the heart. Current models are grounded in over fifty years of research in the development of biophysically detailed models of the electrophysiology (EP) of cardiac cells, but one aspect which is inadequately addressed is the incorporation of uncertainty and physiological variability. Uncertainty quantification (UQ) is the identification and characterisation of the uncertainty in model parameters derived from experimental data, and the computation of the resultant uncertainty in model outputs. It is a necessary tool for establishing the credibility of computational models, and will likely be expected of EP models for future safety-critical clinical applications. The focus of this paper is formal UQ of one major sub-component of cardiac EP models, the steady-state inactivation of the fast sodium current, INa. To better capture average behaviour and quantify variability across cells, we have applied for the first time an ‘individual-based’ statistical methodology to assess voltage clamp data. Advantages of this approach over a more traditional ‘population-averaged’ approach are highlighted. The method was used to characterise variability amongst cells isolated from canine epi and endocardium, and this variability was then ‘propagated forward’ through a canine model to determine the resultant uncertainty in model predictions at different scales, such as of upstroke velocity and spiral wave dynamics. Statistically significant differences between epi and endocardial cells (greater half-inactivation and less steep slope of steady state inactivation curve for endo) was observed, and the forward propagation revealed a lack of robustness of the model to underlying variability, but also surprising robustness to variability at the tissue scale. Overall, the methodology can be used to: (i) better analyse voltage clamp data; (ii) characterise underlying population variability; (iii) investigate consequences of variability; and (iv) improve the ability to validate a model. To our knowledge this article is the first to quantify population variability in membrane dynamics in this manner, and the first to perform formal UQ for a component of a cardiac model. The approach is likely to find much wider applicability across systems biology as current application domains reach greater levels of maturity.},
  file = {/Users/hyan46/Zotero/storage/3JM5QBR2/S0079610715000097.html},
  keywords = {cardiac,Cardiac modelling,metamodel,Nonlinear mixed effects modelling,Population variability,Uncertainty quantification,UQ},
  langid = {english},
  number = {1},
  series = {Multi-Scale {{Systems Biology}}}
}

@article{paynabarChangePoint2016,
  title = {A {{Change}}-{{Point Approach}} for {{Phase}}-{{I Analysis}} in {{Multivariate Profile Monitoring}} and {{Diagnosis}}},
  author = {Paynabar, Kamran and Zou, Changliang and Qiu, Peihua},
  date = {2016-04-02},
  journaltitle = {Technometrics},
  shortjournal = {Technometrics},
  volume = {58},
  pages = {191--204},
  issn = {0040-1706, 1537-2723},
  doi = {10.1080/00401706.2015.1042168},
  url = {http://www.tandfonline.com/doi/full/10.1080/00401706.2015.1042168},
  urldate = {2020-07-07},
  file = {/Users/hyan46/Dropbox (ASU)/ZoteroData/Paynabar et al_2016_A Change-Point Approach for Phase-I Analysis in Multivariate Profile Monitoring.pdf},
  langid = {english},
  number = {2}
}

@article{paynabarCharacterization2011,
  title = {Characterization of Non-Linear Profiles Variations Using Mixed-Effect Models and Wavelets},
  author = {Paynabar, Kamran and Jin, Jionghua},
  date = {2011-01-31},
  journaltitle = {IIE Transactions},
  shortjournal = {IIE Transactions},
  volume = {43},
  pages = {275--290},
  issn = {0740-817X, 1545-8830},
  doi = {10.1080/0740817X.2010.521807},
  url = {http://www.tandfonline.com/doi/abs/10.1080/0740817X.2010.521807},
  urldate = {2020-07-07},
  file = {/Users/hyan46/Dropbox (ASU)/ZoteroData/Paynabar_Jin_2011_Characterization of non-linear profiles variations using mixed-effect models.pdf},
  langid = {english},
  number = {4}
}

@article{paynabarInformative2015,
  title = {Informative {{Sensor}} and {{Feature Selection}} via {{Hierarchical Nonnegative Garrote}}},
  author = {Paynabar, Kamran and Jin, Jionghua and Reed, Matthew P.},
  date = {2015-10-02},
  journaltitle = {Technometrics},
  shortjournal = {Technometrics},
  volume = {57},
  pages = {514--523},
  issn = {0040-1706, 1537-2723},
  doi = {10.1080/00401706.2014.947383},
  url = {http://www.tandfonline.com/doi/full/10.1080/00401706.2014.947383},
  urldate = {2020-07-04},
  file = {/Users/hyan46/Dropbox (ASU)/ZoteroData/Paynabar et al_2015_Informative Sensor and Feature Selection via Hierarchical Nonnegative Garrote.pdf},
  keywords = {Data: Profiles,Method: Sparse,People: Judy Jin},
  langid = {english},
  number = {4}
}

@article{paynabarMonitoring2013,
  title = {Monitoring and Diagnosis of Multichannel Nonlinear Profile Variations Using Uncorrelated Multilinear Principal Component Analysis},
  author = {Paynabar, Kamran and Jin, Jionghua and Pacella, Massimo},
  date = {2013-11},
  journaltitle = {IIE Transactions},
  shortjournal = {IIE Transactions},
  volume = {45},
  pages = {1235--1247},
  issn = {0740-817X, 1545-8830},
  doi = {10.1080/0740817X.2013.770187},
  url = {http://www.tandfonline.com/doi/abs/10.1080/0740817X.2013.770187},
  urldate = {2020-07-04},
  file = {/Users/hyan46/Dropbox (ASU)/ZoteroData/Paynabar et al_2013_Monitoring and diagnosis of multichannel nonlinear profile variations using.pdf},
  keywords = {Data: Profiles,Method: Functional,Method: Tensor,People: Judy Jin},
  langid = {english},
  number = {11}
}

@inproceedings{pelikanBOA1999,
  title = {{{BOA}}: The {{Bayesian}} Optimization Algorithm},
  shorttitle = {{{BOA}}},
  booktitle = {Proceedings of the 1st {{Annual Conference}} on {{Genetic}} and {{Evolutionary Computation}} - {{Volume}} 1},
  author = {Pelikan, Martin and Goldberg, David E. and Cantú-Paz, Erick},
  date = {1999-07-13},
  pages = {525--532},
  publisher = {{Morgan Kaufmann Publishers Inc.}},
  location = {{Orlando, Florida}},
  abstract = {In this paper, an algorithm based on the concepts of genetic algorithms that uses an estimation of a probability distribution of promising solutions in order to generate new candidate solutions is proposed. To estimate the distribution, techniques for modeling multivariate data by Bayesian networks are used. The proposed algorithm identifies, reproduces and mixes building blocks up to a specified order. It is independent of the ordering of the variables in the strings representing the solutions. Moreover, prior information about the problem can be incorporated into the algorithm. However, prior information is not essential. Preliminary experiments show that the BOA outperforms the simple genetic algorithm even on decomposable functions with tight building blocks as a problem size grows.},
  file = {/Users/hyan46/Dropbox (ASU)/ZoteroData/Pelikan et al_1999_BOA.pdf},
  isbn = {978-1-55860-611-1},
  keywords = {Bayesian Optimization,Method: Bayesian},
  series = {{{GECCO}}'99}
}

@article{pernkopfDetection2004,
  title = {Detection of Surface Defects on Raw Steel Blocks Using {{Bayesian}} Network Classifiers},
  author = {Pernkopf, Franz},
  date = {2004-12},
  journaltitle = {Pattern Analysis and Applications},
  shortjournal = {Pattern Anal Applic},
  volume = {7},
  pages = {333--342},
  issn = {1433-7541, 1433-755X},
  doi = {10.1007/s10044-004-0232-3},
  url = {http://link.springer.com/10.1007/s10044-004-0232-3},
  urldate = {2020-07-15},
  abstract = {This p a p e r proposes an approach that detects surface defects with three-dimensional characteristics on scale-covered steel blocks. T h e surface reflection properties o f the flawless surface changes strongly. Light sectioning is used to acquire the surface range data o f the steel block. These sections are arbitrarily located within a r a n g e o f a few millimeters due to vibrations o f the steel block on the conveyor. After the recovery o f the d e p t h map, segments o f the surface are classified according to a set o f extracted features by means o f Bayesian network classifiers. For establishing the structure o f the Bayesian network, a floating search algorithm is applied, w h i c h achieves a good tradeoff between classification performance and computational efficiency for structure learning. This search algorithm enables conditional exclusions o f previously a d d e d attributes a n d / o r arcs from the network. The experiments show that the selective u n r e stricted Bayesian network classifier outperforms the naive Bayes and the tree-augmented naive Bayes decision rules concerning the classification rate. More than 98\% o f the surface segments have been classified correctly.},
  file = {/Users/hyan46/Dropbox (ASU)/ZoteroData/Pernkopf_2004_Detection of surface defects on raw steel blocks using Bayesian network.pdf},
  langid = {english},
  number = {3}
}

@article{petersSeveritybased2020,
  title = {Severity-Based Diagnosis for Vehicular Electric Systems with Multiple, Interacting Fault Modes},
  author = {Peters, Benjamin and Yildirim, Murat and Gebraeel, Nagi and Paynabar, Kamran},
  date = {2020-03},
  journaltitle = {Reliability Engineering \& System Safety},
  shortjournal = {Reliability Engineering \& System Safety},
  volume = {195},
  pages = {106605},
  issn = {09518320},
  doi = {10.1016/j.ress.2019.106605},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0951832019304661},
  urldate = {2020-07-07},
  abstract = {Complex systems are comprised of multiple components that continuously interact in terms of how they degrade and fail. Diagnosing fault severity and causes of failures in these systems is often a non-trivial task. To address this challenge, we propose a data-driven, severity-based diagnosis framework for systems with multiple, interacting fault modes. We focus on the components of the automotive electric power generation and storage system, specifically, the Vehicle-Engine Start system comprised of the battery and the start-stop starter. Our framework leverages sensor data from several component-fault severity combinations. Using multiple feature extraction tools, we train separate classifiers using Regularized Multinomial Regression, and combine the performance of the classifiers using ensemble methods. We demonstrate the effectiveness of our approach by performing degradation-based diagnostic tests utilizing a real-world engine test-rig.},
  file = {/Users/hyan46/Dropbox (ASU)/ZoteroData/Peters et al_2020_Severity-based diagnosis for vehicular electric systems with multiple,.pdf},
  langid = {english}
}

@article{phatakSensorbased2009,
  title = {Sensor-Based Modeling of Slurry Chemistry Effects on the Material Removal Rate ({{MRR}}) in Copper-{{CMP}} Process},
  author = {Phatak, U and Bukkapatnam, Satish and Kong, Z and Komanduri, R},
  date = {2009},
  journaltitle = {International Journal of Machine Tools and Manufacture},
  volume = {49},
  pages = {171--181},
  issn = {0890-6955},
  number = {2}
}

@article{plumleeBayesian2017,
  title = {Bayesian {{Calibration}} of {{Inexact Computer Models}}},
  author = {Plumlee, Matthew},
  date = {2017-07-03},
  journaltitle = {Journal of the American Statistical Association},
  volume = {112},
  pages = {1274--1285},
  publisher = {{Taylor \& Francis}},
  issn = {0162-1459},
  doi = {10.1080/01621459.2016.1211016},
  url = {https://doi.org/10.1080/01621459.2016.1211016},
  urldate = {2020-05-24},
  abstract = {Bayesian calibration is used to study computer models in the presence of both a calibration parameter and model bias. The parameter in the predominant methodology is left undefined. This results in an issue, where the posterior of the parameter is suboptimally broad. There has been no generally accepted alternatives to date. This article proposes using Bayesian calibration, where the prior distribution on the bias is orthogonal to the gradient of the computer model. Problems associated with Bayesian calibration are shown to be mitigated through analytic results in addition to examples. Supplementary materials for this article are available online.},
  annotation = {\_eprint: https://doi.org/10.1080/01621459.2016.1211016},
  file = {/Users/hyan46/Dropbox (ASU)/ZoteroData/Plumlee_2017_Bayesian Calibration of Inexact Computer Models.pdf},
  keywords = {calibration,Calibration,Computer experiments,Deterministic models,Gaussian processes,Identifiability,Kriging,metamodel,Method: Bayesian,Model inadequacy,Orthogonal processes,Uncertainty quantification},
  number = {519}
}

@article{plumleeCalibrating2016,
  title = {Calibrating {{Functional Parameters}} in the {{Ion Channel Models}} of {{Cardiac Cells}}},
  author = {Plumlee, Matthew and Joseph, V. Roshan and Yang, Hui},
  date = {2016-04-02},
  journaltitle = {Journal of the American Statistical Association},
  shortjournal = {Journal of the American Statistical Association},
  volume = {111},
  pages = {500--509},
  publisher = {{Taylor \& Francis}},
  issn = {0162-1459},
  doi = {10.1080/01621459.2015.1119695},
  url = {https://amstat.tandfonline.com/doi/abs/10.1080/01621459.2015.1119695},
  urldate = {2020-05-24},
  abstract = {Computational modeling is a popular tool to understand a diverse set of complex systems. The output from a computational model depends on a set of parameters that are unknown to the designer, but a modeler can estimate them by collecting physical data. In the described study of the ion channels of ventricular myocytes, the parameter of interest is a function as opposed to a scalar or a set of scalars. This article develops a new modeling strategy to nonparametrically study the functional parameter using Bayesian inference with Gaussian process prior distributions. A new sampling scheme is devised to address this unique problem.},
  file = {/Users/hyan46/Dropbox (ASU)/ZoteroData/Plumlee et al_2016_Calibrating Functional Parameters in the Ion Channel Models of Cardiac Cells.pdf},
  keywords = {calibration,cardiac,metamodel},
  number = {514}
}

@article{polunchenkoOptimality2010,
  title = {On Optimality of the {{Shiryaev}}–{{Roberts}} Procedure for Detecting a Change in Distribution},
  author = {Polunchenko, Aleksey S. and Tartakovsky, Alexander G.},
  date = {2010-12},
  journaltitle = {Annals of Statistics},
  shortjournal = {Ann. Statist.},
  volume = {38},
  pages = {3445--3457},
  publisher = {{Institute of Mathematical Statistics}},
  issn = {0090-5364, 2168-8966},
  doi = {10.1214/09-AOS775},
  url = {https://projecteuclid.org/euclid.aos/1291126963},
  urldate = {2020-07-07},
  abstract = {In 1985, for detecting a change in distribution, Pollak introduced a specific minimax performance metric and a randomized version of the Shiryaev–Roberts procedure where the zero initial condition is replaced by a random variable sampled from the quasi-stationary distribution of the Shiryaev–Roberts statistic. Pollak proved that this procedure is third-order asymptotically optimal as the mean time to false alarm becomes large. The question of whether Pollak’s procedure is strictly minimax for any false alarm rate has been open for more than two decades, and there were several attempts to prove this strict optimality. In this paper, we provide a counterexample which shows that Pollak’s procedure is not optimal and that there is a strictly optimal procedure which is nothing but the Shiryaev–Roberts procedure that starts with a specially designed deterministic point.},
  file = {/Users/hyan46/Dropbox (ASU)/ZoteroData/Polunchenko_Tartakovsky_2010_On optimality of the Shiryaev–Roberts procedure for detecting a change in.pdf},
  keywords = {Changepoint problems,sequential detection,Shiryaev–Roberts procedures},
  langid = {english},
  mrnumber = {MR2766858},
  number = {6},
  zmnumber = {1204.62141}
}

@inproceedings{polunchenkoQuickest2013,
  title = {Quickest {{Change}}-{{Point Detection}}: {{A Bird}}'s {{Eye View}}},
  shorttitle = {Quickest {{Change}}-{{Point Detection}}},
  author = {Polunchenko, Aleksey S. and Sokolov, Grigory and Du, Wenyu},
  date = {2013-08-03},
  location = {{Montréal, Québec, Canada}},
  url = {http://arxiv.org/abs/1310.3285},
  urldate = {2020-07-06},
  abstract = {We provide a bird’s eye view onto the area of sequential change-point detection. We focus on the discrete-time case with known pre- and post-change data distributions and offer a summary of the forefront asymptotic results established in each of the four major formulations of the underlying optimization problem: Bayesian, generalized Bayesian, minimax, and multi-cyclic.},
  archiveprefix = {arXiv},
  eprint = {1310.3285},
  eprinttype = {arxiv},
  eventtitle = {Proceedings of the 2013 {{Joint Statistical Meetings}}},
  file = {/Users/hyan46/Dropbox (ASU)/ZoteroData/Polunchenko et al_2013_Quickest Change-Point Detection.pdf},
  keywords = {62L10; 62L15; 62P30,Mathematics - Statistics Theory},
  langid = {english},
  primaryclass = {math, stat}
}

@article{polunchenkoStateoftheArt2012,
  title = {State-of-the-{{Art}} in {{Sequential Change}}-{{Point Detection}}},
  author = {Polunchenko, Aleksey S. and Tartakovsky, Alexander G.},
  date = {2012-09},
  journaltitle = {Methodology and Computing in Applied Probability},
  shortjournal = {Methodol Comput Appl Probab},
  volume = {14},
  pages = {649--684},
  issn = {1387-5841, 1573-7713},
  doi = {10.1007/s11009-011-9256-5},
  url = {http://link.springer.com/10.1007/s11009-011-9256-5},
  urldate = {2020-07-06},
  abstract = {We provide an overview of the state-of-the-art in the area of sequential change-point detection assuming discrete time and known pre- and post-change distributions. The overview spans over all major formulations of the underlying optimization problem, namely, Bayesian, generalized Bayesian, and minimax. We pay particular attention to the latest advances in each. Also, we link together the generalized Bayesian problem with multi-cyclic disorder detection in a stationary regime when the change occurs at a distant time horizon. We conclude with two case studies to illustrate the cutting edge of the field at work.},
  file = {/Users/hyan46/Dropbox (ASU)/ZoteroData/Polunchenko_Tartakovsky_2012_State-of-the-Art in Sequential Change-Point Detection.pdf},
  langid = {english},
  number = {3}
}

@article{pourhabibShortTerm2016,
  title = {Short-{{Term Wind Speed Forecast Using Measurements From Multiple Turbines}} in {{A Wind Farm}}},
  author = {Pourhabib, Arash and Huang, Jianhua Z. and Ding, Yu},
  date = {2016-01-02},
  journaltitle = {Technometrics},
  shortjournal = {Technometrics},
  volume = {58},
  pages = {138--147},
  issn = {0040-1706, 1537-2723},
  doi = {10.1080/00401706.2014.988291},
  url = {http://www.tandfonline.com/doi/full/10.1080/00401706.2014.988291},
  urldate = {2020-07-04},
  file = {/Users/hyan46/Dropbox (ASU)/ZoteroData/Pourhabib et al_2016_Short-Term Wind Speed Forecast Using Measurements From Multiple Turbines in A.pdf},
  keywords = {Application: Wind Turbine,Method: Functional,Method: Kernel,Method: Spatio-temporal,People: Yu Ding,Problem: Forecasting},
  langid = {english},
  number = {1}
}

@article{pukrittayakameePractical2011,
  ids = {pukrittayakameePractical2011a},
  title = {Practical {{Training Framework}} for {{Fitting}} a {{Function}} and {{Its Derivatives}}},
  author = {Pukrittayakamee, A. and Hagan, M. and Raff, L. and Bukkapatnam, Satish and Komanduri, R.},
  date = {2011-06},
  journaltitle = {Ieee Transactions on Neural Networks},
  shortjournal = {Ieee T Neural Networ Ieee T Neural Networ},
  volume = {22},
  pages = {936--947},
  issn = {1045-9227},
  url = {://WOS:000291355700009},
  abstract = {This paper describes a practical framework for using multilayer feedforward neural networks to simultaneously fit both a function and its first derivatives. This framework involves two steps. The first step is to train the network to optimize a performance index, which includes both the error in fitting the function and the error in fitting the derivatives. The second step is to prune the network by removing neurons that cause overfitting and then to retrain it. This paper describes two novel types of overfitting that are only observed when simultaneously fitting both a function and its first derivatives. A new pruning algorithm is proposed to eliminate these types of overfitting. Experimental results show that the pruning algorithm successfully eliminates the overfitting and produces the smoothest responses and the best generalization among all the training algorithms that we have tested.},
  keywords = {approximation,derivative approximation,function approximation,gradient,models,multilayer network,neural-network,pruning},
  langid = {english},
  number = {6}
}

@article{puleoMultistage2014,
  title = {Multi-Stage Linear Programming Optimization for Pump Scheduling},
  author = {Puleo, Valeria and Morley, Mark and Freni, Gabriele and Savić, Dragan},
  date = {2014},
  journaltitle = {Procedia Engineering},
  volume = {70},
  pages = {1378--1385},
  publisher = {{Elsevier}},
  isbn = {1877-7058},
  keywords = {maintenance}
}

@article{qianFast2019,
  title = {Fast Dynamic Nonparametric Distribution Tracking in Electron Microscopic Data},
  author = {Qian, Yanjun and Huang, Jianhua Z. and Park, Chiwoo and Ding, Yu},
  date = {2019-09},
  journaltitle = {The Annals of Applied Statistics},
  shortjournal = {Ann. Appl. Stat.},
  volume = {13},
  pages = {1537--1563},
  issn = {1932-6157},
  doi = {10.1214/19-AOAS1245},
  url = {https://projecteuclid.org/euclid.aoas/1571277763},
  urldate = {2020-07-04},
  file = {/Users/hyan46/Dropbox (ASU)/ZoteroData/Qian et al_2019_Fast dynamic nonparametric distribution tracking in electron microscopic data.pdf},
  keywords = {Application: Manufacturing,Application: Nano,People: Yu Ding},
  langid = {english},
  number = {3}
}

@article{qianIdentifying2017,
  title = {Identifying Multi-Stage Nanocrystal Growth Using in Situ {{TEM}} Video Data},
  author = {Qian, Yanjun and Huang, Jianhua Z. and Ding, Yu},
  date = {2017-05-04},
  journaltitle = {IISE Transactions},
  shortjournal = {IISE Transactions},
  volume = {49},
  pages = {532--543},
  issn = {2472-5854, 2472-5862},
  doi = {10.1080/24725854.2016.1251666},
  url = {https://www.tandfonline.com/doi/full/10.1080/24725854.2016.1251666},
  urldate = {2020-07-04},
  abstract = {The in situ transmission electron microscopy technique is receiving considerable attention in material science research, as its in situ nature makes possible discoveries that ex situ instruments are unable to make and provides the capability of directly observing nanocrystal growth processes. As incresing amounts of dynamic transmission electron microscopy (TEM) video data become available, one of the bottlenecks appears to be the lack of automated, quantitative, and dynamic analytic tools that can process the video data efficiently. The current processing is largely manual in nature and thus laborious, with existing tools focusing primarily on static TEM images. The absence of automated processing of TEM videos does not come as a surprise, as the growth of nanocrystals is highly stochastic and goes through multiple stages. We introduce a method in this article that is suitable for analyzing the in situ TEM videos in an automated and effective way. The method learns and tracks the normalized particle size distribution and identifies the phase-change points delineating the stages in nanocrystal growth. Using the outcome of the change-point detection process, we propose a hybrid multi-stage growth model and test it on an in situ TEM video, made available in 2009 by Science.},
  file = {/Users/hyan46/Dropbox (ASU)/ZoteroData/Qian et al_2017_Identifying multi-stage nanocrystal growth using in situ TEM video data.pdf},
  keywords = {Application: Manufacturing,Application: Nano,Data: Image,Method: Functional,Method: Regularization,Method: Spline,People: Yu Ding},
  langid = {english},
  number = {5}
}

@article{ranjanImpact2017,
  title = {The {{Impact}} of {{Estimation}}: {{A New Method}} for {{Clustering}} and {{Trajectory Estimation}} in {{Patient Flow Modeling}}},
  shorttitle = {The {{Impact}} of {{Estimation}}},
  author = {Ranjan, Chitta and Paynabar, Kamran and Helm, Jonathan E. and Pan, Julian},
  date = {2017-10},
  journaltitle = {Production and Operations Management},
  shortjournal = {Prod Oper Manag},
  volume = {26},
  pages = {1893--1914},
  issn = {10591478},
  doi = {10.1111/poms.12722},
  url = {http://doi.wiley.com/10.1111/poms.12722},
  urldate = {2020-07-07},
  file = {/Users/hyan46/Dropbox (ASU)/ZoteroData/Ranjan et al_2017_The Impact of Estimation.pdf},
  langid = {english},
  number = {10}
}

@article{ranjanLongitudinal2018,
  title = {Longitudinal {{MRI}} Data Analysis in Presence of Measurement Error but Absence of Replicates},
  author = {Ranjan, Chitta and Paynabar, Kamran and Reuter, Martin and Jafari-Khouzani, Kourosh and Adni, the},
  date = {2018-04-03},
  journaltitle = {IISE Transactions on Healthcare Systems Engineering},
  shortjournal = {IISE Transactions on Healthcare Systems Engineering},
  volume = {8},
  pages = {117--130},
  issn = {2472-5579, 2472-5587},
  doi = {10.1080/24725579.2017.1423419},
  url = {https://www.tandfonline.com/doi/full/10.1080/24725579.2017.1423419},
  urldate = {2020-07-07},
  abstract = {Longitudinal data analysis has found immense importance in biomedical fields to assess relationships between an outcome and its explanatory variables over time. However, this analysis is unreliable in presence of measurement errors in response data because the errors confound the effect of any signal caused by process changes. This confounding can be easily resolved by estimating and isolating the measurement errors using replicated measurements; i.e., multiple measurements in a small (stationary) time interval. However, in many medical applications, such as in magnetic resonance imaging (MRI), taking replicated measurements is not possible due to cost and/or risk considerations. This makes measurement error estimation and data analysis very challenging. In this article, we propose a novel method for the analysis of unreplicated longitudinal data under the presence of measurement errors. We formulate the problem using mixed-effect regression and develop a new EM-Variogram technique to estimate regression coefficients as well as variance components. The proposed approach decouples the confounded observed variance into the process and measurement system variances, and helps construct precise confidence intervals, leading to a more powerful statistical hypothesis test for the model parameters. We validate the proposed method using simulation and also apply it to a longitudinal MRI data for patients with neurodegenerative diseases. The results show improved statistical power in measuring their hippocampal volume loss, and a quicker degeneration detection. We also demonstrate the robustness of the proposed method with respect to missing values, a common issue in longitudinal data.},
  file = {/Users/hyan46/Dropbox (ASU)/ZoteroData/Ranjan et al_2018_Longitudinal MRI data analysis in presence of measurement error but absence of.pdf},
  langid = {english},
  number = {2}
}

@article{raoGraphtheoretic2015,
  title = {A Graph-Theoretic Approach for Quantification of Surface Morphology Variation and Its Application to Chemical Mechanical Planarization Process},
  author = {Rao, P. K. and Beyca, O. F. and Kong, Z. Y. and Bukkapatnam, Satish and Case, K. E. and Komanduri, R.},
  date = {2015-10-03},
  journaltitle = {Iie Transactions},
  shortjournal = {Iie Trans Iie Trans},
  volume = {47},
  pages = {1088--1111},
  issn = {0740-817x},
  url = {://WOS:000359770300004},
  abstract = {We present an algebraic graph-theoretic approach for quantification of surface morphology. Using this approach, heterogeneous, multi-scaled aspects of surfaces; e.g., semiconductor wafers, are tracked from optical micrographs as opposed to reticent profile mapping techniques. Therefore, this approach can facilitate in situ real-time assessment of surface quality. We report two complementary methods for realizing graph-theoretic representation and subsequent quantification of surface morphology variations from optical micrograph images. Experimental investigations with specular finished copper wafers (surface roughness (Sa) approximate to 6nm) obtained using a semiconductor chemical mechanical planarization process suggest that the graph-based topological invariant Fiedler number ((2)) was able to quantify and track variations in surface morphology more effectively compared to other quantifiers reported in literature.},
  file = {/Users/hyan46/Dropbox (ASU)/ZoteroData/Rao et al_2015_A graph-theoretic approach for quantification of surface morphology variation.pdf},
  keywords = {algebraic graph theory,chemical mechanical planarization (cmp),extraction,fiedler number,graph-based image processing,metrology,optical metrology,paradigm shifts,pattern,surface morphology quantification,surface quality,trends},
  langid = {english},
  number = {10}
}

@article{raoProcessMachine2014,
  title = {Process-{{Machine Interaction}} ({{PMI}}) {{Modeling}} and {{Monitoring}} of {{Chemical Mechanical Planarization}} ({{CMP}}) {{Process Using Wireless Vibration Sensors}}},
  author = {Rao, P. K. and Bhushan, M. B. and Bukkapatnam, Satish and Kong, Z. Y. and Byalal, S. and Beyca, O. F. and Fields, A. and Komanduri, R.},
  date = {2014-02},
  journaltitle = {Ieee Transactions on Semiconductor Manufacturing},
  shortjournal = {Ieee T Semiconduct M Ieee T Semiconduct M},
  volume = {27},
  pages = {1--15},
  issn = {0894-6507},
  url = {://WOS:000331325400001},
  abstract = {We present a deterministic process-machine interaction (PMI) model that can associate different complex time-frequency patterns, including nonlinear dynamic behaviors that manifest in vibration signals measured during a chemical mechanical planarization (CMP) process for polishing blanket copper wafer surfaces to near-optical finish (R-a similar to 5 nm) to specific process mechanisms. The model captures the effects of the nonuniform structural properties of the polishing pad, pad asperities, and machine kinematics on CMP dynamics using a deterministic 2 degrees of freedom nonlinear differential equation. The model was validated using a Buehler (Automet 250) bench top CMP machine instrumented with a wireless (XBee IEEE 802.15.4 RF module) multi-sensor unit that includes a MEMS 3-axis accelerometer (Analog Devices ADXL 335). Extensive experiments suggest that the deterministic PMI model can capture such significant signal patterns as aperiodicity, broadband frequency spectra, and other prominent manifestations of process nonlinearity. Remarkably, the deterministic PMI model was able to explain not just the physical sources of various time-frequency patterns observed in the measured vibration signals, but also, their variations with process conditions. The features extracted from experimental vibration data, such as power spectral density over the 115 - 120 Hz band, and nonlinear recurrence measures were statistically significant estimators (R-2 similar to 75\%) of process parameter settings. The model together with sparse experimental data was able to estimate process drifts resulting from pad wear with high fidelity (R-2 similar to 85\%). The signal features identified using the PMI model can lead to effective real-time in-situ monitoring of wear and anomalies in the CMP process.},
  keywords = {behavior,cmp condition monitoring,cu-cmp,end-point detection,friction,material removal rate,mrr,pmi model,rate decay,size distribution,slurry,vibration sensors,wireless},
  langid = {english},
  number = {1}
}

@article{raoRealtime2014,
  ids = {raoRealtime2014a},
  title = {Real-Time Identification of Incipient Surface Morphology Variations in Ultraprecision Machining Process},
  author = {Rao, Prahalad and Bukkapatnam, Satish and Beyca, Omer and Kong, Zhenyu James and Komanduri, Ranga},
  date = {2014},
  journaltitle = {Journal of Manufacturing Science and Engineering},
  volume = {136},
  issn = {1087-1357},
  keywords = {Aerospace,Change detection,diamond turning,Machining,Neural networks,recurrent prediction neural network,RPNN,Supervised learning,Surface finish,Ultraprecision},
  number = {2}
}

@inproceedings{raviAmortized2019,
  title = {Amortized {{Bayesian}} Meta-Learning},
  booktitle = {7th {{International Conference}} on {{Learning Representations}}, {{ICLR}} 2019},
  author = {Ravi, Sachin and Beatson, Alex},
  date = {2019},
  abstract = {Meta-learning, or learning-to-learn, has proven to be a successful strategy in attacking problems in supervised learning and reinforcement learning that involve small amounts of data. State-of-the-art solutions involve learning an initialization and/or optimization algorithm using a set of training episodes so that the meta-learner can generalize to an evaluation episode quickly. These methods perform well but often lack good quantification of uncertainty, which can be vital to real-world applications when data is lacking. We propose a meta-learning method which efficiently amortizes hierarchical variational inference across tasks, learning a prior distribution over neural network weights so that a few steps of Bayes by Backprop will produce a good task-specific approximate posterior. We show that our method produces good uncertainty estimates on contextual bandit and few-shot learning benchmarks.},
  file = {/Users/hyan46/Dropbox (ASU)/ZoteroData/Ravi_Beatson_2019_Amortized Bayesian meta-learning.pdf},
  keywords = {Method: Bayesian}
}

@article{reinhartReview2018,
  title = {A {{Review}} of {{Self}}-{{Exciting Spatio}}-{{Temporal Point Processes}} and {{Their Applications}}},
  author = {Reinhart, Alex},
  date = {2018-08},
  journaltitle = {Statistical Science},
  shortjournal = {Statist. Sci.},
  volume = {33},
  pages = {299--318},
  issn = {0883-4237},
  doi = {10.1214/17-STS629},
  url = {http://arxiv.org/abs/1708.02647},
  urldate = {2020-08-08},
  abstract = {Self-exciting spatio-temporal point process models predict the rate of events as a function of space, time, and the previous history of events. These models naturally capture triggering and clustering behavior, and have been widely used in fields where spatio-temporal clustering of events is observed, such as earthquake modeling, infectious disease, and crime. In the past several decades, advances have been made in estimation, inference, simulation, and diagnostic tools for self-exciting point process models. In this review, I describe the basic theory, survey related estimation and inference techniques from each field, highlight several key applications, and suggest directions for future research.},
  archiveprefix = {arXiv},
  eprint = {1708.02647},
  eprinttype = {arxiv},
  file = {/Users/hyan46/Dropbox (ASU)/ZoteroData/Reinhart_2018_A Review of Self-Exciting Spatio-Temporal Point Processes and Their Applications.pdf},
  keywords = {Statistics - Methodology},
  langid = {english},
  number = {3}
}

@article{reisigahrooeiComments2020,
  title = {Comments on: {{On Active Learning Methods}} for {{Manifold Data}}},
  shorttitle = {Comments On},
  author = {Reisi Gahrooei, Mostafa and Yan, Hao and Paynabar, Kamran},
  date = {2020-03},
  journaltitle = {TEST},
  shortjournal = {TEST},
  volume = {29},
  pages = {38--41},
  issn = {1133-0686, 1863-8260},
  doi = {10.1007/s11749-019-00696-w},
  url = {http://link.springer.com/10.1007/s11749-019-00696-w},
  urldate = {2020-07-07},
  file = {/Users/hyan46/Dropbox (ASU)/ZoteroData/Reisi Gahrooei et al_2020_Comments on2.pdf},
  langid = {english},
  number = {1}
}

@article{reisigahrooeiProcess2020,
  title = {Process {{Modeling}} and {{Prediction With Large Number}} of {{High}}-{{Dimensional Variables Using Functional Regression}}},
  author = {Reisi Gahrooei, Mostafa and Paynabar, Kamran and Pacella, Massimo and Shi, Jianjun},
  date = {2020-04},
  journaltitle = {IEEE Transactions on Automation Science and Engineering},
  shortjournal = {IEEE Trans. Automat. Sci. Eng.},
  volume = {17},
  pages = {684--696},
  issn = {1545-5955, 1558-3783},
  doi = {10.1109/TASE.2019.2941167},
  url = {https://ieeexplore.ieee.org/document/8862861/},
  urldate = {2020-07-07},
  abstract = {Learning the relationship between a response variable (e.g., a quality characteristic) and a set of predictors (e.g., process variables) is of special importance in process modeling, prediction, and optimization. In many applications, not only is the number of these variables large but these variables are also high-dimensional (HD) (e.g., they are represented by waveform signals). This high dimensionality requires a systematic approach to both modeling the relationship between the variables and removing the noninformative input variables. This article proposes a functional regression method in which an HD response is estimated and predicted through a set of informative and noninformative HD covariates. For this purpose, the functional regression coefficients are expanded through a set of low-dimensional smooth basis functions. In order to estimate the low-dimensional set of parameters, a penalized loss function with both smoothing and group lasso penalties is defined. The block coordinate decent (BCD) method is employed to develop a computationally tractable algorithm for minimizing the loss function. Through simulations and case studies, the performance of the proposed method is evaluated and compared with benchmarks. The results illustrate the advantage of the proposed method over the benchmarks.},
  file = {/Users/hyan46/Zotero/storage/GYUJ4E9A/Reisi Gahrooei et al. - 2020 - Process Modeling and Prediction With Large Number .pdf},
  langid = {english},
  number = {2}
}

@article{renAdaptive2008,
  title = {Adaptive Evolutionary {{Monte Carlo}} Algorithm for Optimization with Applications to Sensor Placement Problems},
  author = {Ren, Yuan and Ding, Yu and Liang, Faming},
  date = {2008-12},
  journaltitle = {Statistics and Computing},
  shortjournal = {Stat Comput},
  volume = {18},
  pages = {375--390},
  issn = {0960-3174, 1573-1375},
  doi = {10.1007/s11222-008-9079-6},
  url = {http://link.springer.com/10.1007/s11222-008-9079-6},
  urldate = {2020-07-04},
  abstract = {In this paper, we present an adaptive evolutionary Monte Carlo algorithm (AEMC), which combines a treebased predictive model with an evolutionary Monte Carlo sampling procedure for the purpose of global optimization. Our development is motivated by sensor placement applications in engineering, which requires optimizing certain complicated “black-box” objective function. The proposed method is able to enhance the optimization efficiency and effectiveness as compared to a few alternative strategies. AEMC falls into the category of adaptive Markov chain Monte Carlo (MCMC) algorithms and is the first adaptive MCMC algorithm that simulates multiple Markov chains in parallel. A theorem about the ergodicity property of the AEMC algorithm is stated and proven. We demonstrate the advantages of the proposed method by applying it to a sensor placement problem in a manufacturing process, as well as to a standard Griewank test function.},
  file = {/Users/hyan46/Dropbox (ASU)/ZoteroData/Ren et al_2008_Adaptive evolutionary Monte Carlo algorithm for optimization with applications.pdf},
  keywords = {Application: Assembly,Application: Manufacturing,Method: Adaptive Sampling,People: Yu Ding},
  langid = {english},
  number = {4}
}

@article{renData2006,
  title = {A Data Mining Approach to Study the Significance of Nonlinearity in Multistation Assembly Processes},
  author = {Ren, Yuan and Ding, Yu and Zhou, Shiyu},
  date = {2006-12},
  journaltitle = {IIE Transactions},
  shortjournal = {IIE Transactions},
  volume = {38},
  pages = {1069--1083},
  issn = {0740-817X, 1545-8830},
  doi = {10.1080/07408170600735538},
  url = {http://www.tandfonline.com/doi/abs/10.1080/07408170600735538},
  urldate = {2020-07-04},
  file = {/Users/hyan46/Dropbox (ASU)/ZoteroData/Ren et al_2006_A data mining approach to study the significance of nonlinearity in.pdf},
  keywords = {Application: Assembly,Application: Manufacturing,People: Yu Ding},
  langid = {english},
  number = {12}
}

@article{renGeneric2018,
  title = {A {{Generic Deep}}-{{Learning}}-{{Based Approach}} for {{Automated Surface Inspection}}},
  author = {Ren, Ruoxu and Hung, Terence and Tan, Kay Chen},
  date = {2018-03},
  journaltitle = {IEEE Transactions on Cybernetics},
  shortjournal = {IEEE Trans. Cybern.},
  volume = {48},
  pages = {929--940},
  issn = {2168-2267, 2168-2275},
  doi = {10.1109/TCYB.2017.2668395},
  url = {http://ieeexplore.ieee.org/document/7864335/},
  urldate = {2020-07-15},
  abstract = {Automated surface inspection (ASI) is a challenging task in industry, as collecting training dataset is usually costly and related methods are highly dataset-dependent. In this paper, a generic approach that requires small training data for ASI is proposed. First, this approach builds classifier on the features of image patches, where the features are transferred from a pretrained deep learning network. Next, pixel-wise prediction is obtained by convolving the trained classifier over input image. An experiment on three public and one industrial data set is carried out. The experiment involves two tasks: 1) image classification and 2) defect segmentation. The results of proposed algorithm are compared against several best benchmarks in literature. In the classification tasks, the proposed method improves accuracy by 0.66\%–25.50\%. In the segmentation tasks, the proposed method reduces error escape rates by 6.00\%–19.00\% in three defect types and improves accuracies by 2.29\%–9.86\% in all seven defect types. In addition, the proposed method achieves 0.0\% error escape rate in the segmentation task of industrial data.},
  file = {/Users/hyan46/Dropbox (ASU)/ZoteroData/Ren et al_2018_A Generic Deep-Learning-Based Approach for Automated Surface Inspection.pdf},
  langid = {english},
  number = {3}
}

@online{renLikelihood2019,
  title = {Likelihood {{Ratios}} for {{Out}}-of-{{Distribution Detection}}},
  author = {Ren, Jie and Liu, Peter J. and Fertig, Emily and Snoek, Jasper and Poplin, Ryan and DePristo, Mark A. and Dillon, Joshua V. and Lakshminarayanan, Balaji},
  date = {2019-12-05},
  url = {http://arxiv.org/abs/1906.02845},
  urldate = {2020-07-25},
  abstract = {Discriminative neural networks offer little or no performance guarantees when deployed on data not generated by the same process as the training distribution. On such out-of-distribution (OOD) inputs, the prediction may not only be erroneous, but confidently so, limiting the safe deployment of classifiers in real-world applications. One such challenging application is bacteria identification based on genomic sequences, which holds the promise of early detection of diseases, but requires a model that can output low confidence predictions on OOD genomic sequences from new bacteria that were not present in the training data. We introduce a genomics dataset for OOD detection that allows other researchers to benchmark progress on this important problem. We investigate deep generative model based approaches for OOD detection and observe that the likelihood score is heavily affected by population level background statistics. We propose a likelihood ratio method for deep generative models which effectively corrects for these confounding background statistics. We benchmark the OOD detection performance of the proposed method against existing approaches on the genomics dataset and show that our method achieves state-of-the-art performance. We demonstrate the generality of the proposed method by showing that it significantly improves OOD detection when applied to deep generative models of images.},
  archiveprefix = {arXiv},
  eprint = {1906.02845},
  eprinttype = {arxiv},
  file = {/Users/hyan46/Zotero/storage/SCGUHY83/1906.html},
  keywords = {Computer Science - Machine Learning,Method: Deep Learning,Problem: Process Monitoring,Statistics - Machine Learning},
  primaryclass = {cs, stat}
}

@inproceedings{ribeiroWhy2016,
  title = {"{{Why Should I Trust You}}?": {{Explaining}} the {{Predictions}} of {{Any Classifier}}},
  shorttitle = {"{{Why Should I Trust You}}?},
  booktitle = {Proceedings of the 22nd {{ACM SIGKDD International Conference}} on {{Knowledge Discovery}} and {{Data Mining}}},
  author = {Ribeiro, Marco Tulio and Singh, Sameer and Guestrin, Carlos},
  date = {2016-08-13},
  pages = {1135--1144},
  publisher = {{ACM}},
  location = {{San Francisco California USA}},
  doi = {10.1145/2939672.2939778},
  url = {https://dl.acm.org/doi/10.1145/2939672.2939778},
  urldate = {2020-09-27},
  abstract = {Despite widespread adoption, machine learning models remain mostly black boxes. Understanding the reasons behind predictions is, however, quite important in assessing trust, which is fundamental if one plans to take action based on a prediction, or when choosing whether to deploy a new model. Such understanding also provides insights into the model, which can be used to transform an untrustworthy model or prediction into a trustworthy one. In this work, we propose LIME, a novel explanation technique that explains the predictions of any classifier in an interpretable and faithful manner, by learning an interpretable model locally around the prediction. We also propose a method to explain models by presenting representative individual predictions and their explanations in a non-redundant way, framing the task as a submodular optimization problem. We demonstrate the flexibility of these methods by explaining different models for text (e.g. random forests) and image classification (e.g. neural networks). We show the utility of explanations via novel experiments, both simulated and with human subjects, on various scenarios that require trust: deciding if one should trust a prediction, choosing between models, improving an untrustworthy classifier, and identifying why a classifier should not be trusted.},
  eventtitle = {{{KDD}} '16: {{The}} 22nd {{ACM SIGKDD International Conference}} on {{Knowledge Discovery}} and {{Data Mining}}},
  file = {/Users/hyan46/Dropbox (ASU)/ZoteroData/Ribeiro et al_2016_Why Should I Trust You.pdf},
  isbn = {978-1-4503-4232-2},
  langid = {english}
}

@article{rizoiuSIRHawkes2018,
  title = {{{SIR}}-{{Hawkes}}: {{Linking Epidemic Models}} and {{Hawkes Processes}} to {{Model Diffusions}} in {{Finite Populations}}},
  shorttitle = {{{SIR}}-{{Hawkes}}},
  author = {Rizoiu, Marian-Andrei and Mishra, Swapnil and Kong, Quyu and Carman, Mark and Xie, Lexing},
  date = {2018},
  journaltitle = {Proceedings of the 2018 World Wide Web Conference on World Wide Web - WWW '18},
  pages = {419--428},
  doi = {10.1145/3178876.3186108},
  url = {http://arxiv.org/abs/1711.01679},
  urldate = {2020-08-08},
  abstract = {Among the statistical tools for online information diffusion modeling, both epidemic models and Hawkes point processes are popular choices. The former originate from epidemiology, and consider information as a viral contagion which spreads into a population of online users. The latter have roots in geophysics and finance, view individual actions as discrete events in continuous time, and modulate the rate of events according to the self-exciting nature of event sequences. Here, we establish a novel connection between these two frameworks. Namely, the rate of events in an extended Hawkes model is identical to the rate of new infections in the SusceptibleInfected-Recovered (SIR) model after marginalizing out recovery events – which are unobserved in a Hawkes process. This result paves the way to apply tools developed for SIR to Hawkes, and vice versa. It also leads to HawkesN, a generalization of the Hawkes model which accounts for a finite population size. Finally, we derive the distribution of cascade sizes for HawkesN, inspired by methods in stochastic SIR. Such distributions provide nuanced explanations to the general unpredictability of popularity: the distribution for diffusion cascade sizes tends to have two modes, one corresponding to large cascade sizes and another one around zero.},
  archiveprefix = {arXiv},
  eprint = {1711.01679},
  eprinttype = {arxiv},
  file = {/Users/hyan46/Dropbox (ASU)/ZoteroData/Rizoiu et al_2018_SIR-Hawkes.pdf},
  keywords = {Computer Science - Social and Information Networks,Physics - Physics and Society},
  langid = {english}
}

@article{rocchettaReinforcement2019,
  title = {A Reinforcement Learning Framework for Optimal Operation and Maintenance of Power Grids},
  author = {Rocchetta, Roberto and Bellani, L. and Compare, M. and Zio, E. and Patelli, E.},
  date = {2019},
  journaltitle = {Applied energy},
  volume = {241},
  pages = {291--301},
  publisher = {{Elsevier}},
  isbn = {0306-2619},
  keywords = {maintenance}
}

@incollection{rogersMultilinear2013,
  title = {Multilinear {{Dynamical Systems}} for {{Tensor Time Series}}},
  booktitle = {Advances in {{Neural Information Processing Systems}} 26},
  author = {Rogers, Mark and Li, Lei and Russell, Stuart J},
  editor = {Burges, C. J. C. and Bottou, L. and Welling, M. and Ghahramani, Z. and Weinberger, K. Q.},
  date = {2013},
  pages = {2634--2642},
  publisher = {{Curran Associates, Inc.}},
  url = {http://papers.nips.cc/paper/5117-multilinear-dynamical-systems-for-tensor-time-series.pdf},
  urldate = {2020-06-13},
  file = {/Users/hyan46/Dropbox (ASU)/ZoteroData/Rogers et al_2013_Multilinear Dynamical Systems for Tensor Time Series2.pdf;/Users/hyan46/Zotero/storage/DCHBSVNE/5117-multilinear-dynamical-systems-for-tensor-time-series.html},
  keywords = {Method: Tensor}
}

@inproceedings{rohrbachEvaluating2011,
  title = {Evaluating Knowledge Transfer and Zero-Shot Learning in a Large-Scale Setting},
  booktitle = {{{CVPR}} 2011},
  author = {Rohrbach, Marcus and Stark, Michael and Schiele, Bernt},
  date = {2011-06},
  pages = {1641--1648},
  publisher = {{IEEE}},
  location = {{Colorado Springs, CO, USA}},
  doi = {10.1109/CVPR.2011.5995627},
  url = {http://ieeexplore.ieee.org/document/5995627/},
  urldate = {2021-06-02},
  abstract = {While knowledge transfer (KT) between object classes has been accepted as a promising route towards scalable recognition, most experimental KT studies are surprisingly limited in the number of object classes considered. To support claims of KT w.r.t. scalability we thus advocate to evaluate KT in a large-scale setting. To this end, we provide an extensive evaluation of three popular approaches to KT on a recently proposed large-scale data set, the ImageNet Large Scale Visual Recognition Competition 2010 data set. In a first setting they are directly compared to one-vs-all classification often neglected in KT papers and in a second setting we evaluate their ability to enable zero-shot learning. While none of the KT methods can improve over one-vs-all classification they prove valuable for zero-shot learning, especially hierarchical and direct similarity based KT. We also propose and describe several extensions of the evaluated approaches that are necessary for this large-scale study.},
  eventtitle = {2011 {{IEEE Conference}} on {{Computer Vision}} and {{Pattern Recognition}} ({{CVPR}})},
  file = {/Users/hyan46/Dropbox (ASU)/ZoteroData/Rohrbach et al_2011_Evaluating knowledge transfer and zero-shot learning in a large-scale setting.pdf},
  isbn = {978-1-4577-0394-2},
  langid = {english}
}

@incollection{romera-paredesEmbarrassingly2017,
  title = {An {{Embarrassingly Simple Approach}} to {{Zero}}-{{Shot Learning}}},
  booktitle = {Visual {{Attributes}}},
  author = {Romera-Paredes, Bernardino and Torr, Philip H. S.},
  editor = {Feris, Rogerio Schmidt and Lampert, Christoph and Parikh, Devi},
  date = {2017},
  pages = {11--30},
  publisher = {{Springer International Publishing}},
  location = {{Cham}},
  doi = {10.1007/978-3-319-50077-5_2},
  url = {http://link.springer.com/10.1007/978-3-319-50077-5_2},
  urldate = {2021-06-03},
  abstract = {Zero-shot learning consists in learning how to recognise new concepts by just having a description of them. Many sophisticated approaches have been proposed to address the challenges this problem comprises. In this paper we describe a zero-shot learning approach that can be implemented in just one line of code, yet it is able to outperform state of the art approaches on standard datasets. The approach is based on a more general framework which models the relationships between features, attributes, and classes as a two linear layers network, where the weights of the top layer are not learned but are given by the environment. We further provide a learning bound on the generalisation error of this kind of approaches, by casting them as domain adaptation methods. In experiments carried out on three standard real datasets, we found that our approach is able to perform significantly better than the state of art on all of them, obtaining a ratio of improvement up to 17\%.},
  file = {/Users/hyan46/Dropbox (ASU)/ZoteroData/Romera-Paredes_Torr_2017_An Embarrassingly Simple Approach to Zero-Shot Learning.pdf},
  isbn = {978-3-319-50075-1 978-3-319-50077-5},
  langid = {english},
  series = {Advances in {{Computer Vision}} and {{Pattern Recognition}}}
}

@online{ruffDeep2020,
  title = {Deep {{Semi}}-{{Supervised Anomaly Detection}}},
  author = {Ruff, Lukas and Vandermeulen, Robert A. and Görnitz, Nico and Binder, Alexander and Müller, Emmanuel and Müller, Klaus-Robert and Kloft, Marius},
  date = {2020-02-14},
  url = {http://arxiv.org/abs/1906.02694},
  urldate = {2020-05-25},
  abstract = {Deep approaches to anomaly detection have recently shown promising results over shallow methods on large and complex datasets. Typically anomaly detection is treated as an unsupervised learning problem. In practice however, one may have---in addition to a large set of unlabeled samples---access to a small pool of labeled samples, e.g. a subset verified by some domain expert as being normal or anomalous. Semi-supervised approaches to anomaly detection aim to utilize such labeled samples, but most proposed methods are limited to merely including labeled normal samples. Only a few methods take advantage of labeled anomalies, with existing deep approaches being domain-specific. In this work we present Deep SAD, an end-to-end deep methodology for general semi-supervised anomaly detection. We further introduce an information-theoretic framework for deep anomaly detection based on the idea that the entropy of the latent distribution for normal data should be lower than the entropy of the anomalous distribution, which can serve as a theoretical interpretation for our method. In extensive experiments on MNIST, Fashion-MNIST, and CIFAR-10, along with other anomaly detection benchmark datasets, we demonstrate that our method is on par or outperforms shallow, hybrid, and deep competitors, yielding appreciable performance improvements even when provided with only little labeled data.},
  archiveprefix = {arXiv},
  eprint = {1906.02694},
  eprinttype = {arxiv},
  file = {/Users/hyan46/Zotero/storage/Z6YTGEW5/1906.html},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryclass = {cs, stat}
}

@online{RuHeZhengJiuWuFa,
  title = {如何拯救无法「深度学习」的制造业，2019工业智能灵魂10问},
  url = {https://zhuanlan.zhihu.com/p/102465409},
  urldate = {2020-05-23},
  abstract = {一条难以逾越的鸿沟正横跨在人工智能与工业制造之间。我国是制造业第一大国，2018 年制造业增加值达 26.5 万亿元，占 GDP 总量的 29.4\%，占比近三分之一。同时我国又是人工智能第二大国，拥有全球第二多的 AI 企业…},
  file = {/Users/hyan46/Dropbox (ASU)/ZoteroData/如何拯救无法「深度学习」的制造业，2019工业智能灵魂10问.pdf},
  keywords = {Application: Manufacturing},
  langid = {pinyin},
  organization = {{知乎专栏}}
}

@inproceedings{ruizhiAdversarial,
  title = {Adversarial {{Robust Estimate}} and {{Risk Analysis}} in {{Linear Regression}}},
  author = {Ruizhi, Zhang},
  file = {/Users/hyan46/Dropbox (ASU)/ZoteroData/Ruizhi_Adversarial Robust Estimate and Risk Analysis in Linear Regression.pdf}
}

@book{rupertgSurvival2011,
  title = {Survival {{Analysis}}},
  author = {Rupert G, Miller Jr},
  date = {2011-01},
  abstract = {A concise summary of the statistical methods used in the analysis of survival data with censoring. Emphasizes recently developed nonparametric techniques. Outlines methods in detail and illustrates them with actual data. Discusses the theory behind each method. Includes numerous worked problems and numerical exercises.},
  isbn = {978-1-118-03106-3},
  pagetotal = {238},
  series = {Wiley {{Classics Library}}}
}

@article{sa-ngasoongsongMultistep2012,
  title = {Multi-Step Sales Forecasting in Automotive Industry Based on Structural Relationship Identification},
  author = {Sa-ngasoongsong, A. and Bukkapatnam, Satish and Kim, J. and Iyer, P. S. and Suresh, R. P.},
  date = {2012-12},
  journaltitle = {International Journal of Production Economics},
  shortjournal = {Int J Prod Econ Int J Prod Econ},
  volume = {140},
  pages = {875--887},
  issn = {0925-5273},
  url = {://WOS:000311193200036},
  abstract = {Forecasting sales and demand over 6-24 month horizon is crucial for planning the production processes of automotive and other complex product industries (e.g., electronics and heavy equipment) where typical concept-to-release times are 12-60 month long. However, nonlinear and nonstationary evolution and dependencies with diverse macroeconomic variables hinder accurate long-term prediction of the future of automotive sales. In this paper, a structural relationship identification methodology that uses a battery of statistical unit root, weakly exogeneity, Granger-causality and cointegration tests, is presented to identify the dynamic couplings among automobile sales and economic indicators. Our empirical analysis indicates that automobile sales at segment levels have a long-run equilibrium relationship (cointegration) with identified economic indicators. A vector error correction model (VECM) of multi-segment automobile sales was estimated based on impulse response functions to quantify long-term impact of these economic indicators on sales. Comparisons of prediction accuracy demonstrate that VECM model outperforms other classical and advanced time-series techniques. The empirical results suggest that VECM can significantly improve prediction accuracy of automotive sales for 12-month ahead prediction in terms of RMSE (42.73\%) and MAPE (42.25\%), compared to the classical time series techniques. (C) 2012 Elsevier B.V. All rights reserved.},
  keywords = {automobile sales forecasting,autoregressive time-series,causality,choice,cointegration,demand,error correction,long-run equilibrium relationship,models,price,promotions,statistical-analysis,vector error correction model},
  langid = {english},
  number = {2}
}

@article{sabbaghiBayesian2018,
  title = {Bayesian {{Model Building From Small Samples}} of {{Disparate Data}} for {{Capturing In}}-{{Plane Deviation}} in {{Additive Manufacturing}}},
  author = {Sabbaghi, Arman and Huang, Qiang and Dasgupta, Tirthankar},
  date = {2018-10-02},
  journaltitle = {Technometrics},
  shortjournal = {Technometrics},
  volume = {60},
  pages = {532--544},
  issn = {0040-1706, 1537-2723},
  doi = {10.1080/00401706.2017.1391715},
  url = {https://www.tandfonline.com/doi/full/10.1080/00401706.2017.1391715},
  urldate = {2020-07-04},
  abstract = {Quality control of geometric shape deviation in additive manufacturing relies on statistical deviation models. However, resource constraints limit the manufacture of test shapes, and consequently impede the specification of deviation models for new shape varieties. We present an adaptive Bayesian methodology that effectively combines in-plane deviation data and models for a small sample of previously manufactured, disparate shapes to aid in the model specification of in-plane deviation for a broad class of new shapes. The power and simplicity of this general methodology is demonstrated with illustrative case studies on in-plane deviation modeling for polygons and straight edges in free-form shapes using only data and models for cylinders and a single regular pentagon. Our Bayesian approach facilitates deviation modeling in general, and thereby can help advance additive manufacturing as a high-quality technology. Supplementary materials for this article are available online.},
  file = {/Users/hyan46/Dropbox (ASU)/ZoteroData/Sabbaghi et al_2018_Bayesian Model Building From Small Samples of Disparate Data for Capturing.pdf},
  keywords = {Application: Additive Manufacturing,Application: Manufacturing,Method: Bayesian,People: Qiang Huang},
  langid = {english},
  number = {4}
}

@article{sabbaghiInference2014,
  title = {Inference for Deformation and Interference in {{3D}} Printing},
  author = {Sabbaghi, Arman and Dasgupta, Tirthankar and Huang, Qiang and Zhang, Jizhe},
  date = {2014-09},
  journaltitle = {The Annals of Applied Statistics},
  shortjournal = {Ann. Appl. Stat.},
  volume = {8},
  pages = {1395--1415},
  issn = {1932-6157},
  doi = {10.1214/14-AOAS762},
  url = {http://projecteuclid.org/euclid.aoas/1414091218},
  urldate = {2020-07-04},
  file = {/Users/hyan46/Dropbox (ASU)/ZoteroData/Sabbaghi et al_2014_Inference for deformation and interference in 3D printing.pdf},
  keywords = {People: Qiang Huang},
  langid = {english},
  number = {3}
}

@article{sabbaghiModel2018,
  title = {Model Transfer across Additive Manufacturing Processes via Mean Effect Equivalence of Lurking Variables},
  author = {Sabbaghi, Arman and Huang, Qiang},
  date = {2018-12},
  journaltitle = {The Annals of Applied Statistics},
  shortjournal = {Ann. Appl. Stat.},
  volume = {12},
  pages = {2409--2429},
  issn = {1932-6157},
  doi = {10.1214/18-AOAS1158},
  url = {https://projecteuclid.org/euclid.aoas/1542078050},
  urldate = {2020-07-04},
  file = {/Users/hyan46/Dropbox (ASU)/ZoteroData/Sabbaghi_Huang_2018_Model transfer across additive manufacturing processes via mean effect.pdf},
  keywords = {Application: Additive Manufacturing,Application: Manufacturing,Method: Transfer Learning,People: Qiang Huang},
  langid = {english},
  number = {4}
}

@article{sandoukMultiLabel,
  title = {Multi-{{Label Zero}}-{{Shot Learning}} via {{Concept Embedding}}},
  author = {Sandouk, Ubai and Chen, Ke},
  pages = {15},
  abstract = {Zero Shot Learning (ZSL) enables a learning model to classify instances of an unseen class during training. While most research in ZSL focuses on single-label classification, few studies have been done in multi-label ZSL, where an instance is associated with a set of labels simultaneously, due to the difficulty in modeling complex semantics conveyed by a set of labels. In this paper, we propose a novel approach to multi-label ZSL via concept embedding learned from collections of public users’ annotations of multimedia. Thanks to concept embedding, multi-label ZSL can be done by efficiently mapping an instance input features onto the concept embedding space in a similar manner used in single-label ZSL. Moreover, our semantic learning model is capable of embedding an out-of-vocabulary label by inferring its meaning from its co-occurring labels. Thus, our approach allows both seen and unseen labels during the concept embedding learning to be used in the aforementioned instance mapping, which makes multi-label ZSL more flexible and suitable for real applications. Experimental results of multilabel ZSL on images and music tracks suggest that our approach outperforms a state-of-the-art multi-label ZSL model and can deal with a scenario involving out-of-vocabulary labels without re-training the semantics learning model.},
  file = {/Users/hyan46/Dropbox (ASU)/ZoteroData/Sandouk_Chen_Multi-Label Zero-Shot Learning via Concept Embedding.pdf},
  langid = {english}
}

@online{schrammSymmetric2015,
  title = {Symmetric {{Tensor Completion}} from {{Multilinear Entries}} and {{Learning Product Mixtures}} over the {{Hypercube}}},
  author = {Schramm, Tselil and Weitz, Benjamin},
  date = {2015-11-23},
  url = {http://arxiv.org/abs/1506.03137},
  urldate = {2020-11-18},
  abstract = {We give an algorithm for completing an order-m symmetric low-rank tensor from its multilinear entries in time roughly proportional to the number of tensor entries. We apply our tensor completion algorithm to the problem of learning mixtures of product distributions over the hypercube, obtaining new algorithmic results. If the centers of the product distribution are linearly independent, then we recover distributions with as many as Ω(n) centers in polynomial time and sample complexity. In the general case, we recover distributions with as many as Ω˜ (n) centers in quasi-polynomial time, answering an open problem of Feldman et al. (SIAM J. Comp.) for the special case of distributions with incoherent bias vectors. Our main algorithmic tool is the iterated application of a low-rank matrix completion algorithm for matrices with adversarially missing entries.},
  archiveprefix = {arXiv},
  eprint = {1506.03137},
  eprinttype = {arxiv},
  file = {/Users/hyan46/Dropbox (ASU)/ZoteroData/Schramm_Weitz_2015_Symmetric Tensor Completion from Multilinear Entries and Learning Product.pdf},
  keywords = {Computer Science - Data Structures and Algorithms,Computer Science - Machine Learning,Statistics - Machine Learning},
  langid = {english},
  primaryclass = {cs, stat}
}

@article{schrunnerstefanMachineInReview,
  title = {Machine {{Learning}} Based {{Indicators}} to {{Enhance Process Monitoring}} by {{Pattern Recognition}}},
  author = {{Schrunner, Stefan} and {Scheiber, Michael} and {Jenul, Anna} and {Zernig, Anja} and {Kaestner, Andre} and {Kern, Roman}},
  year = {In Review},
  journaltitle = {IEEE Transactions on Automation Science and Engineering},
  file = {/Users/hyan46/Dropbox (ASU)/ZoteroData/Schrunner, Stefan et al_In Review_Machine Learning based Indicators to Enhance Process Monitoring by Pattern.pdf}
}

@article{schwierZero2009,
  title = {Zero Knowledge Hidden Markov Model Inference},
  author = {Schwier, Jason M and Brooks, Richard R and Griffin, Christopher and Bukkapatnam, Satish},
  date = {2009},
  journaltitle = {Pattern Recognition Letters},
  volume = {30},
  pages = {1273--1280},
  issn = {0167-8655},
  number = {14}
}

@online{SemiSupervised,
  title = {Semi-{{Supervised Anomaly Detection Survey}}},
  url = {https://kaggle.com/matheusfacure/semi-supervised-anomaly-detection-survey},
  urldate = {2020-05-25},
  abstract = {Explore and run machine learning code with Kaggle Notebooks | Using data from Credit Card Fraud Detection},
  file = {/Users/hyan46/Zotero/storage/BS4GF34C/semi-supervised-anomaly-detection-survey.html},
  langid = {english}
}

@article{sergin2021toward,
  title = {Toward a Better Monitoring Statistic for Profile Monitoring via Variational Autoencoders},
  author = {Sergin, Nurettin Dorukhan and Yan, Hao},
  date = {2021},
  journaltitle = {Journal of Quality Technology},
  pages = {1--46},
  publisher = {{Taylor \& Francis}},
  doi = {10.1080/00224065.2021.1903821},
  abstract = {Variational autoencoders have been recently proposed for the problem of process monitoring. While these works show impressive results over classical methods, the proposed monitoring statistics often ignore the inconsistencies in learned lower-dimensional representations and computational limitations in high-dimensional approximations. In this work, we first manifest these issues and then overcome them with a novel statistic formulation that increases out-of-control detection accuracy without compromising computational efficiency. We demonstrate our results on a simulation study with explicit control over latent variations, and a real-life example of image profiles obtained from a hot steel rolling process.},
  file = {/Users/hyan46/Dropbox (ASU)/ZoteroData/Sergin_Yan_2021_Toward a better monitoring statistic for profile monitoring via variational.pdf},
  keywords = {Application: Manufacturing,Data: Image,Method: Deep Learning,Problem: Anomaly Detection}
}

@article{serginHighdimensionalInPress,
  title = {High-Dimensional {{Nonlinear Profile Monitoring}} Based on {{Deep Probabilistic Autoencoders}}},
  author = {Sergin, Nurettin and Yan, Hao},
  year = {In Press},
  journaltitle = {Journal of Quality Technology},
  url = {http://arxiv.org/abs/1911.00482},
  abstract = {Wide accessibility of imaging and profile sensors in modern industrial systems created an abundance of high-dimensional sensing variables. This led to a a growing interest in the research of high-dimensional process monitoring. However, most of the approaches in the literature assume the in-control population to lie on a linear manifold with a given basis (i.e., spline, wavelet, kernel, etc) or an unknown basis (i.e., principal component analysis and its variants), which cannot be used to efficiently model profiles with a nonlinear manifold which is common in many real-life cases. We propose deep probabilistic autoencoders as a viable unsupervised learning approach to model such manifolds. To do so, we formulate nonlinear and probabilistic extensions of the monitoring statistics from classical approaches as the expected reconstruction error (ERE) and the KL-divergence (KLD) based monitoring statistics. Through extensive simulation study, we provide insights on why latent-space based statistics are unreliable and why residual-space based ones typically perform much better for deep learning based approaches. Finally, we demonstrate the superiority of deep probabilistic models via both simulation study and a real-life case study involving images of defects from a hot steel rolling process.},
  annotation = {\_eprint: 1911.00482},
  file = {/Users/hyan46/Dropbox (ASU)/ZoteroData/Sergin_Yan_In Press_High-dimensional Nonlinear Profile Monitoring based on Deep Probabilistic.pdf},
  keywords = {Application: Rolling,Data: Image,Method: Deep Learning,Method: Functional,Problem: Process Monitoring}
}

@book{settlesActive2012,
  title = {Active {{Learning}}},
  author = {Settles, Burr},
  date = {2012-07-01},
  publisher = {{Morgan \& Claypool Publishers}},
  abstract = {The key idea behind active learning is that a machine learning algorithm can perform better with less training if it is allowed to choose the data from which it learns. An active learner may pose "queries," usually in the form of unlabeled data instances to be labeled by an "oracle" (e.g., a human annotator) that already understands the nature of the problem. This sort of approach is well-motivated in many modern machine learning and data mining applications, where unlabeled data may be abundant or easy to come by, but training labels are difficult, time-consuming, or expensive to obtain. This book is a general introduction to active learning. It outlines several scenarios in which queries might be formulated, and details many query selection algorithms which have been organized into four broad categories, or "query selection frameworks." We also touch on some of the theoretical foundations of active learning, and conclude with an overview of the strengths and weaknesses of these approaches in practice, including a summary of ongoing work to address these open challenges and opportunities. Table of Contents: Automating Inquiry / Uncertainty Sampling / Searching Through the Hypothesis Space / Minimizing Expected Error and Variance / Exploiting Structure in Data / Theory / Practical Considerations},
  eprint = {fbFdAQAAQBAJ},
  eprinttype = {googlebooks},
  file = {/Users/hyan46/Dropbox (ASU)/ZoteroData/Settles_2012_Active Learning.pdf},
  isbn = {978-1-60845-726-7},
  keywords = {Computers / Hardware / General,Computers / Intelligence (AI) & Semantics,Computers / Machine Theory},
  langid = {english},
  pagetotal = {116}
}

@article{setzerArtificial2020,
  title = {Artificial {{Intelligence}} for the {{Computer}}-Aided {{Detection}} of {{Periapical Lesions}} in {{Cone}}-Beam {{Computed Tomographic Images}}},
  author = {Setzer, Frank C. and Shi, Katherine J. and Zhang, Zhiyang and Yan, Hao and Yoon, Hyunsoo and Mupparapu, Mel and Li, Jing},
  date = {2020-07-01},
  journaltitle = {Journal of Endodontics},
  shortjournal = {Journal of Endodontics},
  volume = {46},
  pages = {987--993},
  issn = {0099-2399},
  doi = {10.1016/j.joen.2020.03.025},
  url = {https://www.sciencedirect.com/science/article/pii/S0099239920302351},
  urldate = {2021-07-05},
  abstract = {Introduction The aim of this study was to use a Deep Learning (DL) algorithm for the automated segmentation of cone-beam computed tomographic (CBCT) images and the detection of periapical lesions. Methods Limited field of view CBCT volumes (n = 20) containing 61 roots with and without lesions were segmented clinician dependent versus using the DL approach based on a U-Net architecture. Segmentation labeled each voxel as 1 of 5 categories: “lesion” (periapical lesion), “tooth structure,” “bone,” “restorative materials,” and “background.” Repeated splits of all images into a training set and a validation set based on 5-fold cross validation were performed using Deep Learning segmentation (DLS), and the results were averaged. DLS versus clinical-dependent segmentation was assessed by dichotomized lesion detection accuracy evaluating sensitivity, specificity, positive predictive value, negative predictive value, and voxel-matching accuracy using the DICE index for each of the 5 labels. Results DLS lesion detection accuracy was 0.93 with specificity of 0.88, positive predictive value of 0.87, and negative predictive value of 0.93. The overall cumulative DICE indexes for the individual labels were lesion = 0.52, tooth structure = 0.74, bone = 0.78, restorative materials = 0.58, and background = 0.95. The cumulative DICE index for all actual true lesions was 0.67. Conclusions This DL algorithm trained in a limited CBCT environment showed excellent results in lesion detection accuracy. Overall voxel-matching accuracy may be benefited by enhanced versions of artificial intelligence.},
  keywords = {Artificial intelligence,cone-beam computed tomography,Deep Learning,digital imaging/radiology,periapical lesion,U-Net},
  langid = {english},
  number = {7}
}

@online{shafaeiLess2019,
  title = {A {{Less Biased Evaluation}} of {{Out}}-of-Distribution {{Sample Detectors}}},
  author = {Shafaei, Alireza and Schmidt, Mark and Little, James J.},
  date = {2019-08-20},
  url = {http://arxiv.org/abs/1809.04729},
  urldate = {2020-09-06},
  abstract = {In the real world, a learning system could receive an input that is unlike anything it has seen during training. Unfortunately, out-of-distribution samples can lead to unpredictable behaviour. We need to know whether any given input belongs to the population distribution of the training/evaluation data to prevent unpredictable behaviour in deployed systems. A recent surge of interest in this problem has led to the development of sophisticated techniques in the deep learning literature. However, due to the absence of a standard problem definition or an exhaustive evaluation, it is not evident if we can rely on these methods. What makes this problem different from a typical supervised learning setting is that the distribution of outliers used in training may not be the same as the distribution of outliers encountered in the application. Classical approaches that learn inliers vs. outliers with only two datasets can yield optimistic results. We introduce OD-test, a three-dataset evaluation scheme as a more reliable strategy to assess progress on this problem. We present an exhaustive evaluation of a broad set of methods from related areas on image classification tasks. Contrary to the existing results, we show that for realistic applications of highdimensional images the previous techniques have low accuracy and are not reliable in practice.},
  archiveprefix = {arXiv},
  eprint = {1809.04729},
  eprinttype = {arxiv},
  file = {/Users/hyan46/Dropbox (ASU)/ZoteroData/Shafaei et al_2019_A Less Biased Evaluation of Out-of-distribution Sample Detectors.pdf},
  keywords = {Computer Science - Computer Vision and Pattern Recognition,Computer Science - Machine Learning,Statistics - Machine Learning},
  langid = {english},
  primaryclass = {cs, stat}
}

@article{shaoFeature2013,
  title = {Feature Selection for Manufacturing Process Monitoring Using Cross-Validation},
  author = {Shao, Chenhui and Paynabar, Kamran and Kim, Tae Hyung and Jin, Jionghua and Hu, S. Jack and Spicer, J. Patrick and Wang, Hui and Abell, Jeffrey A.},
  date = {2013-10},
  journaltitle = {Journal of Manufacturing Systems},
  shortjournal = {Journal of Manufacturing Systems},
  volume = {32},
  pages = {550--555},
  issn = {02786125},
  doi = {10.1016/j.jmsy.2013.05.006},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S027861251300071X},
  urldate = {2020-07-07},
  abstract = {A novel algorithm is developed for feature selection and parameter tuning in quality monitoring of manufacturing processes using cross-validation. Due to the recent development in sensing technology, many on-line signals are collected for manufacturing process monitoring and feature extraction is then performed to extract critical features related to product/process quality. However, lack of precise process knowledge may result in many irrelevant or redundant features. Therefore, a systematic procedure is needed to select a parsimonious set of features which provide sufficient information for process monitoring. In this study, a new method for selecting features and tuning SPC limits is proposed by applying k-fold cross-validation to simultaneously select important features and set the monitoring limits using Type I and Type II errors obtained from cross-validation. The monitoring performance for production data collected from ultrasonic metal welding of batteries demonstrates that the proposed algorithm is able to select the most efficient features and control limits and thus leading to satisfactory monitoring performance.},
  file = {/Users/hyan46/Dropbox (ASU)/ZoteroData/Shao et al_2013_Feature selection for manufacturing process monitoring using cross-validation.pdf},
  langid = {english},
  number = {4}
}

@article{shaoImproving2017,
  title = {Improving {{Machined Surface Shape Prediction}} by {{Integrating Multi}}-{{Task Learning With Cutting Force Variation Modeling}}},
  author = {Shao, Chenhui and Ren, Jie and Wang, Hui and Jin, Jionghua and Hu, S. Jack},
  date = {2017-01-01},
  journaltitle = {Journal of Manufacturing Science and Engineering},
  volume = {139},
  pages = {011014},
  issn = {1087-1357, 1528-8935},
  doi = {10.1115/1.4034592},
  url = {https://asmedigitalcollection.asme.org/manufacturingscience/article/doi/10.1115/1.4034592/472250/Improving-Machined-Surface-Shape-Prediction-by},
  urldate = {2020-07-04},
  abstract = {The shapes of machined surfaces play a critical role affecting powertrain performance, and therefore, it is necessary to characterize the shapes with high resolution. State-of-the-art approaches for surface shape characterization are mostly data-driven by interpolating and extrapolating the spatial data but its precision is limited by the density of measurements. This paper explores the new opportunity of improving surface shape prediction through considering the similarity of multiple similar manufacturing processes. It is a common scenario when the process of interest lacks sufficient data whereas rich data could be available from other similar-but-not-identical processes. It is reasonable to transfer the insights gained from other relevant processes into the surface shape prediction. This paper develops an engineering-guided multitask learning (EG-MTL) surface model by fusing surface cutting physics in engineering processes and the spatial data from a number of similar-but-not-identical processes. An iterative multitask Gaussian process learning algorithm is developed to learn the model parameters. Compared with the conventional multitask learning, the proposed method has the advantages in incorporating the insights on cutting force variation during machining and is potentially able to improve the prediction performance given limited measurement data. The methodology is demonstrated based on the data from real-world machining processes in an engine plant.},
  file = {/Users/hyan46/Dropbox (ASU)/ZoteroData/Shao et al_2017_Improving Machined Surface Shape Prediction by Integrating Multi-Task Learning2.pdf},
  keywords = {Application: Manufacturing,Application: Surface Scanning,Method: Transfer Learning,People: Judy Jin},
  langid = {english},
  number = {1}
}

@online{sharmaWhy2019,
  title = {Why {{Machine Learning Is Important For Smarter Manufacturing}}},
  author = {Sharma, Ashok},
  date = {2019-10-21T13:34:30},
  url = {https://towardsdatascience.com/why-machine-learning-is-important-for-smarter-manufacturing-27da545de779},
  urldate = {2020-05-23},
  abstract = {Manufacturing products can be very expensive and a complex process for those businesses that do not have the right tools and resources to…},
  file = {/Users/hyan46/Dropbox (ASU)/ZoteroData/Sharma_2019_Why Machine Learning Is Important For Smarter Manufacturing.pdf},
  keywords = {Application: Manufacturing},
  langid = {english},
  organization = {{Medium}}
}

@article{shinCovariate2018,
  title = {Covariate Matching Methods for Testing and Quantifying Wind Turbine Upgrades},
  author = {Shin, Yei Eun and Ding, Yu and Huang, Jianhua Z.},
  date = {2018-06},
  journaltitle = {The Annals of Applied Statistics},
  shortjournal = {Ann. Appl. Stat.},
  volume = {12},
  pages = {1271--1292},
  issn = {1932-6157},
  doi = {10.1214/17-AOAS1109},
  url = {https://projecteuclid.org/euclid.aoas/1532743494},
  urldate = {2020-07-04},
  file = {/Users/hyan46/Dropbox (ASU)/ZoteroData/Shin et al_2018_Covariate matching methods for testing and quantifying wind turbine upgrades.pdf},
  keywords = {Application: Wind Turbine,People: Yu Ding},
  langid = {english},
  number = {2}
}

@article{shiryaevOptimum1963,
  title = {On {{Optimum Methods}} in {{Quickest Detection Problems}}},
  author = {Shiryaev, A. N.},
  date = {1963-01-01},
  journaltitle = {Theory of Probability \& Its Applications},
  shortjournal = {Theory Probab. Appl.},
  volume = {8},
  pages = {22--46},
  publisher = {{Society for Industrial and Applied Mathematics}},
  issn = {0040-585X},
  doi = {10.1137/1108002},
  url = {https://epubs.siam.org/doi/abs/10.1137/1108002},
  urldate = {2020-08-13},
  abstract = {In this paper optimum methods are developed for observing a process (1), in which the moment when a “disorder” \$\textbackslash theta\$ appears is not known. The basic quantity characterizing the quality of this observation method is the mean time delay \$\{\textbackslash boldsymbol \textbackslash tau\}\$ for detection of a disorder.After making assumption (4) it is shown that for a given false alarm probability \$\textbackslash omega\$ or for a given \$\{\textbackslash bf N\}\$ — mathematical expectation of false alarm numbers occurring up to the moment the disorder appears — the observation method minimizing \$\{\textbackslash boldsymbol \textbackslash tau \} = \{\textbackslash boldsymbol \textbackslash tau \} (\textbackslash omega)\$ or \$\{\textbackslash boldsymbol \textbackslash tau\} = \{\textbackslash boldsymbol \textbackslash tau\} (\{\textbackslash boldsymbol N\})\$ is based on an observation of a posteriors probability (23).In § 3 a case is considered, wherein, the disorder appears on the background of steadystate conditions arising when the disorder is absent. A method is found for minimizing \$\{\textbackslash boldsymbol \textbackslash tau\} = \{\textbackslash boldsymbol \textbackslash tau\} (\{\textbackslash bf T\})\$ for a set \$\{\textbackslash bf T\}\$ — mathematical expectation of the time between two false alarms. The dependence \$\{\textbackslash boldsymbol \textbackslash tau\} = \{\textbackslash boldsymbol \textbackslash tau\} (\{\textbackslash bf T\})\$ is given by formula (36).},
  file = {/Users/hyan46/Zotero/storage/QSUW4VNA/1108002.html},
  number = {1}
}

@article{siMultiresponse2017,
  ids = {simultiresponse2017a},
  title = {A Multi-Response Multilevel Model with Application in Nurse Care Coordination},
  author = {Si, Bing and Lamb, Gerri and Schmitt, Madeline H. and Li, Jing},
  date = {2017-07-03},
  journaltitle = {IISE Transactions},
  shortjournal = {IISE Transactions},
  volume = {49},
  pages = {669--681},
  issn = {2472-5854, 2472-5862},
  doi = {10.1080/24725854.2016.1263770},
  url = {https://www.tandfonline.com/doi/full/10.1080/24725854.2016.1263770},
  urldate = {2020-07-04},
  abstract = {Due to the aging of our society, patient care needs to be well coordinated within the health care team in order to effectively manage the overall health of each patient. Staff nurses, as the patient’s “ever-present” health care team members, play a vital role in the care coordination. The recently developed Nurse Care Coordination Instrument (NCCI) is the first of its kind that enables quantitative data to be collected to measure various aspects of nurse care coordination. Driven by this new development, we propose a multiresponse multilevel model with joint fixed effect selection and joint random effect selection across multiple responses. This model is particularly suitable for modeling the unique data structure of the NCCI due to its ability of jointly modeling of multilevel predictors, including demographic and workload variables at the individual/nurse level and characteristics of the practice environment at the unit level and multiple response variables that measure the key components of nurse care coordination. We develop a Block Coordinate Descent algorithm integrated with an Expectation-Maximization framework for model estimation. Asymptotic properties are derived. Finally, we present an application to a data set collected across four U.S. hospitals using the NCCI and discuss implications of the findings.},
  file = {/Users/hyan46/Dropbox (ASU)/ZoteroData/Si et al_2017_A multi-response multilevel model with application in nurse care coordination.pdf},
  keywords = {Application: Health,People: Jing Li},
  langid = {english},
  number = {7}
}

@article{Sinha:B1uqJRPr,
  title = {Object Shape Error Response Using Bayesian {{3D}} Convolutional Neural Networks for Assembly Systems with Compliant Parts},
  author = {Sinha, Sumit and Franciosa, Pasquale and Ceglarek, Dariusz},
  date = {2020},
  journaltitle = {IEEE Transaction on Industrial Informatics},
  date-added = {2020-07-03T22:25:38GMT},
  date-modified = {2020-07-04T00:26:51GMT},
  file = {/Users/hyan46/Dropbox (ASU)/ZoteroData/Sinha et al_2020_Object shape error response using bayesian 3D convolutional neural networks for.pdf},
  keywords = {Application: Assembly,Application: Manufacturing,Data: Point Cloud,Method: Deep Learning,People: Cerek},
  rating = {0},
  uri = {papers3://publication/uuid/075BAA25-13EB-479D-B565-CE9C40B0BB3F}
}

@article{siReliability2018,
  title = {Reliability {{Analysis}} of {{Repairable Systems With Incomplete Failure Time Data}}},
  author = {Si, Wujun and Yang, Qingyu and Monplaisir, Leslie and Chen, Yong},
  date = {2018-09},
  journaltitle = {IEEE Transactions on Reliability},
  shortjournal = {IEEE Trans. Rel.},
  volume = {67},
  pages = {1043--1059},
  issn = {0018-9529, 1558-1721},
  doi = {10.1109/TR.2018.2832022},
  url = {https://ieeexplore.ieee.org/document/8390709/},
  urldate = {2020-07-04},
  abstract = {Reliability analysis of repairable systems has been widely conducted based on collected information such as the systems’ failure counting processes. In many real-life situations, the failure counting processes may not be completely observed when some failure times are not recorded or missing due to various practical reasons. In the literature, only a limited number of reliability studies focus on missing failure time data for repairable systems with an assumption that the system repair is either perfect or minimal. When the repair effect is general as in many real-world situations, challenges arise for reliability analysis in that the observed and unobserved failure times are statistically dependent in a complex manner, and the time censoring problem becomes unconventional. In this paper, to overcome these challenges, we propose a reliability model for repairable systems with incomplete failure time data under general repair. The proposed model is suitable for modeling both a single system and multiple systems subject to failure heterogeneity. A maximum likelihood estimation method is developed to estimate the model parameters. Based on the proposed model, statistical inference of the missing times is developed. Simulation and real-life case studies are conducted to verify the developed methods.},
  file = {/Users/hyan46/Dropbox (ASU)/ZoteroData/Si et al_2018_Reliability Analysis of Repairable Systems With Incomplete Failure Time Data.pdf},
  keywords = {People: Chen Yong,Problem: Reliability},
  langid = {english},
  number = {3}
}

@inproceedings{snoekPractical2012,
  title = {Practical {{Bayesian}} Optimization of Machine Learning Algorithms},
  booktitle = {Advances in {{Neural Information Processing Systems}}},
  author = {Snoek, Jasper and Larochelle, Hugo and Adams, Ryan P.},
  date = {2012},
  issn = {10495258},
  abstract = {The use of machine learning algorithms frequently involves careful tuning of learning parameters and model hyperparameters. Unfortunately, this tuning is often a "black art" requiring expert experience, rules of thumb, or sometimes bruteforce search. There is therefore great appeal for automatic approaches that can optimize the performance of any given learning algorithm to the problem at hand. In this work, we consider this problem through the framework of Bayesian optimization, in which a learning algorithm's generalization performance is modeled as a sample from a Gaussian process (GP). We show that certain choices for the nature of the GP, such as the type of kernel and the treatment of its hyperparameters, can play a crucial role in obtaining a good optimizer that can achieve expertlevel performance. We describe new algorithms that take into account the variable cost (duration) of learning algorithm experiments and that can leverage the presence of multiple cores for parallel experimentation. We show that these proposed algorithms improve on previous automatic procedures and can reach or surpass human expert-level optimization for many algorithms including latent Dirichlet allocation, structured SVMs and convolutional neural networks.},
  annotation = {\_eprint: 1206.2944},
  file = {/Users/hyan46/Dropbox (ASU)/ZoteroData/Snoek et al_2012_Practical Bayesian optimization of machine learning algorithms.pdf},
  isbn = {978-1-62748-003-1},
  keywords = {Bayesian Optimization,Method: Bayesian,Method: Functional}
}

@article{sohnAutomated2011,
  title = {Automated Detection of Delamination and Disbond from Wavefield Images Obtained Using a Scanning Laser Vibrometer},
  author = {Sohn, H and Dutta, D and Yang, J Y and DeSimio, M and Olson, S and Swenson, E},
  date = {2011-04-01},
  journaltitle = {Smart Materials and Structures},
  shortjournal = {Smart Mater. Struct.},
  volume = {20},
  pages = {045017},
  issn = {0964-1726, 1361-665X},
  doi = {10.1088/0964-1726/20/4/045017},
  url = {https://iopscience.iop.org/article/10.1088/0964-1726/20/4/045017},
  urldate = {2020-07-15},
  file = {/Users/hyan46/Dropbox (ASU)/ZoteroData/Sohn et al_2011_Automated detection of delamination and disbond from wavefield images obtained.pdf},
  langid = {english},
  number = {4}
}

@article{Sokolov:2020bf,
  title = {Keyhole Mapping to Enable Closed-Loop Weld Penetration Depth Control for Remote Laser Welding of Aluminum Components Using Optical Coherence Tomography},
  author = {Sokolov, Mikhail and Franciosa, Pasquale and Al Botros, Rehab and Ceglarek, Dariusz},
  date = {2020-08},
  journaltitle = {Journal of Laser Applications},
  volume = {32},
  pages = {032004},
  publisher = {{Laser Institute of AmericaLIA}},
  doi = {10.2351/7.0000086},
  url = {http://lia.scitation.org/doi/10.2351/7.0000086},
  abstract = {Remote laser welding (RLW) combines the positive features of tactile laser welding with additional benefits such as increased processing speed, reduced operational cost and service, and higher process flexibility. A leading challenge preventing the full uptake of RLW technology in industry is the lack of efficient closed loop in-process (CLIP) monitoring and weld quality control solutions. This underpins the need to fuse multiple sensor technologies and data analytics with predictive engineering simulations. Although the development and integration of a variety of sensors covers the radiation spectrum from ultraviolet to far-infrared, the flawless deployment of CLIP solutions is still challenged by the need for the following: signal denoising in the case of process instability; real-time data analytics; and adaptive control engineering architecture to cope with process variations induced by manufacturing tolerances. This paper focuses on the aspect of weld penetration depth control using optical coherence tomography (OCT) as a necessary step to enable adaptive penetration depth control during RLW of aluminum components in the fillet lap joint configuration with consideration to part-to-part gap variation. The approach entails decoupling the welding process parameters in two subsets: (1) in-plane control of the heat input on the upper part to facilitate the droplet formation; and (2) out-of-plane heat management to achieve the desired level of penetration control in the keyhole mode. This paper presents the results of finding the optimal placement of the OCT beam with variable part-to-part gap conditions. Results have shown that statistical signal processing of the raw OCT signal gives insight not only into the depth of the keyhole but can infer the shape of the keyhole itself. Current limitations and next phases of research and development are highlighted based on the experimental study.},
  date-added = {2020-07-03T22:24:16GMT},
  date-modified = {2020-07-04T00:26:51GMT},
  keywords = {Application: Assembly,Application: Manufacturing,Method: State Space,People: Cerek,Problem: Control,Problem: Process Monitoring},
  langid = {english},
  local-url = {file://localhost/Users/hyan46/Dropbox\%20(ASU)/PapersSync/Files/7D/7D251DD1-F911-4DAE-8314-90C170D111F3.pdf},
  number = {3},
  rating = {0},
  uri = {papers3://publication/doi/10.2351/7.0000086}
}

@inproceedings{song2020generalized,
  title = {Generalized Zero-Shot Text Classification for {{ICD}} Coding},
  booktitle = {{{IJCAI}}},
  author = {Song, Congzheng and Zhang, Shanghang and Sadoughi, Najmeh and Xie, Pengtao and Xing, Eric P},
  date = {2020},
  file = {/Users/hyan46/Dropbox (ASU)/ZoteroData/Song et al_2020_Generalized zero-shot text classification for ICD coding.pdf}
}

@article{songBuilding,
  title = {Building {{Local Models}} for {{Flexible Degradation Modeling}} and {{Prognostics}}},
  author = {Song, Changyue and Zheng, Ziqian and Liu, Kaibo},
  pages = {12},
  abstract = {To avoid unexpected failures of engineering systems, sensors have been widely used to monitor the degradation process of the systems. A number of studies have been conducted to analyze the collected sensor signals and predict the failure time. However, the existing studies are usually restricted and cannot be adapted to different practical situations. In this paper, we propose a systematic method for degradation modeling and prognosis that can be widely applied in different scenarios. In particular, the proposed method is capable to handle one or multiple sensors, powerful to capture the nonlinear relations between sensor signals and the degradation process with few assumptions, generic to consider multiple failure modes, flexible to deal with unequally spaced sensor measurements or asynchronous signals, and easily understandable with little preprocessing required. The main idea is to predict the failure time of an in-service unit based on a subset of the nearest historical units, where features are extracted from each sensor to describe the progression of sensor signals and local linear regression models are constructed to establish the relation between failure time and the extracted features. The prediction variance is then used as the goodness-of-fit measure, based on which decision-level fusion and feature-level fusion are proposed to combine multiple sensors. A case study with two datasets on the degradation modeling of aircraft engines is conducted which shows satisfactory performance of the proposed method.},
  file = {/Users/hyan46/Zotero/storage/SKZNCQRK/Song et al. - Building Local Models for Flexible Degradation Mod.pdf},
  langid = {english}
}

@article{songGeneric2019,
  title = {A Generic Framework for Multisensor Degradation Modeling Based on Supervised Classification and Failure Surface},
  author = {Song, Changyue and Liu, Kaibo and Zhang, Xi},
  date = {2019-11-02},
  journaltitle = {IISE Transactions},
  shortjournal = {IISE Transactions},
  volume = {51},
  pages = {1288--1302},
  issn = {2472-5854, 2472-5862},
  doi = {10.1080/24725854.2018.1555384},
  url = {https://www.tandfonline.com/doi/full/10.1080/24725854.2018.1555384},
  urldate = {2020-07-04},
  abstract = {In condition monitoring, multiple sensors are widely used to simultaneously collect measurements from the same unit to estimate the degradation status and predict the remaining useful life. In this article, we propose a generic framework for multisensor degradation modeling, which can be viewed as an extension of the degradation models from one-dimensional space to multi-dimensional space. Specifically, we model each sensor signal based on random-effect models and characterize failure events by a multi-dimensional failure surface, which is an extension of the conventional definition of the failure threshold for a single sensor signal. To overcome the challenges in estimating the failure surface, we transform the degradation modeling problem into a supervised classification problem, where a variety of classifiers can be incorporated to estimate the degradation status of the unit based on the underlying signal paths, i.e., the collected sensor signals after removing the noise. As a result, the proposed method gains great flexibility. It can also be used for sensor selection, can handle asynchronous sensor signals, and is easy to implement in practice. Simulation studies and a case study on the degradation of aircraft engines are conducted to evaluate the performance of the proposed framework in parameter estimation and prognosis.},
  file = {/Users/hyan46/Dropbox (ASU)/ZoteroData/Song et al_2019_A generic framework for multisensor degradation modeling based on supervised.pdf},
  keywords = {Application: Engine,Data: Profiles,Method: Health Index,People: Kaibo Liu,Problem: Prognostics},
  langid = {english},
  number = {11}
}

@article{songIntegration2018,
  title = {Integration of {{Data}}-{{Level Fusion Model}} and {{Kernel Methods}} for {{Degradation Modeling}} and {{Prognostic Analysis}}},
  author = {Song, Changyue and Liu, Kaibo and Zhang, Xi},
  date = {2018-06},
  journaltitle = {IEEE Transactions on Reliability},
  shortjournal = {IEEE Trans. Rel.},
  volume = {67},
  pages = {640--650},
  issn = {0018-9529, 1558-1721},
  doi = {10.1109/TR.2017.2715180},
  url = {https://ieeexplore.ieee.org/document/7974789/},
  urldate = {2020-07-04},
  abstract = {To prevent unexpected failures of complex engineering systems, multiple sensors have been widely used to simultaneously monitor the degradation process and make inference about the remaining useful life in real time. As each of the sensor signals often contains partial and dependent information, data-level fusion techniques have been developed that aim to construct a health index via the combination of multiple sensor signals. While the existing data-level fusion approaches have shown a promise for degradation modeling and prognostics, they are limited by only considering a linear fusion function. Such a linear assumption is usually insufficient to accurately characterize the complicated relations between multiple sensor signals and the underlying degradation process in practice, especially for complex engineering systems considered in this study. To address this issue, this study fills the literature gap by integrating kernel methods into the data-level fusion approaches to construct a health index for better characterizing the degradation process of the system. Through selecting a proper kernel function, the nonlinear relation between multiple sensor signals and the underlying degradation process can be captured. As a result, the constructed health index is expected to perform better in prognosis than existing data-level fusion methods that are based on the linear assumption. In fact, the existing data-level fusion models turn out to be only a special case of the proposed method. A case study based on the degradation signals of aircraft gas turbine engines is conducted and finally shows the developed health index by using the proposed method is insensitive for missing data and leads to an improved prognostic performance.},
  file = {/Users/hyan46/Dropbox (ASU)/ZoteroData/Song et al_2018_Integration of Data-Level Fusion Model and Kernel Methods for Degradation.pdf},
  keywords = {Application: Engine,Data: Profiles,Method: Health Index,People: Kaibo Liu,Problem: Prognostics},
  langid = {english},
  number = {2}
}

@article{songObstructive2016,
  title = {An {{Obstructive Sleep Apnea Detection Approach Using}} a {{Discriminative Hidden Markov Model From ECG Signals}}},
  author = {Song, Changyue and Liu, Kaibo and Zhang, Xi and Chen, Lili and Xian, Xiaochen},
  date = {2016-07},
  journaltitle = {IEEE Transactions on Biomedical Engineering},
  shortjournal = {IEEE Trans. Biomed. Eng.},
  volume = {63},
  pages = {1532--1542},
  issn = {0018-9294, 1558-2531},
  doi = {10.1109/TBME.2015.2498199},
  url = {http://ieeexplore.ieee.org/document/7320974/},
  urldate = {2020-07-04},
  abstract = {Obstructive sleep apnea (OSA) syndrome is a common sleep disorder suffered by an increasing number of people worldwide. As an alternative to polysomnography (PSG) for OSA diagnosis, the automatic OSA detection methods used in the current practice mainly concentrate on feature extraction and classifier selection based on collected physiological signals. However, one common limitation in these methods is that the temporal dependence of signals are usually ignored, which may result in critical information loss for OSA diagnosis. In this study, we propose a novel OSA detection approach based on ECG signals by considering temporal dependence within segmented signals. A discriminative hidden Markov model (HMM) and corresponding parameter estimation algorithms are provided. In addition, subject-specific transition probabilities within the model are employed to characterize the subject-to-subject differences of potential OSA patients. To validate our approach, 70 recordings obtained from the Physionet Apnea-ECG database were used. Accuracies of 97.1\% for per-recording classification and 86.2\% for per-segment OSA detection with satisfactory sensitivity and specificity were achieved. Compared with other existing methods that simply ignore the temporal dependence of signals, the proposed HMM-based detection approach delivers more satisfactory detection performance and could be extended to other disease diagnosis applications.},
  file = {/Users/hyan46/Dropbox (ASU)/ZoteroData/Song et al_2016_An Obstructive Sleep Apnea Detection Approach Using a Discriminative Hidden.pdf},
  keywords = {Application: Health,People: Kaibo Liu,Problem: Process Monitoring},
  langid = {english},
  number = {7}
}

@article{songStatistical2018,
  title = {Statistical Degradation Modeling and Prognostics of Multiple Sensor Signals via Data Fusion: {{A}} Composite Health Index Approach},
  shorttitle = {Statistical Degradation Modeling and Prognostics of Multiple Sensor Signals via Data Fusion},
  author = {Song, Changyue and Liu, Kaibo},
  date = {2018-10-03},
  journaltitle = {IISE Transactions},
  shortjournal = {IISE Transactions},
  volume = {50},
  pages = {853--867},
  issn = {2472-5854, 2472-5862},
  doi = {10.1080/24725854.2018.1440673},
  url = {https://www.tandfonline.com/doi/full/10.1080/24725854.2018.1440673},
  urldate = {2020-07-04},
  abstract = {Nowadays multiple sensors are widely used to simultaneously monitor the degradation status of a unit. Because those sensor signals are often correlated and measure different characteristics of the same unit, effective fusion of such a diverse “gene pool” is an important step to better understanding the degradation process and producing a more accurate prediction of the remaining useful life. To address this issue, this article proposes a novel data fusion method that constructs a composite Health Index (HI) via the combination of multiple sensor signals for better characterizing the degradation process. In particular, we formulate the problem as indirect supervised learning and leverage the quantile regression to derive the optimal fusion coefficient. In this way, the prognostic performance of the proposed method is guaranteed. To the best of our knowledge, this is the first article that provides the theoretical analysis of the data fusion method for degradation modeling and prognostics. Simulation studies are conducted to evaluate the proposed method in different scenarios. A case study on the degradation of aircraft engines is also performed, which shows the superior performance of our method over existing HI-based methods.},
  file = {/Users/hyan46/Dropbox (ASU)/ZoteroData/Song_Liu_2018_Statistical degradation modeling and prognostics of multiple sensor signals via.pdf},
  keywords = {Application: Engine,Data: Profiles,Method: Health Index,People: Kaibo Liu,Problem: Prognostics},
  langid = {english},
  number = {10}
}

@online{sorokinDeep2015,
  title = {Deep {{Attention Recurrent Q}}-{{Network}}},
  author = {Sorokin, Ivan and Seleznev, Alexey and Pavlov, Mikhail and Fedorov, Aleksandr and Ignateva, Anastasiia},
  date = {2015-12-05},
  url = {http://arxiv.org/abs/1512.01693},
  urldate = {2020-05-27},
  abstract = {A deep learning approach to reinforcement learning led to a general learner able to train on visual input to play a variety of arcade games at the human and superhuman levels. Its creators at the Google DeepMind's team called the approach: Deep Q-Network (DQN). We present an extension of DQN by "soft" and "hard" attention mechanisms. Tests of the proposed Deep Attention Recurrent Q-Network (DARQN) algorithm on multiple Atari 2600 games show level of performance superior to that of DQN. Moreover, built-in attention mechanisms allow a direct online monitoring of the training process by highlighting the regions of the game screen the agent is focusing on when making decisions.},
  archiveprefix = {arXiv},
  eprint = {1512.01693},
  eprinttype = {arxiv},
  file = {/Users/hyan46/Dropbox (ASU)/ZoteroData/Sorokin et al_2015_Deep Attention Recurrent Q-Network3.pdf;/Users/hyan46/Zotero/storage/4VBAAN3A/1512.html},
  keywords = {Computer Science - Machine Learning,Problem: Process Monitoring},
  primaryclass = {cs}
}

@article{sosinaStochastic2016,
  title = {A Stochastic Graphene Growth Kinetics Model},
  author = {Sosina, Sobambo and Dasgupta, Tirthankar and Huang, Qiang},
  date = {2016-11},
  journaltitle = {Journal of the Royal Statistical Society: Series C (Applied Statistics)},
  shortjournal = {J. R. Stat. Soc. C},
  volume = {65},
  pages = {705--729},
  issn = {00359254},
  doi = {10.1111/rssc.12149},
  url = {http://doi.wiley.com/10.1111/rssc.12149},
  urldate = {2020-07-04},
  abstract = {Graphene is an emerging nanomaterial for a wide variety of novel applications. Controlled synthesis of high quality graphene sheets requires analytical understanding of graphene growth kinetics. Graphene growth via chemical vapour deposition starts with randomly nucleated islands that gradually develop into complex shapes, grow in size and eventually connect together to form a graphene sheet. Models proposed for this stochastic process do not, in general, permit assessment of uncertainty. We develop a stochastic framework for the growth process and propose Bayesian inferential models, which account for the data collection mechanism and allow for uncertainty analyses, for learning about the kinetics from experimental data. Furthermore, we link the growth kinetics with controllable experimental factors, thus providing a framework for statistical design and analysis of future experiments.},
  file = {/Users/hyan46/Dropbox (ASU)/ZoteroData/Sosina et al_2016_A stochastic graphene growth kinetics model.pdf},
  keywords = {Application: Manufacturing,Application: Nano,People: Qiang Huang},
  langid = {english},
  number = {5}
}

@article{SpatioTemporal,
  title = {Spatio-{{Temporal Process Monitoring Using Exponentially Weighted Spatial LASSO}}},
  journaltitle = {Technometrics},
  file = {/Users/hyan46/Dropbox (ASU)/ZoteroData/Spatio-Temporal Process Monitoring Using Exponentially Weighted Spatial LASSO.pdf}
}

@article{stenzelPredictive,
  title = {Predictive {{Maintenance}} in {{Photovoltaic Plants}} with a {{Big Data Approach}}},
  author = {Stenzel, Anna},
  pages = {6},
  abstract = {This paper presents a novel and flexible solution for fault prediction based on data collected from SCADA system. Fault prediction is offered at two different levels based on a data-driven approach: (a) generic fault/status prediction and (b) specific fault class prediction, implemented by means of two different machine learning based modules built on an unsupervised clustering algorithm and a Pattern Recognition Neural Network, respectively. Model has been assessed on a park of six photovoltaic (PV) plants up to 10 MW and on more than one hundred inverter modules of three different technology brands. The results indicate that the proposed method is effective in (a) predicting incipient generic faults up to 7 days in advance with sensitivity up to 95\% and (b) anticipating damage of specific fault classes with times ranging from few hours up to 7 days. The model is easily deployable for on-line monitoring of anomalies on new PV plants and technologies, requiring only the availability of historical SCADA and fault data, fault taxonomy and inverter electrical datasheet.},
  file = {/Users/hyan46/Dropbox (ASU)/ZoteroData/Stenzel_Predictive Maintenance in Photovoltaic Plants with a Big Data Approach.pdf},
  langid = {english}
}

@article{suGuided2006,
  title = {Guided {{Lamb}} Waves for Identification of Damage in Composite Structures: {{A}} Review},
  shorttitle = {Guided {{Lamb}} Waves for Identification of Damage in Composite Structures},
  author = {Su, Zhongqing and Ye, Lin and Lu, Ye},
  date = {2006-08},
  journaltitle = {Journal of Sound and Vibration},
  shortjournal = {Journal of Sound and Vibration},
  volume = {295},
  pages = {753--780},
  issn = {0022460X},
  doi = {10.1016/j.jsv.2006.01.020},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0022460X0600109X},
  urldate = {2020-07-15},
  abstract = {The guided Lamb wave is widely acknowledged as one of the most encouraging tools for quantitative identification of damage in composite structures, and relevant research has been conducted intensively since the 1980s. The main aim of this paper is to provide a comprehensive review on the state of the art of Lamb wave-based damage identification approaches for composite structures, addressing the advances and achievements in these techniques in the past decades. Major emphasis is placed on the unique characteristics and mechanisms of Lamb waves in laminated composites; approaches in wave mode selection, generation and collection; modelling and numerical simulation techniques; signal processing and identification algorithms; and sensor network technology for practical utility. Representative case studies are also briefly described in terms of various experimental validations and applications.},
  file = {/Users/hyan46/Dropbox (ASU)/ZoteroData/Su et al_2006_Guided Lamb waves for identification of damage in composite structures.pdf},
  langid = {english},
  number = {3-5}
}

@article{sukchotratOneclass2009,
  title = {One-Class Classification-Based Control Charts for Multivariate Process Monitoring},
  author = {Sukchotrat, Thuntee and Kim, Seoung Bum and Tsung, Fugee},
  date = {2009-11-30},
  journaltitle = {IIE Transactions},
  volume = {42},
  pages = {107--120},
  publisher = {{Taylor \& Francis}},
  issn = {0740-817X},
  doi = {10.1080/07408170903019150},
  url = {https://doi.org/10.1080/07408170903019150},
  urldate = {2020-05-25},
  abstract = {One-class classification problems have attracted a great deal of attention from various disciplines. In the present study, attempts are made to extend the scope of application of the one-class classification technique to Statistical Process Control (SPC) problems. New multivariate control charts that apply the effectiveness of one-class classification to improvement of Phase I and Phase II analysis in SPC are proposed. These charts use a monitoring statistic to represent the degree of being an outlier as obtained through one-class classification. The control limits of the proposed charts are established based on the empirical level of significance on the percentile, estimated by the bootstrap method. A simulation study is conducted to illustrate the limitations of current one-class classification control charts and demonstrate the effectiveness of the proposed control charts.},
  annotation = {\_eprint: https://doi.org/10.1080/07408170903019150},
  file = {/Users/hyan46/Zotero/storage/2C8PRFL5/07408170903019150.html},
  keywords = {Data mining,Hotelling's T 2,Method: Classification,multivariate process,one-class classification method,Problem: Classification,Problem: Process Monitoring,statistical process control},
  number = {2}
}

@article{sunUnderstanding2016,
  title = {Understanding Urban Mobility Patterns with a Probabilistic Tensor Factorization Framework},
  author = {Sun, Lijun and Axhausen, Kay W.},
  date = {2016-09-01},
  journaltitle = {Transportation Research Part B: Methodological},
  shortjournal = {Transportation Research Part B: Methodological},
  volume = {91},
  pages = {511--524},
  issn = {0191-2615},
  doi = {10.1016/j.trb.2016.06.011},
  url = {http://www.sciencedirect.com/science/article/pii/S0191261516300261},
  urldate = {2020-05-31},
  abstract = {The rapid developments of ubiquitous mobile computing provide planners and researchers with new opportunities to understand and build smart cities by mining the massive spatial-temporal mobility data. However, given the increasing complexity and volume of the emerging mobility datasets, it also becomes challenging to build novel analytical framework that is capable of understanding the structural properties and critical features. In this paper, we introduce an analytical framework to deal with high-dimensional human mobility data. To this end, we formulate mobility data in a probabilistic setting and consider each record a multivariate observation sampled from an underlying distribution. In order to characterize this distribution, we use a multi-way probabilistic factorization model based on the concept of tensor decomposition and probabilistic latent semantic analysis (PLSA). The model provides us with a flexible approach to understand multi-way mobility involving higher-order interactions—which are difficult to characterize with conventional approaches—using simple latent structures. The model can be efficiently estimated using the expectation maximization (EM) algorithm. As a numerical example, this model is applied on a four-way dataset recording 14 million public transport journeys extracted from smart card transactions in Singapore. This framework can shed light on the modeling of urban structure by understanding mobility flows in both spatial and temporal dimensions.},
  file = {/Users/hyan46/Dropbox (ASU)/ZoteroData/Sun_Axhausen_2016_Understanding urban mobility patterns with a probabilistic tensor factorization2.pdf},
  keywords = {Data-driven,Human mobility,Method: Tensor,Smart card data,Tensor decomposition,Urban computing},
  langid = {english}
}

@book{suttonReinforcement1998,
  title = {Reinforcement Learning: An Introduction},
  shorttitle = {Reinforcement Learning},
  author = {Sutton, Richard S. and Barto, Andrew G.},
  date = {1998},
  publisher = {{MIT Press}},
  location = {{Cambridge, Mass}},
  file = {/Users/hyan46/Dropbox (ASU)/ZoteroData/Sutton_Barto_1998_Reinforcement learning.pdf},
  isbn = {978-0-262-19398-6},
  keywords = {Reinforcement learning},
  langid = {english},
  pagetotal = {322},
  series = {Adaptive Computation and Machine Learning}
}

@unpublished{tartakovskyQuickest2014,
  title = {Quickest {{Changepoint Detection}}:   {{Optimality Properties}} of the {{Shiryaev}}–{{Roberts}}-{{Type Procedures}}},
  author = {Tartakovsky, Alexander},
  date = {2014-01-17},
  url = {https://www.newton.ac.uk/files/seminar/20140117101511001-153921.pdf#page30},
  urldate = {2020-07-16},
  file = {/Users/hyan46/Dropbox (ASU)/ZoteroData/Tartakovsky_2014_Quickest Changepoint Detection.pdf},
  langid = {english},
  venue = {{Cambridge, UK}}
}

@unpublished{tartakovskySequential2012,
  title = {Sequential {{Hypothesis Testing}} and {{Changepoint Detection}}:   {{State}} of the {{Art}} and {{Challenges}}},
  author = {Tartakovsky, Alexander},
  date = {2012-06-04},
  eventtitle = {International {{Workshop}} on {{Sequential Methods}} and {{Their Applications}}},
  file = {/Users/hyan46/Dropbox (ASU)/ZoteroData/Tartakovsky_2012_Sequential Hypothesis Testing and Changepoint Detection.pdf},
  langid = {english},
  venue = {{University of Rouen, France}}
}

@book{tartakovskySequential2014,
  title = {Sequential Analysis: Hypothesis Testing and Changepoint Detection},
  shorttitle = {Sequential Analysis},
  author = {Tartakovsky, Alexander and Nikiforov, Igor and Michele, Basseville},
  date = {2014},
  publisher = {{CRC Press}},
  url = {http://www.tandfonline.com/doi/full/10.1080/02664763.2015.1015813},
  urldate = {2020-07-11},
  file = {/Users/hyan46/Dropbox (ASU)/ZoteroData/Tartakovsky et al_2014_Sequential analysis.pdf},
  langid = {english}
}

@article{tongSupport,
  title = {Support {{Vector Machine Active Learning}} with {{Applications}} to {{Text Classiﬁcation}}},
  author = {Tong, Simon and Koller, Daphne},
  pages = {22},
  abstract = {Support vector machines have met with significant success in numerous real-world learning tasks. However, like most machine learning algorithms, they are generally applied using a randomly selected training set classified in advance. In many settings, we also have the option of using pool-based active learning. Instead of using a randomly selected training set, the learner has access to a pool of unlabeled instances and can request the labels for some number of them. We introduce a new algorithm for performing active learning with support vector machines, i.e., an algorithm for choosing which instances to request next. We provide a theoretical motivation for the algorithm using the notion of a version space. We present experimental results showing that employing our active learning method can significantly reduce the need for labeled training instances in both the standard inductive and transductive settings.},
  file = {/Users/hyan46/Zotero/storage/LT3RXPW4/Tong and Koller - Support Vector Machine Active Learning with Applic.pdf},
  langid = {english}
}

@article{tootooniOnline2016,
  title = {Online Non-Contact Surface Finish Measurement in Machining Using Graph Theory-Based Image Analysis},
  author = {Tootooni, M. S. and Liu, C. and Roberson, D. and Donovan, R. and Rao, P. K. and Kong, Z. and Bukkapatnamd, Satish},
  date = {2016-10},
  journaltitle = {Journal of Manufacturing Systems},
  shortjournal = {J Manuf Syst J Manuf Syst},
  volume = {41},
  pages = {266--276},
  issn = {0278-6125},
  url = {://WOS:000390080700023},
  abstract = {This work addresses the following open research question: what non-contact measurement techniques and analytical approaches are required to assess the surface finish of a workpiece in situ during conventional machining without stopping the machine tool? The goal is to track variations in surface finish during conventional machining without stopping the machine tool so that quick compensatory action can be taken in case of a process drift. In pursuit of this goal, the objective of this work is non-contact, vision-based online measurement of surface finish in a conventional machining operation, such as outside diameter (OD) turning on a lathe. To realize the foregoing objective, algebraic graph theoretic image processing is used. The approach is based on converting an image of a surface into an unweighted and undirected network graph. The graph theoretic invariant, Fiedler number (lambda(2)), is estimated, and subsequently invoked as a discriminant of workpiece surface roughness. The advantage of the proposed approach is that it eschews complex image filtering and segmentation steps. The central hypothesis is that the graph-based topological quantifier Fiedler number (lambda(2)) estimates surface finish in a conventional machining operation with accuracy Sa +/- 2 mu m (arithmetic average areal surface roughness, mu m) when Sa is in the range of 1-10 mu m. This hypothesis is tested on conventional cylindrical (outside diameter) turning of shafts by using an optical imaging setup (CCD camera) incorporated into a lathe machine. Through statistical modeling it is demonstrated that the Fiedler number (lambda(2)) tracks surface finish variations in situ for steel and aluminum alloy shafts (4340 and 6061 grades, respectively) in near real-time with a maximum error of approximately Sa +/- 2 mu m. This measurement error was verified to be within 15\% of the actual measured surface finish. Tests were also carried out under three different rotational speeds (0 rpm, 45 rpm, 245 rpm); and the approach was consequently attested to be robust to rotational speeds. The computational time for estimating the surface finish from this approach was assessed to be within tenth of a second, thus validating its practical applicability. (C) 2016 The Society of Manufacturing Engineers. Published by Elsevier Ltd. All rights reserved.},
  keywords = {algebraic graph theory,in situ surface finish measurement,machining,metrology,non-contact surface measurement,paradigm shifts,roughness,texture,vision system},
  langid = {english}
}

@article{tranDetecting2019,
  title = {Detecting Changes in Transient Complex Systems via Dynamic Network Inference},
  author = {Tran, H. M. and Bukkapatnam, Satish and Garg, M.},
  date = {2019},
  journaltitle = {Iise Transactions},
  shortjournal = {Iise Trans Iise Trans},
  volume = {51},
  pages = {337--353},
  issn = {2472-5854},
  url = {://WOS:000468240500008},
  abstract = {Graph analytics methods have evoked significant interest in recent years. Their applicability to real-world complex systems is currently limited by the challenges of inferring effective graph representations of the high-dimensional, noisy, nonlinear and transient dynamics from limited time series outputs, as well as of extracting statistical quantifiers that capture the salient structure of the inferred graphs for detecting change. In this article, we present an approach to detecting changes in complex dynamic systems that is based on spectral-graph-theory and uses a single realization of time series data collected under specific, common types of transient conditions, such as intermittency. We introduce a statistic, gamma(k), based on the spectral content of the inferred graph. We show that the gamma(k) statistic under high-dimensional dynamics converges to a normal distribution, and we employ the parameters of this distribution to construct a procedure to detect qualitative changes in the coupling structure of a dynamical system. Experimental investigations suggest that the gamma(k) statistic by itself is able to detect changes with modified area under curve (mAUC) of about 0.96 (for numerical simulation tests), and can, by itself, achieve a true positive rate of about 40\% for detecting seizures from EEG signals. In addition, by incorporating this statistic with random forest, one of the best seizure detection methods, the seizure detection rate of the random forest method improves by 5\% in 35\% of the subjects. These studies of the network inferred from EEG signals suggest that gamma(k) can capture salient structural changes in the physiology of the process and can therefore serve as an effective feature for detecting seizures from EEG signals.},
  keywords = {behavior,brain,change detection,expression,functional connectivity,modulation,network inference,prediction,resonance,seizure,synchronization,time series,time-series,transient process},
  langid = {english},
  number = {3}
}

@online{Transformers2019,
  title = {Transformers {{In NLP}} | {{State}}-{{Of}}-{{The}}-{{Art}}-{{Models}}},
  date = {2019-06-19T02:37:10+00:00},
  url = {https://www.analyticsvidhya.com/blog/2019/06/understanding-transformers-nlp-state-of-the-art-models/},
  urldate = {2020-07-10},
  abstract = {What is a Transformers in NLP? Transformers are one of the most interesting concepts in NLP. A guide to state-of-the-art-model and how transformers work.},
  file = {/Users/hyan46/Zotero/storage/BBYKZPSK/understanding-transformers-nlp-state-of-the-art-models.html},
  organization = {{Analytics Vidhya}}
}

@article{traoreOnline,
  title = {Online Multimodal Dictionary Learning through {{Tucker}} Decomposition},
  author = {Traoré, Abraham and Berar, Maxime and Rakotomamonjy, Alain},
  pages = {33},
  abstract = {We propose a new online approach for multimodal dictionary learning. The method developed in this work addresses the great challenges posed by the computational resource constraints in dynamic environment when dealing with large scale tensor sequences. Given a sequence of tensors, i.e. a set composed of equal-size tensors, the approach proposed in this paper allows to infer a basis of latent factors that generate these tensors by sequentially processing a small number of data samples instead of using the whole sequence at once. Our technique is based on block coordinate descent, gradient descent and recursive computations of the gradient. A theoretical result is provided and numerical experiments on both real and synthetic data sets are performed.},
  file = {/Users/hyan46/Dropbox (ASU)/ZoteroData/Traoré et al_Online multimodal dictionary learning through Tucker decomposition.pdf},
  langid = {english}
}

@article{tsochantaridisLarge2005,
  title = {Large {{Margin Methods}} for {{Structured}} and {{Interdependent Output Variables}}},
  author = {Tsochantaridis, Ioannis and Joachims, Thorsten and Hofmann, Thomas and Altun, Yasemin},
  date = {2005},
  journaltitle = {Journal of Machine Learning Research},
  volume = {6},
  pages = {1453--1484},
  abstract = {Learning general functional dependencies between arbitrary input and output spaces is one of the key challenges in computational intelligence. While recent progress in machine learning has mainly focused on designing flexible and powerful input representations, this paper addresses the complementary issue of designing classification algorithms that can deal with more complex outputs, such as trees, sequences, or sets. More generally, we consider problems involving multiple dependent output variables, structured output spaces, and classification problems with class attributes. In order to accomplish this, we propose to appropriately generalize the well-known notion of a separation margin and derive a corresponding maximum-margin formulation. While this leads to a quadratic program with a potentially prohibitive, i.e. exponential, number of constraints, we present a cutting plane algorithm that solves the optimization problem in polynomial time for a large class of problems. The proposed method has important applications in areas such as computational biology, natural language processing, information retrieval/extraction, and optical character recognition. Experiments from various domains involving different types of output spaces emphasize the breadth and generality of our approach.},
  file = {/Users/hyan46/Dropbox (ASU)/ZoteroData/Tsochantaridis et al_Large Margin Methods for Structured and Interdependent Output Variables.pdf},
  langid = {english},
  number = {9}
}

@article{tsungStatistical2018,
  title = {Statistical Transfer Learning: {{A}} Review and Some Extensions to Statistical Process Control},
  author = {Tsung, Fugee and Zhang, Ke and Cheng, Longwei and Song, Zhenli},
  date = {2018-01-02},
  journaltitle = {Quality Engineering},
  shortjournal = {Quality Engineering},
  volume = {30},
  pages = {135--136},
  issn = {0898-2112, 1532-4222},
  doi = {10.1080/08982112.2018.1390957},
  url = {https://www.tandfonline.com/doi/full/10.1080/08982112.2018.1390957},
  urldate = {2020-07-20},
  abstract = {The rapid development of information technology, together with advances in sensory and data acquisition techniques, has led to the increasing necessity of handling datasets from multiple domains. In recent years, transfer learning has emerged as an effective framework for tackling related tasks in target domains by transferring previously-acquired knowledge from source domains. Statistical models and methodologies are widely involved in transfer learning and play a critical role, which, however, has not been emphasized in most surveys of transfer learning. In this article, we conduct a comprehensive literature review on statistical transfer learning, i.e., transfer learning techniques with a focus on statistical models and statistical methodologies, demonstrating how statistics can be used in transfer learning. In addition, we highlight opportunities for the use of statistical transfer learning to improve statistical process control and quality control. Several potential future issues in statistical transfer learning are discussed.},
  file = {/Users/hyan46/Dropbox (ASU)/ZoteroData/Tsung et al_2018_Statistical transfer learning.pdf},
  keywords = {Method: Transfer Learning,Problem: Process Monitoring},
  langid = {english},
  number = {1}
}

@article{unknownRecurrence2020,
  title = {Recurrence {{Network Analysis}} of {{Design}}-Quality {{Interactions}} in {{Additive Manufacturing}}},
  author = {Unknown, Unknown},
  date = {2020},
  journaltitle = {IISE Transactions},
  volume = {0},
  pages = {0},
  abstract = {Powder bed fusion (PBF) additive manufacturing (AM) provides a greater level of  ex- ibility in the design-driven build of metal products. However, the more complex the design is, the more di cult to control the quality of AM builds. The quality challenge persistently hampers the widespread application of AM technology. Advanced imaging (e.g., X-ray com- puted tomography scans and high-resolution optical images) has been increasingly invested to enhance the visibility of information and improve the AM quality control. However, re- alizing the full potential of imaging data depends on the advent of information processing methodologies for the analysis of design-quality interactions. This paper presents a design of AM experiment to investigate how design parameters (e.g., build orientation, thin-wall width, thin-wall height, and hatching distance) interact with quality characteristics in thin- wall builds. First, we develop a novel generalized recurrence network (GRN) to represent the AM spatial image data. Then, GRN quanti ers, namely degree, betweenness, pagerank, closeness, and eigenvector centralities, are extracted to characterize the quality of layer- wise builds. Further, we establish a regression model to predict how the design complexity impacts GRN behaviors in each layer of thin-wall builds. Experimental results show that net- work features are sensitive to build orientations, width, height, and hatching distance under the signi cant level   = 0:05. Thin-walls with the width bigger than 0.1 mm printed under orientation 0  are found to yield better quality compared to 60 and 90. Also, thin-walls build with orientation 60 are more sensitive to the changes in hatching distance compare to the other two orientations. As a result, the orientation 60 should be avoided while printing thin-wall structures. The proposed design-quality analysis shows great potential to optimize engineering design and enhance the quality of PBF-AM builds.},
  file = {/Users/hyan46/Dropbox (ASU)/ZoteroData/Unknown_2020_Recurrence Network Analysis of Design-quality Interactions in Additive.pdf},
  number = {0}
}

@article{vaicenaviciusEvaluating,
  title = {Evaluating Model Calibration in Classification},
  author = {Vaicenavicius, Juozas and Widmann, David and Andersson, Carl and Lindsten, Fredrik},
  pages = {9},
  abstract = {Probabilistic classifiers output a probability distribution on target classes rather than just a class prediction. Besides providing a clear separation of prediction and decision making, the main advantage of probabilistic models is their ability to represent uncertainty about predictions. In safetycritical applications, it is pivotal for a model to possess an adequate sense of uncertainty, which for probabilistic classifiers translates into outputting probability distributions that are consistent with the empirical frequencies observed from realized outcomes. A classifier with such a property is called calibrated. In this work, we develop a general theoretical calibration evaluation framework grounded in probability theory, and point out subtleties present in model calibration evaluation that lead to refined interpretations of existing evaluation techniques. Lastly, we propose new ways to quantify and visualize miscalibration in probabilistic classification, including novel multidimensional reliability diagrams.},
  file = {/Users/hyan46/Dropbox (ASU)/ZoteroData/Vaicenavicius et al_Evaluating model calibration in classification.pdf},
  langid = {english}
}

@online{vaswaniAttention2017,
  title = {Attention {{Is All You Need}}},
  author = {Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N. and Kaiser, Lukasz and Polosukhin, Illia},
  date = {2017-12-05},
  url = {http://arxiv.org/abs/1706.03762},
  urldate = {2020-07-10},
  abstract = {The dominant sequence transduction models are based on complex recurrent or convolutional neural networks that include an encoder and a decoder. The best performing models also connect the encoder and decoder through an attention mechanism. We propose a new simple network architecture, the Transformer, based solely on attention mechanisms, dispensing with recurrence and convolutions entirely. Experiments on two machine translation tasks show these models to be superior in quality while being more parallelizable and requiring significantly less time to train. Our model achieves 28.4 BLEU on the WMT 2014 Englishto-German translation task, improving over the existing best results, including ensembles, by over 2 BLEU. On the WMT 2014 English-to-French translation task, our model establishes a new single-model state-of-the-art BLEU score of 41.8 after training for 3.5 days on eight GPUs, a small fraction of the training costs of the best models from the literature. We show that the Transformer generalizes well to other tasks by applying it successfully to English constituency parsing both with large and limited training data.},
  archiveprefix = {arXiv},
  eprint = {1706.03762},
  eprinttype = {arxiv},
  file = {/Users/hyan46/Dropbox (ASU)/ZoteroData/Vaswani et al_2017_Attention Is All You Need.pdf},
  keywords = {Computer Science - Computation and Language,Computer Science - Machine Learning},
  langid = {english},
  primaryclass = {cs}
}

@article{vilaltaPerspective2002,
  title = {A {{Perspective View}} and {{Survey}} of {{Meta}}-{{Learning}}},
  author = {Vilalta, Ricardo and Drissi, Youssef},
  date = {2002-06-01},
  journaltitle = {Artificial Intelligence Review},
  shortjournal = {Artificial Intelligence Review},
  volume = {18},
  pages = {77--95},
  issn = {1573-7462},
  doi = {10.1023/A:1019956318069},
  url = {https://doi.org/10.1023/A:1019956318069},
  urldate = {2020-05-22},
  abstract = {Different researchers hold different views of what the term meta-learning exactlymeans. The first part of this paper provides our own perspective view in which the goal isto build self-adaptive learners (i.e. learning algorithms that improve their bias dynamicallythrough experience by accumulating meta-knowledge). The second part provides a survey ofmeta-learning as reported by the machine-learning literature. We find that, despite differentviews and research lines, a question remains constant: how can we exploit knowledge aboutlearning (i.e. meta-knowledge) to improve the performance of learning algorithms? Clearlythe answer to this question is key to the advancement of the field and continues being thesubject of intensive research.},
  file = {/Users/hyan46/Dropbox (ASU)/ZoteroData/Vilalta_Drissi_2002_A Perspective View and Survey of Meta-Learning.pdf},
  langid = {english},
  number = {2}
}

@article{villariniOptimization2017,
  title = {Optimization of Photovoltaic Maintenance Plan by Means of a {{FMEA}} Approach Based on Real Data},
  author = {Villarini, Mauro and Cesarotti, Vittorio and Alfonsi, Lucrezia and Introna, Vito},
  date = {2017-11-15},
  journaltitle = {Energy Conversion and Management},
  shortjournal = {Energy Conversion and Management},
  volume = {152},
  pages = {1--12},
  issn = {0196-8904},
  doi = {10.1016/j.enconman.2017.08.090},
  url = {http://www.sciencedirect.com/science/article/pii/S0196890417307926},
  urldate = {2020-06-09},
  abstract = {There have been many scientific advances in the improvement of renewable energy systems. Recently, considerable interest has been given to their optimized management during their service life due to a large increase in the number of new renewable energy source power plants. High reliability levels are as important as high yields in order to maximize the useful green energy produced. Solar energy has been one of the most popular and exploited renewable sources in the market and therefore improvements in its efficiency and reliability have had a considerable impact. All energy systems require an increase in their conversion efficiency to reduce the consumption of primary energy. Moreover, the optimization of the performance of photovoltaic systems has increased their incidence as renewable sources in global power generation and has boosted their profitability. A failure of the components and sub-components of a working energy system cause two main issues; the first direct implication for the plant is the damage of the components and sub-components, and the second indirect implication is the consequent lack of energy production due to the plant being out of order. Furthermore, unforeseen failures of the components increase the uncontrollability of photovoltaic power systems, which worsens electric grid dispatching. The work presented here provides, for the first time, a complete and new assessment of Reliability Centered Maintenance carried out using a failure mode and effect analysis approach to photovoltaic systems. We use a large volume of data derived from a database of real maintenance activities carried out by a multinational company. These data were interpreted by the opinions of experts with specialist experience in the installation, operation, and maintenance of photovoltaic power systems, from small to multi-megawatt size. The present work here has advantages over many previous studies since the information was derived from real experiences of photovoltaic systems which allowed for a more realistic risk analysis and, especially, this information was also used to revise the maintenance plan of photovoltaic installations and to optimize their effectiveness, concentrating on various failure modes which mostly affect production or which can be easily removed/reduced.},
  file = {/Users/hyan46/Dropbox (ASU)/ZoteroData/Villarini et al_2017_Optimization of photovoltaic maintenance plan by means of a FMEA approach based2.pdf},
  keywords = {Application: Solar},
  langid = {english}
}

@inproceedings{viswanathDetecting2014,
  title = {Towards {{Detecting Anomalous User Behavior}} in {{Online Social Networks}}},
  booktitle = {Proceedings of the 23rd {{USENIX Security Symposium}}},
  author = {Viswanath, Bimal and Gummadi, Krishna P and Bashir, M Ahmad and Crovella, Mark and Guha, Saikat and Krishnamurthy, Balachander and Mislove, Alan},
  date = {2014},
  pages = {17},
  location = {{San Diego}},
  abstract = {Users increasingly rely on crowdsourced information, such as reviews on Yelp and Amazon, and liked posts and ads on Facebook. This has led to a market for blackhat promotion techniques via fake (e.g., Sybil) and compromised accounts, and collusion networks. Existing approaches to detect such behavior relies mostly on supervised (or semi-supervised) learning over known (or hypothesized) attacks. They are unable to detect attacks missed by the operator while labeling, or when the attacker changes strategy.},
  file = {/Users/hyan46/Dropbox (ASU)/ZoteroData/Viswanath et al_2014_Towards Detecting Anomalous User Behavior in Online Social Networks.pdf},
  isbn = {978-1-931971-15-7},
  langid = {english}
}

@article{wang2017knowledge,
  title = {Knowledge Graph Embedding: {{A}} Survey of Approaches and Applications},
  author = {Wang, Quan and Mao, Zhendong and Wang, Bin and Guo, Li},
  date = {2017},
  journaltitle = {IEEE Transactions on Knowledge and Data Engineering},
  volume = {29},
  pages = {2724--2743},
  publisher = {{IEEE}},
  file = {/Users/hyan46/Dropbox (ASU)/ZoteroData/Wang et al_2017_Knowledge graph embedding.pdf},
  number = {12}
}

@article{wangAcoustic2020,
  title = {Acoustic {{Emission Characterization}} of {{Natural Fiber Reinforced Plastic Composite Machining Using}} a {{Random Forest Machine Learning Model}}},
  author = {Wang, Zimo and Chegdani, Faissal and Yalamarti, Neehar and Takabi, Behrouz and Tai, Bruce and El Mansori, Mohamed and Bukkapatnam, Satish},
  date = {2020},
  journaltitle = {Journal of Manufacturing Science and Engineering},
  volume = {142},
  issn = {1087-1357},
  file = {/Users/hyan46/Dropbox (ASU)/ZoteroData/Wang et al_2020_Acoustic Emission Characterization of Natural Fiber Reinforced Plastic.pdf},
  number = {3}
}

@inproceedings{wangAdaptive2019,
  title = {An {{Adaptive Probabilistic Maintenance Framework}} for {{Decision Planning Optimization}}},
  booktitle = {{{AIAA Scitech}} 2019 {{Forum}}},
  author = {Wang, Yuhao and Liu, Yongming},
  date = {2019},
  pages = {0442}
}

@article{wangAugmented,
  title = {An {{Augmented Regression Model}} for {{Tensors}} with {{Missing Values}}},
  author = {Wang, Feng and Gahrooei, Mostafa Reisi and Zhong, Zhen and Tang, Tao and Shi, Jianjun},
  pages = {13},
  abstract = {Heterogeneous but complementary sources of data provide an unprecedented opportunity for developing accurate statistical models of systems. Although the existing methods have shown promising results, they are mostly applicable to situations where the system output is measured in its complete form. In reality, however, it may not be feasible to obtain the complete output measurement of a system, which results in observations that contain missing values. This paper introduces a general framework that integrates tensor regression with tensor completion and proposes an efficient optimization framework that alternates between two steps for parameter estimation. Through multiple simulations and a case study, we evaluate the performance of the proposed method. The results indicate the superiority of the proposed method in comparison to a benchmark.},
  file = {/Users/hyan46/Dropbox (ASU)/ZoteroData/Wang et al_An Augmented Regression Model for Tensors with Missing Values.pdf},
  langid = {english}
}

@article{wangBayesian2020,
  title = {Bayesian Entropy Network for Fusion of Different Types of Information},
  author = {Wang, Yuhao and Liu, Yongming},
  date = {2020-03-01},
  journaltitle = {Reliability Engineering \& System Safety},
  shortjournal = {Reliability Engineering \& System Safety},
  volume = {195},
  pages = {106747},
  issn = {0951-8320},
  doi = {10.1016/j.ress.2019.106747},
  url = {http://www.sciencedirect.com/science/article/pii/S0951832018313115},
  urldate = {2020-09-27},
  abstract = {A hybrid method for information fusion combining the maximum entropy (ME) method with the classical Bayesian network is proposed as the Bayesian-Entropy Network (BEN) in this paper. The key benefit of the proposed method is the capability to handle various types of information for classification and updating, such as classical point data, abstracted statistical information, and range data. The detailed derivation of the proposed is given and special focus is on the formulation of different types of information as constraints embedded in the entropy part. The Bayesian part is used to handle classical point observation data. Next, an adaptive algorithm is proposed to mitigate the impact of wrong information constraints on the final posterior distribution estimation. Following this, several examples are used to demonstrate the proposed methodology and application to engineering problems. It is shown that the proposed method is a generalized form of classical Bayesian method, and can take advantage of the extra information. This advantage is preferable in many engineering applications especially when the number of point observations is limited. Conclusions and future work are drawn based on the current study.},
  file = {/Users/hyan46/Zotero/storage/2ACLCZFW/S0951832018313115.html},
  keywords = {Bayesian network,Classification,Maximum entropy,Probability,Updating},
  langid = {english}
}

@article{wangBidirectional2020,
  ids = {wangBidirectional2020a},
  title = {Bidirectional {{Gated Recurrent Deep Learning Neural Networks}} for {{Smart Acoustic Emission Sensing}} of {{Natural Fiber}}–{{Reinforced Polymer Composite Machining Process}}},
  author = {Wang, Zimo and Dixit, Pawan and Chegdani, Faissal and Takabi, Behrouz and Tai, Bruce L and El Mansori, Mohamed and Bukkapatnam, Satish},
  date = {2020},
  issn = {2520-6478},
  file = {/Users/hyan46/Dropbox (ASU)/ZoteroData/Wang et al_2020_Bidirectional Gated Recurrent Deep Learning Neural Networks for Smart Acoustic.pdf},
  keywords = {Application: Additive Manufacturing,Method: Deep Learning}
}

@article{wangBuiltupedge2016,
  title = {Built-up-Edge Effects on Surface Deterioration in Micromilling Processes},
  author = {Wang, Z and Kovvuri, V and Araujo, A and Bacci, M and Hung, WNP and Bukkapatnam, Satish},
  date = {2016},
  journaltitle = {Journal of Manufacturing Processes},
  volume = {24},
  pages = {321--327},
  issn = {1526-6125},
  file = {/Users/hyan46/Dropbox (ASU)/ZoteroData/Wang et al_2016_Built-up-edge effects on surface deterioration in micromilling processes.pdf},
  keywords = {micro-Machining,micromilling,other,Supervised learning,surface finish}
}

@article{wangChange2014,
  title = {Change Detection in Precision Manufacturing Processes under Transient Conditions},
  author = {Wang, Z. M. and Bukkapatnam, Satish and Kumara, S. R. T. and Kong, Z. Y. and Katz, Z.},
  date = {2014},
  journaltitle = {Cirp Annals-Manufacturing Technology},
  shortjournal = {Cirp Ann-Manuf Techn Cirp Ann-Manuf Techn},
  volume = {63},
  pages = {449--452},
  issn = {0007-8506},
  url = {://WOS:000338811000113},
  abstract = {Early detection of changes in transient process behaviors from sensor signals is becoming essential for quality assurance in microelectronics and ultraprecision manufacturing processes. We present a Dirichlet process Gaussian State Machine (DPGSM) representation to capture complex dynamics as a random concatenation of nonlinear stationary segments, and develop a method to detect early-stage fault-inducing changes. Extensive experiments suggest that the present approach, compared to other methods tested, was able to detect slight changes that cause severe surface damage 48 ms earlier in an ultraprecision machining (UPM) process, and at least 2000 ms earlier in a chemical mechanical planarization (CMP) process. (C) 2014 CIRP.},
  keywords = {complex systems,predictive model,quality assurance},
  langid = {english},
  number = {1}
}

@article{wangConfigurationBased2020,
  title = {Configuration-{{Based Smart Customization Service}}: {{A Multitask Learning Approach}}},
  shorttitle = {Configuration-{{Based Smart Customization Service}}},
  author = {Wang, Yue and Li, Xiang and Tsung, Fugee},
  date = {2020},
  journaltitle = {IEEE Transactions on Automation Science and Engineering},
  shortjournal = {IEEE Trans. Automat. Sci. Eng.},
  pages = {1--10},
  issn = {1545-5955, 1558-3783},
  doi = {10.1109/TASE.2020.2986774},
  url = {https://ieeexplore.ieee.org/document/9078363/},
  urldate = {2020-07-20},
  abstract = {Smart customization service is an important element for smart manufacturing. The success of smart customization requires that designers, manufacturers, and customers with differences in context, semantics, and other cognitive aspects be engaged in a collaborative process. With product configurators reported to have positive impacts on product quality to meet customers’ needs, this article attempts to explore an approach for smart customization service based on configurators. To better address the semantic gap between customers and designers/manufacturers, a new configuration mechanism is proposed that takes into consideration customer needs using natural language as the input and maps them to product specifications in the design stage. We collected a massive amount of review text from e-commerce websites and used ELMo, a contextualized word representation based on a deep bidirectional language model, to encode the text. A multitask learning-based neural network was adopted to build the mapping from layman customer needs to product specifications. Our experiments show that this approach can achieve a promising performance for the configuration task and, thereby, facilitate smart customization services.},
  file = {/Users/hyan46/Dropbox (ASU)/ZoteroData/Wang et al_2020_Configuration-Based Smart Customization Service.pdf},
  keywords = {Application: Manufacturing,Data: Text,Method: Deep Learning,Method: Transfer Learning},
  langid = {english}
}

@online{wangCPACConv2020,
  title = {{{CPAC}}-{{Conv}}: {{CP}}-Decomposition to {{Approximately Compress Convolutional Layers}} in {{Deep Learning}}},
  shorttitle = {{{CPAC}}-{{Conv}}},
  author = {Wang, Yinan and Weihong and Guo and Yue, Xiaowei},
  date = {2020-05-27},
  url = {http://arxiv.org/abs/2005.13746},
  urldate = {2020-07-21},
  abstract = {Feature extraction for tensor data serves as an important step in many tasks such as anomaly detection, process monitoring, image classification, and quality control. Although many methods have been proposed for tensor feature extraction, there are still two challenges that need to be addressed: 1) how to reduce the computation cost for high dimensional and large volume tensor data; 2) how to interpret the output features and evaluate their significance. Although the most recent methods in deep learning, such as Convolutional Neural Network (CNN), have shown outstanding performance in analyzing tensor data, their wide adoption is still hindered by model complexity and lack of interpretability. To fill this research gap, we propose to use CP-decomposition to approximately compress the convolutional layer (CPAC-Conv layer) in deep learning. The contributions of our work could be summarized into three aspects: 1) we adapt CP-decomposition to compress convolutional kernels and derive the expressions of both forward and backward propagations for our proposed CPAC-Conv layer; 2) compared with the original convolutional layer, the proposed CPAC-Conv layer can reduce the number of parameters without decaying prediction performance. It can combine with other layers to build novel Neural Networks; 3) the value of decomposed kernels indicates the significance of the corresponding feature map, which increases model interpretability and provides us insights to guide feature selection.},
  archiveprefix = {arXiv},
  eprint = {2005.13746},
  eprinttype = {arxiv},
  file = {/Users/hyan46/Dropbox (ASU)/ZoteroData/Wang et al_2020_CPAC-Conv.pdf},
  keywords = {Method: Deep Learning,Method: Tensor},
  langid = {english},
  primaryclass = {cs, stat}
}

@article{wangCrossDomain2013,
  title = {Cross-{{Domain Model Building}} and {{Validation}} ({{CDMV}}): {{A New Modeling Strategy}} to {{Reinforce Understanding}} of {{Nanomanufacturing Processes}}},
  shorttitle = {Cross-{{Domain Model Building}} and {{Validation}} ({{CDMV}})},
  author = {Wang, Li and Huang, Qiang},
  date = {2013-07},
  journaltitle = {IEEE Transactions on Automation Science and Engineering},
  shortjournal = {IEEE Trans. Automat. Sci. Eng.},
  volume = {10},
  pages = {571--578},
  issn = {1545-5955, 1558-3783},
  doi = {10.1109/TASE.2013.2243433},
  url = {http://ieeexplore.ieee.org/document/6466395/},
  urldate = {2020-07-04},
  abstract = {Understanding nanostructure growth faces issues of limited data, lack of physical knowledge, and large process uncertainties. These issues result in modeling difficulty because a large pool of candidate models almost fit the data equally well. Through the Integrated Nanomanufacturing and Nanoinformatics (INN) strategy, we derive the process models from physical and statistical domains, respectively, and reinforce the understanding of growth processes by identifying the common model structure across two domains. This cross-domain model building strategy essentially validates models by domain knowledge rather than by (unavailable) data. It not only increases modeling confidence under large uncertainties, but also enables insightful physical understanding of the growth kinetics. We present this method by studying the weight growth kinetics of silica nanowire under two temperature conditions. The derived nanowire growth model is able to provide physical insights for prediction and control under uncertainties.},
  file = {/Users/hyan46/Dropbox (ASU)/ZoteroData/Wang_Huang_2013_Cross-Domain Model Building and Validation (CDMV).pdf},
  keywords = {Application: Manufacturing,Application: Nano,People: Qiang Huang},
  langid = {english},
  number = {3}
}

@article{wangDefect2020,
  title = {Defect Pattern Recognition on Wafers Using Convolutional Neural Networks},
  author = {Wang, Rui and Chen, Nan},
  date = {2020-06},
  journaltitle = {Quality and Reliability Engineering International},
  shortjournal = {Qual Reliab Engng Int},
  volume = {36},
  pages = {1245--1257},
  issn = {0748-8017, 1099-1638},
  doi = {10.1002/qre.2627},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/qre.2627},
  urldate = {2020-07-04},
  abstract = {In semiconductor manufacturing, wafer testing is performed to ensure the performance of each product after wafer fabrication. The wafer map is used to visualize the color-coded wafer test results based on the locations. The defects on the wafer map may be randomly distributed or form clustered patterns. The various clustered defect patterns are usually caused by assignable faults. The identification of the patterns is thus important to provide valuable hints for the root causes diagnosis. Solving the problems helps improve the manufacturing processes and reduce costs. In this study, we present a novel convolutional neural network (CNN)–based method to automatically recognize the defect pattern on wafer maps. Our method uses polar mapping before the training of CNN to transform the circular wafer map into a matrix, which can be processed within CNN architecture. This procedure also reduces the input size and solves variations in wafer sizes and die sizes. To eliminate the effects of rotation, we apply data augmentation in the training of CNN. Experiments using the real-world dataset prove the effectiveness and superiority of our method.},
  file = {/Users/hyan46/Dropbox (Personal)/ZoteroData/Wang_Chen_2020_Defect pattern recognition on wafers using convolutional neural networks.pdf},
  keywords = {Application: Manufacturing,Application: Semiconductor,Method: Classification,Method: Deep Learning,People: Chen Nan,Problem: Classification},
  langid = {english},
  number = {4}
}

@article{wangDirichlet2018,
  title = {A {{Dirichlet Process Gaussian State Machine Model}} for {{Change Detection}} in {{Transient Processes}}},
  author = {Wang, Z. M. and Bukkapatnam, Satish},
  date = {2018},
  journaltitle = {Technometrics},
  shortjournal = {Technometrics Technometrics},
  volume = {60},
  pages = {373--385},
  issn = {0040-1706},
  url = {://WOS:000442695100009},
  abstract = {The ability to detect incipient and critical changes in real world process-esessential for system integrity assurance-is currently impeded by the mismatch between the key assumption of stationarity underlying most change detection methods and the nonlinear and non-stationary (transient) dynamics of most real-world processes. The current approaches are slow or outright unable to detect qualitative changes in the behaviors that lead to anomalies. We present a Dirichlet process Gaussian state machine (DPGSM) model to represent dynamic intermittency, which is one of the most ubiquitous real-world transient behaviors. The DPGSM model treats a signal as a random walk among a Dirichlet process mixture of Gaussian clusters. Hypothesis tests and a numerical scheme based on this non-parametric representation were developed to detect subtle changes in the transient (intermittent) dynamics. Experimental investigations suggest that the DPGSM approach can consistently detect incipient, critical changes in intermittent signals some 50-2000 ms (20-90\%) ahead of competing methods in benchmark test cases as well as a variety of real-world applications, such as in alternation patterns (e.g., ragas) in a music piece, and in the vibration signals capturing the initiation of product defects in an ultraprecision manufacturing process. A supplementary file to this article, available online, includes a Matlab implementation of the presented DPGSM.},
  keywords = {algorithm,bayesian nonparametrics,convergence-rates,density-estimation,intermittency,intermittent nonstationary process,mixture,nonstationary,quality assurance,sequences},
  langid = {english},
  number = {3}
}

@article{wangFast2019,
  title = {A {{Fast}} and {{Robust Nonparametric Monitoring Scheme}} for {{Free}}-{{Form Surface Scanning Data}}},
  author = {Wang, Kai and Tsung, Fugee},
  date = {2019-10},
  journaltitle = {IEEE Transactions on Automation Science and Engineering},
  shortjournal = {IEEE Trans. Automat. Sci. Eng.},
  volume = {16},
  pages = {1675--1685},
  issn = {1545-5955, 1558-3783},
  doi = {10.1109/TASE.2019.2892510},
  url = {https://ieeexplore.ieee.org/document/8630820/},
  urldate = {2020-07-20},
  abstract = {The advance of new sensing technologies, such as the 3-D laser scanning, creates a data-rich environment for quality control in modern industries. The free-form surfaces of complex manufactured parts can be quickly scanned, producing thousands of data points. To monitor these large-scale surface scanning data, three major challenges have to be solved simultaneously: 1) simple parametric models are no longer sufficient to describe free-form surfaces; 2) the massive data points need fast computations; and 3) the presence of outliers calls for robust analytics. To fulfill this task, this paper proposes a novel monitoring scheme where the control chart is designed based on a new robust bilateral kernel smoothing method. A fast approximation algorithm is also developed for efficient online monitoring. This fast and robust nonparametric control chart shows significant superiority for surface monitoring in our numerical simulations. Finally, a real case study demonstrates the effectiveness of our proposed scheme in monitoring the stability of a 3-D printing process.},
  file = {/Users/hyan46/Dropbox (ASU)/ZoteroData/Wang_Tsung_2019_A Fast and Robust Nonparametric Monitoring Scheme for Free-Form Surface.pdf},
  keywords = {Application: Manufacturing,Application: Surface Scanning,Data: Point Cloud,Method: Functional,Problem: Process Monitoring},
  langid = {english},
  number = {4}
}

@article{wangHierarchical2020,
  title = {Hierarchical Sparse Functional Principal Component Analysis for Multistage Multivariate Profile Data},
  author = {Wang, Kai and Tsung, Fugee},
  date = {2020-04-22},
  journaltitle = {IISE Transactions},
  shortjournal = {IISE Transactions},
  pages = {1--16},
  issn = {2472-5854, 2472-5862},
  doi = {10.1080/24725854.2020.1738599},
  url = {https://www.tandfonline.com/doi/full/10.1080/24725854.2020.1738599},
  urldate = {2020-07-20},
  abstract = {Modern manufacturing systems typically involve multiple production stages, the real-time status of which can be tracked continuously using sensor networks that generate a large number of profiles associated with all process variables at all stages. The analysis of the collective behavior of the multistage multivariate profile data is essential for understanding the variance patterns of the entire manufacturing process. For this purpose, two major challenges regarding the high data dimensionality and low model interpretability have to be well addressed. This article proposes integrating Multivariate Functional Principal Component Analysis (MFPCA) with a three-level structured sparsity idea to develop a novel Hierarchical Sparse MFPCA (HSMFPCA), in which the stagewise, profile-wise and element-wise sparsity are jointly investigated to clearly identify the informative stages and variables in each eigenvector. In this way, the derived principal components would be more interpretable. The proposed HSMFPCA employs the regression-type reformulation of the PCA and the reparameterization of the entries of eigenvectors, and enjoys an efficient optimization algorithm in high-dimensional settings. The extensive simulations and a real example study verify the superiority of the proposed HSMFPCA with respect to the estimation accuracy and interpretation clarity of the derived eigenvectors.},
  file = {/Users/hyan46/Dropbox (ASU)/ZoteroData/Wang_Tsung_2020_Hierarchical sparse functional principal component analysis for multistage.pdf},
  keywords = {Application: Semiconductor,Data: Profiles,Method: Sparse,Method: Tensor,Problem: Supervised Learning},
  langid = {english}
}

@article{wangInPlane2017,
  title = {In-{{Plane Shape}}-{{Deviation Modeling}} and {{Compensation}} for {{Fused Deposition Modeling Processes}}},
  author = {Wang, Andi and Song, Suoyuan and Huang, Qiang and Tsung, Fugee},
  date = {2017-04},
  journaltitle = {IEEE Transactions on Automation Science and Engineering},
  shortjournal = {IEEE Trans. Automat. Sci. Eng.},
  volume = {14},
  pages = {968--976},
  issn = {1545-5955, 1558-3783},
  doi = {10.1109/TASE.2016.2544941},
  url = {http://ieeexplore.ieee.org/document/7460927/},
  urldate = {2020-07-04},
  abstract = {Additive manufacturing (AM) or 3-D printing refers to a new class of technologies that actively construct products directly from any 3-D digital model. In the future, the broader applications of AM will require a cost reduction of AM machines. Currently, the products fabricated by low-end machines, such as those fabricated using fused deposition modeling (FDM) processes, suffer from the issue of low dimensional accuracy due to multiple error sources. To properly manage error sources for improved prevision, this paper proposes a novel strategy for error compensation in the FDM processes. First, we consecutively attribute the dimensional inaccuracy to two major error sources that affect the geometric shape of the product: 1) positioning error of the extruder and 2) shape deformation induced by processing error, including material phase change and other variations that occur. The extruder positioning error is characterized by a Kriging model, while the modeling of shape deformation due to processing error follows the method developed by Huang et al. Second, using error equivalence concept, we transform the positioning error into the equivalent amount of design input error. Finally, we adjust the design to compensate for the overall shape deviation. To validate this strategy, we conduct a designed experiment for the shape deviation prediction and the compensation. The experimental results successfully demonstrate the effectiveness of the proposed three-step strategy to manage multiple error sources in the FDM processes.},
  file = {/Users/hyan46/Dropbox (ASU)/ZoteroData/Wang et al_2017_In-Plane Shape-Deviation Modeling and Compensation for Fused Deposition.pdf},
  keywords = {Application: Additive Manufacturing,Application: Manufacturing,People: Qiang Huang},
  langid = {english},
  number = {2}
}

@article{wangModeling2019,
  title = {Modeling of a Three-Dimensional Dynamic Thermal Field under Grid-Based Sensor Networks in Grain Storage},
  author = {Wang, Di and Liu, Kaibo and Zhang, Xi},
  date = {2019-05-04},
  journaltitle = {IISE Transactions},
  shortjournal = {IISE Transactions},
  volume = {51},
  pages = {531--546},
  issn = {2472-5854, 2472-5862},
  doi = {10.1080/24725854.2018.1504356},
  url = {https://www.tandfonline.com/doi/full/10.1080/24725854.2018.1504356},
  urldate = {2020-07-04},
  abstract = {Thermal management is a major task in granaries, due to the essential role of temperature in grain storage. The accurate acquisition and updating of thermal field information generates a meaningful index for grain quality surveillance and storage maintenance actions. However, given the unknown mechanisms of local uncertainties, including local grain degradation and fungal infections that may significantly vary the thermal field in granaries, the appropriate modeling of field dynamics remains a challenging task. To address this issue, this article combines a threedimensional (3D) nonlinear dynamics model with a stochastic spatiotemporal model to capture a 3D dynamic thermal map. To best harness the temperature data from the grid-based sensor network, we integrate the Kriging model into the Gaussian Markov random field model by introducing an anisotropic covariance function. Both simulation and real case studies are conducted to validate our proposed approach, and the results show that our approach outperforms other alternative methods for field estimation.},
  file = {/Users/hyan46/Dropbox (ASU)/ZoteroData/Wang et al_2019_Modeling of a three-dimensional dynamic thermal field under grid-based sensor.pdf},
  keywords = {Application: Remote Sensing,Method: Spatio-temporal,People: Kaibo Liu},
  langid = {english},
  number = {5}
}

@article{wangNovel2015,
  title = {A Novel Multi-Mode Data Processing Method and Its Application in Industrial Process Monitoring},
  author = {Wang, Guozhu and Liu, Jianchang and Zhang, Yingwei and Li, Yuan},
  date = {2015},
  journaltitle = {Journal of Chemometrics},
  volume = {29},
  pages = {126--138},
  issn = {1099-128X},
  doi = {10.1002/cem.2686},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/cem.2686},
  urldate = {2020-05-25},
  abstract = {Multi-mode process monitoring is a key issue often raised in industrial process control. Most multivariate statistical process monitoring strategies, such as principal component analysis (PCA) and partial least squares, make an essential assumption that the collected data follow a unimodal or Gaussian distribution. However, owing to the complexity and the multi-mode feature of industrial processes, the collected data usually follow different distributions. This paper proposes a novel multi-mode data processing method called weighted k neighbourhood standardisation (WKNS) to address the multi-mode data problem. This method can transform multi-mode data into an approximately unimodal or Gaussian distribution. The results of theoretical analysis and discussion suggest that the WKNS strategy is more suitable for multi-mode data normalisation than the z-score method is. Furthermore, a new fault detection approach called WKNS-PCA is developed and applied to detect process outliers. This method does not require process knowledge and multi-mode modelling; only a single model is required for multi-mode process monitoring. The proposed method is tested on a numerical example and the Tennessee Eastman process. Finally, the results demonstrate that the proposed data preprocessing and process monitoring methods are particularly suitable and effective in multi-mode data normalisation and industrial process fault detection. Copyright © 2014 John Wiley \& Sons, Ltd.},
  annotation = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/cem.2686},
  file = {/Users/hyan46/Zotero/storage/5PN96CZK/cem.html},
  keywords = {data processing,fault detection,multi-mode process,multimode,principal component analysis,Problem: Process Monitoring,weighted k neighbourhood standardisation},
  langid = {english},
  number = {2}
}

@article{wangpingExtended2020,
  title = {Extended {{SIR Prediction}} of the {{Epidemics Trend}} of {{COVID}}-19 in {{Italy}} and {{Compared With Hunan}}, {{China}}},
  author = {Wangping, Jia and Ke, Han and Yang, Song and Wenzhe, Cao and Shengshu, Wang and Shanshan, Yang and Jianwei, Wang and Fuyin, Kou and Penggang, Tai and Jing, Li and Miao, Liu and Yao, He},
  date = {2020-05-06},
  journaltitle = {Frontiers in Medicine},
  shortjournal = {Front. Med.},
  volume = {7},
  pages = {169},
  issn = {2296-858X},
  doi = {10.3389/fmed.2020.00169},
  url = {https://www.frontiersin.org/article/10.3389/fmed.2020.00169/full},
  urldate = {2020-08-09},
  abstract = {Background: Coronavirus Disease 2019 (COVID-19) is currently a global public health threat. Outside of China, Italy is one of the countries suffering the most with the COVID-19 epidemic. It is important to predict the epidemic trend of the COVID-19 epidemic in Italy to help develop public health strategies. Methods: We used time-series data of COVID-19 from Jan 22 2020 to Apr 02 2020. An infectious disease dynamic extended susceptible-infected-removed (eSIR) model, which covers the effects of different intervention measures in dissimilar periods, was applied to estimate the epidemic trend in Italy. The basic reproductive number was estimated using Markov Chain Monte Carlo methods and presented using the resulting posterior mean and 95\% credible interval (CI). Hunan, with a similar total population number to Italy, was used as a comparative item. Results: In the eSIR model, we estimated that the mean of basic reproductive number for COVID-19 was 4.34 (95\% CI, 3.04–6.00) in Italy and 3.16 (95\% CI, 1.73–5.25) in Hunan. There would be a total of 182 051 infected cases (95\%CI:116 114–274 378) under the current country blockade and the endpoint would be Aug 05 in Italy. Conclusion: Italy’s current strict measures can efficaciously prevent the further spread of COVID-19 and should be maintained. Necessary strict public health measures should be implemented as soon as possible in other European countries with a high number of COVID-19 cases. The most effective strategy needs to be confirmed in further studies.},
  file = {/Users/hyan46/Dropbox (ASU)/ZoteroData/Wangping et al_2020_Extended SIR Prediction of the Epidemics Trend of COVID-19 in Italy and.pdf},
  langid = {english}
}

@article{wangRegistrationfree2018,
  title = {Registration-Free Monitoring of Multimode near-Circular Shape Profiles: {{Monitoring Multimode Shape Profiles}}},
  shorttitle = {Registration-Free Monitoring of Multimode near-Circular Shape Profiles},
  author = {Wang, Kai and Li, Jian and Tsung, Fugee},
  date = {2018-06},
  journaltitle = {Quality and Reliability Engineering International},
  shortjournal = {Qual Reliab Engng Int},
  volume = {34},
  pages = {529--542},
  issn = {07488017},
  doi = {10.1002/qre.2270},
  url = {http://doi.wiley.com/10.1002/qre.2270},
  urldate = {2020-07-20},
  abstract = {Traditional shape profile monitoring of product geometric features mostly focuses on one type or mode of shapes in the discrete-part manufacturing. Little attention has been paid to monitoring of multimode shape profiles, where different modes of shapes appear in a sample in the batch production process. Motivated by a real example of a powder material production process, we exploit the statistical process monitoring of multimode near-circular shape profiles. First, we develop a feature extraction approach that is invariant to shape rotation and thus requires no registration for a mixture of different modes of shape profiles. The extracted feature vectors capture shape features well, based on which different modes of shape profiles are separated into several clusters. This enables us to build a Gaussian mixture model for the multimodality in the feature vector space. In process surveillance, a control chart is constructed based on the likelihood ratio test for detecting shifts in both the proportions and the shape features of multimode near-circular shape profiles. Numerical simulations and real case studies demonstrate the effectiveness of our proposed chart.},
  file = {/Users/hyan46/Dropbox (ASU)/ZoteroData/Wang et al_2018_Registration-free monitoring of multimode near-circular shape profiles.pdf},
  keywords = {Method: Functional,Problem: Process Monitoring},
  langid = {english},
  number = {4}
}

@article{wangSpatialadaptive2018,
  title = {A Spatial-Adaptive Sampling Procedure for Online Monitoring of Big Data Streams},
  author = {Wang, Andi and Xian, Xiaochen and Tsung, Fugee and Liu, Kaibo},
  date = {2018-10-02},
  journaltitle = {Journal of Quality Technology},
  shortjournal = {Journal of Quality Technology},
  volume = {50},
  pages = {329--343},
  issn = {0022-4065, 2575-6230},
  doi = {10.1080/00224065.2018.1507560},
  url = {https://www.tandfonline.com/doi/full/10.1080/00224065.2018.1507560},
  urldate = {2020-07-04},
  abstract = {With the improvement of data-acquisition technology, big data streams that involve continuous observations with high dimensionality and large volume frequently appear in modern applications, which poses significant challenges for statistical process control. In this article we consider the problem of online monitoring a class of big data streams where each data stream is associated with a spatial location. Our goal is to quickly detect shifts occurring in such big data streams when only partial information can be observed at each time and the out-of-control variables are clustered in a small and unknown region. To achieve this goal, we propose a novel spatial-adaptive sampling and monitoring (SASAM) procedure that aims to leverage the spatial information of the data streams for quick change detection. Specifically, the proposed sampling strategy will adaptively and intelligently integrate two seemingly contradictory ideas: (1) random sampling that quickly searches for possible out-of-control variables; and (2) directional sampling that focuses on highly suspicious outof-control variables that may cluster in a small region. Simulation and real case studies show that the proposed method significantly outperforms the existing sampling strategy without taking the spatial information of the data streams into consideration.},
  file = {/Users/hyan46/Dropbox (ASU)/ZoteroData/Wang et al_2018_A spatial-adaptive sampling procedure for online monitoring of big data streams.pdf},
  keywords = {Application: Solar Flare,Method: Adaptive Sampling,People: Kaibo Liu,Problem: Process Monitoring},
  langid = {english},
  number = {4}
}

@article{wangSpatiotemporal2020,
  title = {Spatiotemporal {{Multitask Learning}} for 3-{{D Dynamic Field Modeling}}},
  author = {Wang, Di and Liu, Kaibo and Zhang, Xi and Wang, Hui},
  date = {2020-04},
  journaltitle = {IEEE Transactions on Automation Science and Engineering},
  shortjournal = {IEEE Trans. Automat. Sci. Eng.},
  volume = {17},
  pages = {708--721},
  issn = {1545-5955, 1558-3783},
  doi = {10.1109/TASE.2019.2941736},
  url = {https://ieeexplore.ieee.org/document/8883059/},
  urldate = {2020-07-04},
  file = {/Users/hyan46/Dropbox (ASU)/ZoteroData/Wang et al_2020_Spatiotemporal Multitask Learning for 3-D Dynamic Field Modeling.pdf},
  keywords = {Method: Functional,Method: Kernel,Method: Spatio-temporal,Method: Transfer Learning,People: Kaibo Liu},
  langid = {english},
  number = {2}
}

@article{wangSpatiotemporal2020a,
  title = {Spatiotemporal {{Thermal Field Modeling Using Partial Differential Equations With Time}}-{{Varying Parameters}}},
  author = {Wang, Di and Liu, Kaibo and Zhang, Xi},
  date = {2020-04},
  journaltitle = {IEEE Transactions on Automation Science and Engineering},
  shortjournal = {IEEE Trans. Automat. Sci. Eng.},
  volume = {17},
  pages = {646--657},
  issn = {1545-5955, 1558-3783},
  doi = {10.1109/TASE.2019.2940269},
  url = {https://ieeexplore.ieee.org/document/8852843/},
  urldate = {2020-07-04},
  abstract = {Accurate modeling of a thermal field is one of the fundamental requirements in engineering thermal management in numerous industries. Existing studies have shown that using differential equations to model a thermal field delivers good performance when the parameters are predetermined through physical or experimental analysis. However, due to variations of the inner medium affected by certain latent factors, the parameters in differential equation models may not be treated as constants while the thermal field is estimated, and this fact poses a new challenge to field estimation by directly solving the differential equation models. In this study, a novel approach to thermal field modeling is developed by considering the parameters as functional variables that vary temporally in partial differential equations (PDEs). This approach provides a new perspective to model the dynamic thermal field by fully using the collected sensor data from the thermal system. Specifically, time-varying parameters can be constructed through a combination of basis functions whose coefficients can be efficiently estimated through the sensor data. A two-level iterative parameter estimation algorithm is also tailored to obtain the parameters in the PDE model. Both simulation and real case studies show that our proposed approach provides satisfactory estimation performance compared with the benchmark method that uses the constant parameter estimation.},
  file = {/Users/hyan46/Dropbox (ASU)/ZoteroData/Wang et al_2020_Spatiotemporal Thermal Field Modeling Using Partial Differential Equations With.pdf},
  keywords = {Method: Functional,Method: Physics,Method: Spatio-temporal,People: Kaibo Liu},
  langid = {english},
  number = {2}
}

@article{wangSystem2020,
  title = {System Inference for the Spatio-Temporal Evolution of Infectious Diseases: {{Michigan}} in the Time of {{COVID}}-19},
  shorttitle = {System Inference for the Spatio-Temporal Evolution of Infectious Diseases},
  author = {Wang, Z. and Zhang, X. and Teichert, G. H. and Carrasco-Teja, M. and Garikipati, K.},
  date = {2020-11},
  journaltitle = {Computational Mechanics},
  shortjournal = {Comput Mech},
  volume = {66},
  pages = {1153--1176},
  issn = {0178-7675, 1432-0924},
  doi = {10.1007/s00466-020-01894-2},
  url = {http://link.springer.com/10.1007/s00466-020-01894-2},
  urldate = {2021-01-15},
  abstract = {We extend the classical SIR model of infectious disease spread to account for time dependence in the parameters, which also include diffusivities. The temporal dependence accounts for the changing characteristics of testing, quarantine and treatment protocols, while diffusivity incorporates a mobile population. This model has been applied to data on the evolution of the COVID-19 pandemic in the US state of Michigan. For system inference, we use recent advances; specifically our framework for Variational System Identification (Wang et al., Comp. Meth. App. Mech. Eng., 356, 44-74, 2019; arXiv:2001.04816 [cs.CE]) as well as Bayesian machine learning methods.},
  file = {/Users/hyan46/Zotero/storage/BZPNMY7Y/Wang et al. - 2020 - System inference for the spatio-temporal evolution.pdf},
  langid = {english},
  number = {5}
}

@article{wangThresholded2018,
  title = {Thresholded {{Multivariate Principal Component Analysis}} for {{Phase I Multichannel Profile Monitoring}}},
  author = {Wang, Yuan and Mei, Yajun and Paynabar, Kamran},
  date = {2018-07-03},
  journaltitle = {Technometrics},
  shortjournal = {Technometrics},
  volume = {60},
  pages = {360--372},
  issn = {0040-1706, 1537-2723},
  doi = {10.1080/00401706.2017.1375993},
  url = {https://www.tandfonline.com/doi/full/10.1080/00401706.2017.1375993},
  urldate = {2020-07-07},
  abstract = {Monitoring multichannel profiles has important applications in manufacturing systems improvement, but it is nontrivial to develop efficient statistical methods because profiles are high-dimensional functional data with intrinsic inner- and interchannel correlations, and that the change might only affect a few unknown features of multichannel profiles. To tackle these challenges, we propose a novel thresholded multivariate principal component analysis (PCA) method for multichannel profile monitoring. Our proposed method consists of two steps of dimension reduction: It first applies the functional PCA to extract a reasonably large number of features under the in-control state, and then uses the soft-thresholding techniques to further select significant features capturing profile information under the out-of-control state. The choice of tuning parameter for soft-thresholding is provided based on asymptotic analysis, and extensive numerical studies are conducted to illustrate the efficacy of our proposed thresholded PCA methodology.},
  file = {/Users/hyan46/Dropbox (ASU)/ZoteroData/Wang et al_2018_Thresholded Multivariate Principal Component Analysis for Phase I Multichannel.pdf},
  langid = {english},
  number = {3}
}

@article{wangWafer2019,
  title = {Wafer {{Map Defect Pattern Recognition Using Rotation}}-{{Invariant Features}}},
  author = {Wang, Rui and Chen, Nan},
  date = {2019-11},
  journaltitle = {IEEE Transactions on Semiconductor Manufacturing},
  volume = {32},
  pages = {596--604},
  issn = {1558-2345},
  doi = {10.1109/TSM.2019.2944181},
  abstract = {In semiconductor manufacturing, the patterns on the wafer map provide important information for engineers to identify the root causes of production problems. The detection and recognition of wafer map patterns is thus an important issue in semiconductor industry. Automatic techniques are required to cut down on cost and to improve accuracy. In this study, we propose an approach to recognize patterns in the wafer maps which uses the extracted features based on the proposed weight masks. The proposed masks contain three types, namely, polar masks, line masks and arc masks. Polar masks aim to extract features of concentric patterns, while line and arc masks are designed to mainly deal with eccentric patterns like scratches. These masks can be applied to extract rotation-invariant features for the classification of the defect patterns. To demonstrate the effectiveness of our model, we apply the method to a real-world wafer map dataset. Comparisons with alternative methods show superiority of our method in the task of wafer map defect pattern recognition.},
  eventtitle = {{{IEEE Transactions}} on {{Semiconductor Manufacturing}}},
  file = {/Users/hyan46/Dropbox (ASU)/ZoteroData/Wang_Chen_2019_Wafer Map Defect Pattern Recognition Using Rotation-Invariant Features2.pdf},
  keywords = {Application: Manufacturing,Application: Semiconductor,Method: Classification,People: Chen Nan,Problem: Classification},
  number = {4}
}

@article{weiRealtime2016,
  title = {Real-Time Process Monitoring Using Kernel Distances},
  author = {Wei, Qingming and Huang, Wenpo and Jiang, Wei and Zhao, Wenhui},
  date = {2016-11},
  journaltitle = {International Journal of Production Research},
  shortjournal = {International Journal of Production Research},
  volume = {54},
  pages = {6563--6578},
  issn = {0020-7543, 1366-588X},
  doi = {10.1080/00207543.2016.1173257},
  url = {https://www.tandfonline.com/doi/full/10.1080/00207543.2016.1173257},
  urldate = {2020-07-04},
  file = {/Users/hyan46/Dropbox (ASU)/ZoteroData/Wei et al_2016_Real-time process monitoring using kernel distances.pdf},
  keywords = {Application: Wine,Method: Functional,Method: Kernel,People: Wei Jiang,Problem: Process Monitoring},
  langid = {english},
  number = {21}
}

@article{wilkinsRecurrence2011,
  title = {Recurrence {{Time Ratio Slope}} ({{RTRS}}) to Estimate Nonstationarity in Dynamic Nonlinear Heart Rate Variability Signals},
  author = {Wilkins, B. and Bukkapatnam, Satish and Komanduri, R. and Benjamin, B. A.},
  date = {2011-04},
  journaltitle = {Faseb Journal},
  shortjournal = {Faseb J Faseb J},
  volume = {25},
  issn = {0892-6638},
  url = {://WOS:000310708401624},
  langid = {english}
}

@article{wuAdaptive2021,
  title = {Adaptive {{Change Point Monitoring}} for {{High}}-{{Dimensional Data}}},
  author = {Wu, Teng and Wang, Runmin and Yan, Hao and Shao, Xiaofeng},
  date = {2021},
  journaltitle = {Statistica Sinica},
  doi = {10.5705/ss.202020.0438},
  url = {http://arxiv.org/abs/2101.06839},
  urldate = {2021-01-27},
  abstract = {In this paper, we propose a class of monitoring statistics for a mean shift in a sequence of high-dimensional observations. Inspired by the recent U-statistic based retrospective tests developed by Wang et al. (2019) and Zhang et al. (2020), we advance the U-statistic based approach to the sequential monitoring problem by developing a new adaptive monitoring procedure that can detect both dense and sparse changes in real time. Unlike Wang et al. (2019) and Zhang et al. (2020), where self-normalization was used in their tests, we instead introduce a class of estimators for q-norm of the covariance matrix and prove their ratio consistency. To facilitate fast computation, we further develop recursive algorithms to improve the computational efficiency of the monitoring procedure. The advantage of the proposed methodology is demonstrated via simulation studies and real data illustrations.},
  archiveprefix = {arXiv},
  eprint = {2101.06839},
  eprinttype = {arxiv},
  file = {/Users/hyan46/Dropbox (ASU)/ZoteroData/Wu et al_2021_Adaptive Change Point Monitoring for High-Dimensional Data.pdf},
  keywords = {Data: Sigmal,Problem: Process Monitoring},
  langid = {english}
}

@online{wuFault2014,
  title = {Fault {{Detection}} and {{Diagnosis}} in {{Process Data Using Support Vector Machines}}},
  author = {Wu, Fang and Yin, Shen and Karimi, Hamid Reza},
  date = {2014},
  volume = {2014},
  pages = {e732104},
  publisher = {{Hindawi}},
  issn = {1110-757X},
  doi = {10.1155/2014/732104},
  url = {https://www.hindawi.com/journals/jam/2014/732104/},
  urldate = {2020-05-25},
  abstract = {For the complex industrial process, it has become increasingly challenging to effectively diagnose complicated faults. In this paper, a combined measure of the original Support Vector Machine (SVM) and Principal Component Analysis (PCA) is provided to carry out the fault classification, and compare its result with what is based on SVM-RFE (Recursive Feature Elimination) method. RFE is used for feature extraction, and PCA is utilized to project the original data onto a lower dimensional space. PCA , SPE statistics, and original SVM are proposed to detect the faults. Some common faults of the Tennessee Eastman Process (TEP) are analyzed in terms of the practical system and reflections of the dataset. PCA-SVM and SVM-RFE can effectively detect and diagnose these common faults. In RFE algorithm, all variables are decreasingly ordered according to their contributions. The classification accuracy rate is improved by choosing a reasonable number of features.},
  file = {/Users/hyan46/Zotero/storage/WLLL5U2Q/732104.html},
  keywords = {Method: Classification,Problem: Classification},
  langid = {english},
  organization = {{Journal of Applied Mathematics}},
  type = {Research Article}
}

@article{wuGraphene2014,
  title = {Graphene Growth Process Modeling: A Physical–Statistical Approach},
  shorttitle = {Graphene Growth Process Modeling},
  author = {Wu, Jian and Huang, Qiang},
  date = {2014-09},
  journaltitle = {Applied Physics A},
  shortjournal = {Appl. Phys. A},
  volume = {116},
  pages = {1747--1756},
  issn = {0947-8396, 1432-0630},
  doi = {10.1007/s00339-014-8320-8},
  url = {http://link.springer.com/10.1007/s00339-014-8320-8},
  urldate = {2020-07-04},
  abstract = {As a zero-band semiconductor, graphene is an attractive material for a wide variety of applications such as optoelectronics. Among various techniques developed for graphene synthesis, chemical vapor deposition on copper foils shows high potential for producing few-layer and large-area graphene. Since fabrication of high-quality graphene sheets requires the understanding of growth mechanisms, and methods of characterization and control of grain size of graphene flakes, analytical modeling of graphene growth process is therefore essential for controlled fabrication. The graphene growth process starts with randomly nucleated islands that gradually develop into complex shapes, grow in size, and eventually connect together to cover the copper foil. To model this complex process, we develop a physical–statistical approach under the assumption of self-similarity during graphene growth. The growth kinetics is uncovered by separating island shapes from area growth rate. We propose to characterize the area growth velocity using a confined exponential model, which not only has clear physical explanation, but also fits the real data well. For the shape modeling, we develop a parametric shape model which can be well explained by the angular-dependent growth rate. This work can provide useful information for the control and optimization of graphene growth process on Cu foil.},
  file = {/Users/hyan46/Dropbox (ASU)/ZoteroData/Wu_Huang_2014_Graphene growth process modeling.pdf},
  keywords = {Application: Manufacturing,Application: Semiconductor,Method: Physics,People: Qiang Huang},
  langid = {english},
  number = {4}
}

@article{xianCausationBased2019,
  title = {Causation-{{Based Monitoring}} and {{Diagnosis}} for {{Multivariate Categorical Processes With Ordinal Information}}},
  author = {Xian, Xiaochen and Li, Jian and Liu, Kaibo},
  date = {2019-04},
  journaltitle = {IEEE Transactions on Automation Science and Engineering},
  shortjournal = {IEEE Trans. Automat. Sci. Eng.},
  volume = {16},
  pages = {886--897},
  issn = {1545-5955, 1558-3783},
  doi = {10.1109/TASE.2018.2873365},
  url = {https://ieeexplore.ieee.org/document/8509178/},
  urldate = {2020-07-04},
  abstract = {The monitoring and diagnosis of multivariate categorical processes (MCPs) have drawn increasing attention lately, as categorical variables have been frequently involved in modern quality control applications. In these applications, there may exist causal relationships among multiple categorical variables, where the attribute level of a cause variable influences that of its effect variable. In such a case, shifts occurring in a cause variable will propagate to its effect variable based on the causal structure. Furthermore, there usually exists natural order among the attribute levels of some categorical variables such as good, neutral, and bad for measuring the product quality. By assuming a latent continuous variable, the attribute levels of an ordinal categorical variable can be determined by classifying the value of the latent variable based on thresholds. In this paper, we leverage Bayesian networks (BNs) to characterize MCPs with a causal structure, where the categorical variables can be either nominal, ordinal or a combination of both. We develop one general control chart and one directional control chart, both of which fully exploit the causal relationships and the ordinal information for better process monitoring and diagnosis. Numerical simulations have demonstrated the superiority and robustness of our method in detecting and diagnosing the conditional probability shifts of nominal factors as well as the conditional latent location shifts of ordinal factors.},
  file = {/Users/hyan46/Dropbox (ASU)/ZoteroData/Xian et al_2019_Causation-Based Monitoring and Diagnosis for Multivariate Categorical Processes.pdf},
  keywords = {Application: Rolling,Method: Causal,People: Kaibo Liu,Problem: Process Monitoring},
  langid = {english},
  number = {2}
}

@article{xianEffective2019,
  title = {An Effective Online Data Monitoring and Saving Strategy for Large-Scale Climate Simulations},
  author = {Xian, Xiaochen and Archibald, Rick and Mayer, Benjamin and Liu, Kaibo and Li, Jian},
  date = {2019-05-04},
  journaltitle = {Quality Technology \& Quantitative Management},
  shortjournal = {Quality Technology \& Quantitative Management},
  volume = {16},
  pages = {330--346},
  issn = {1684-3703},
  doi = {10.1080/16843703.2017.1414112},
  url = {https://www.tandfonline.com/doi/full/10.1080/16843703.2017.1414112},
  urldate = {2020-07-04},
  file = {/Users/hyan46/Dropbox (ASU)/ZoteroData/Xian et al_2019_An effective online data monitoring and saving strategy for large-scale climate.pdf},
  keywords = {Application: Weather,Method: Adaptive Sampling,People: Kaibo Liu,Problem: Process Monitoring},
  langid = {english},
  number = {3}
}

@inproceedings{xianFeature2018,
  title = {Feature {{Generating Networks}} for {{Zero}}-{{Shot Learning}}},
  booktitle = {2018 {{IEEE}}/{{CVF Conference}} on {{Computer Vision}} and {{Pattern Recognition}}},
  author = {Xian, Yongqin and Lorenz, Tobias and Schiele, Bernt and Akata, Zeynep},
  date = {2018-06},
  pages = {5542--5551},
  publisher = {{IEEE}},
  location = {{Salt Lake City, UT}},
  doi = {10.1109/CVPR.2018.00581},
  url = {https://ieeexplore.ieee.org/document/8578679/},
  urldate = {2021-06-17},
  abstract = {Suffering from the extreme training data imbalance between seen and unseen classes, most of existing state-of-theart approaches fail to achieve satisfactory results for the challenging generalized zero-shot learning task. To circumvent the need for labeled examples of unseen classes, we propose a novel generative adversarial network (GAN) that synthesizes CNN features conditioned on class-level semantic information, offering a shortcut directly from a semantic descriptor of a class to a class-conditional feature distribution. Our proposed approach, pairing a Wasserstein GAN with a classification loss, is able to generate sufficiently discriminative CNN features to train softmax classifiers or any multimodal embedding method. Our experimental results demonstrate a significant boost in accuracy over the state of the art on five challenging datasets – CUB, FLO, SUN, AWA and ImageNet – in both the zero-shot learning and generalized zero-shot learning settings.},
  eventtitle = {2018 {{IEEE}}/{{CVF Conference}} on {{Computer Vision}} and {{Pattern Recognition}} ({{CVPR}})},
  file = {/Users/hyan46/Zotero/storage/XGTBNH3N/Xian et al. - 2018 - Feature Generating Networks for Zero-Shot Learning.pdf},
  isbn = {978-1-5386-6420-9},
  langid = {english}
}

@article{xiangChange2020,
  title = {Change Detection of Profile with Jumps and Its Application to {{3D}} Printing},
  author = {Xiang, Dongdong and Tsung, Fugee and Pu, Xiaolong and Li, Wendong},
  date = {2020-01},
  journaltitle = {Computers \& Industrial Engineering},
  shortjournal = {Computers \& Industrial Engineering},
  volume = {139},
  pages = {106198},
  issn = {03608352},
  doi = {10.1016/j.cie.2019.106198},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0360835219306679},
  urldate = {2020-07-20},
  abstract = {Three-dimensional (3D) printing, or additive manufacturing, is widely accepted as a disruptive technology, and becomes increasingly popular in manufacturing industries in recent years. As a result, quality control of 3D printing is crucial to improve the quality of products. In this paper, motivated by a novel 3D printing application with fused deposition modeling, we propose a change detection procedure for monitoring profile data with jumps that represents regular structural changes at certain positions. Jumps along with phase variability make profile monitoring challenging because it is hard to combine information in different profiles properly. First, jumps detection procedures are developed by using jump regression analysis technique. After the jumps are detected, a novel piecewise profile registration procedure is suggested to eliminate phase variability. The key information on jumps, profile registration, and the registered profiles is then integrated into an exponentially weighted moving average charting scheme. We use simulation studies and a real-data analysis to show the efficiency of the proposed control chart.},
  file = {/Users/hyan46/Dropbox (ASU)/ZoteroData/Xiang et al_2020_Change detection of profile with jumps and its application to 3D printing.pdf},
  keywords = {Application: Additive Manufacturing,Method: Functional,Method: Kernel,Problem: Process Monitoring},
  langid = {english}
}

@inproceedings{xiangOptimization2014,
  title = {Optimization of Fatigue Maintenance Strategies Based on Prognosis Results},
  booktitle = {2011 {{Annual Conference}} of the {{Prognostics}} and {{Health Management Society}}, {{PHM}} 2011},
  author = {Xiang, Yibing and Liu, Yongming},
  date = {2014},
  pages = {398--408},
  publisher = {{Prognostics and Health Management Society}}
}

@article{xianNonparametric2018,
  title = {A {{Nonparametric Adaptive Sampling Strategy}} for {{Online Monitoring}} of {{Big Data Streams}}},
  author = {Xian, Xiaochen and Wang, Andi and Liu, Kaibo},
  date = {2018-01-02},
  journaltitle = {Technometrics},
  shortjournal = {Technometrics},
  volume = {60},
  pages = {14--25},
  issn = {0040-1706, 1537-2723},
  doi = {10.1080/00401706.2017.1317291},
  url = {https://www.tandfonline.com/doi/full/10.1080/00401706.2017.1317291},
  urldate = {2020-07-04},
  abstract = {With the rapid advancement of sensor technology, a huge amount of data is generated in various applications, which poses new and unique challenges for statistical process control (SPC). In this article, we propose a nonparametric adaptive sampling (NAS) strategy to online monitor nonnormal big data streams in the context of limited resources, where only a subset of observations are available at each acquisition time. In particular, this proposed method integrates a rank-based CUSUM scheme and an innovative idea that corrects the anti-rank statistics with partial observations, which can effectively detect a wide range of possible mean shifts when data streams are exchangeable and follow arbitrary distributions. Two theoretical properties on the sampling layout of the proposed NAS algorithm are investigated when the process is in control and out of control. Both simulations and case studies are conducted under different scenarios to illustrate and evaluate the performance of the proposed method. Supplementary materials for this article are available online.},
  file = {/Users/hyan46/Dropbox (ASU)/ZoteroData/Xian et al_2018_A Nonparametric Adaptive Sampling Strategy for Online Monitoring of Big Data.pdf},
  keywords = {Application: Solar Flare,Method: Adaptive Sampling,People: Kaibo Liu,Problem: Process Monitoring},
  langid = {english},
  number = {1}
}

@article{xianOnline2019,
  title = {Online Monitoring of Big Data Streams: {{A}} Rank-Based Sampling Algorithm by Data Augmentation},
  shorttitle = {Online Monitoring of Big Data Streams},
  author = {Xian, Xiaochen and Zhang, Chen and Bonk, Scott and Liu, Kaibo},
  date = {2019-11-18},
  journaltitle = {Journal of Quality Technology},
  shortjournal = {Journal of Quality Technology},
  pages = {1--19},
  issn = {0022-4065, 2575-6230},
  doi = {10.1080/00224065.2019.1681924},
  url = {https://www.tandfonline.com/doi/full/10.1080/00224065.2019.1681924},
  urldate = {2020-07-04},
  abstract = {In many applications of modern quality control, process monitoring involves a large number of process variables and quality characteristics. Practitioners are desired to attain complete information about the process in order to assure quick detection of shifts that may possibly occur at any variable. However, full information is not always available during online monitoring of big data streams due to limitations of monitoring resources in practice. In this paper, a rank-based monitoring and sampling algorithm based on data augmentation is proposed to quickly detect the mean shifts in a process when only a limited portion of observations are available online. Specifically, at each observation time, the proposed method will automatically augment information for unobservable variables based on the online observations, and then intelligently allocate the monitoring resources to the most suspicious data streams. Comparing to the existing literature, this method is able to accurately infer the status of all variables in a process based on a small number of observable variables and effectively construct a global monitoring statistic with the proposed augmented vector, which leads to a quick detection of the out-of-control status even if limited shifted variables are observed in real time. Simulation studies as well as a real case study on real-time solar flare detection are conducted to demonstrate the efficacy and applicability of the proposed method.},
  file = {/Users/hyan46/Dropbox (ASU)/ZoteroData/Xian et al_2019_Online monitoring of big data streams.pdf},
  keywords = {Application: Solar Flare,Method: Adaptive Sampling,Method: CUSUM,People: Kaibo Liu,Problem: Process Monitoring},
  langid = {english}
}

@article{xianSpatiotemporal2020,
  title = {Spatiotemporal {{Modeling}} and {{Real}}-{{Time Prediction}} of {{Origin}}-{{Destination Traffic Demand}}},
  author = {Xian, Xiaochen and Ye, Honghan and Wang, Xin and Liu, Kaibo},
  date = {2020-01-22},
  journaltitle = {Technometrics},
  shortjournal = {Technometrics},
  pages = {1--13},
  issn = {0040-1706, 1537-2723},
  doi = {10.1080/00401706.2019.1704887},
  url = {https://www.tandfonline.com/doi/full/10.1080/00401706.2019.1704887},
  urldate = {2020-07-04},
  abstract = {Traffic demand prediction has been a crucial problem for the planning, scheduling, and optimization in transportation management. The prediction of traffic demand counts for origin-destination (OD) pairs has been considered challenging due to the high variability and complicated spatiotemporal correlations in the data. Though several articles have considered estimating traffic flows from counts observed at specific locations, existing traffic prediction models seldom dealt with spatiotemporal demand count data of certain OD pairs, or they failed to effectively consider domain knowledge of the traffic network to enhance the prediction accuracy of traffic demand. To tackle the aforementioned challenges, we formulate and propose a multivariate Poisson log-normal model with specific parameterization tailored to the traffic demand problem, which captures the spatiotemporal correlations of the traffic demand across different routes and epochs, and automatically clusters the routes based on the demand correlations. The model is further estimated using an expectation-maximization algorithm and applied for predicting future demand counts at the subsequent epochs. The estimation and prediction procedures incorporate Markov chain Monte Carlo sampling to overcome the computational challenges. Simulations as well as a real application on a New York yellow taxi data are performed to demonstrate the applicability and effectiveness of the proposed method. Supplementary materials for this article are available online.},
  file = {/Users/hyan46/Dropbox (ASU)/ZoteroData/Xian et al_2020_Spatiotemporal Modeling and Real-Time Prediction of Origin-Destination Traffic.pdf},
  keywords = {Application: Traffic,Method: Latent,Method: Spatio-temporal,People: Kaibo Liu},
  langid = {english}
}

@article{xianZeroShot2019,
  title = {Zero-{{Shot Learning}}—{{A Comprehensive Evaluation}} of the {{Good}}, the {{Bad}} and the {{Ugly}}},
  author = {Xian, Yongqin and Lampert, Christoph H. and Schiele, Bernt and Akata, Zeynep},
  date = {2019-09-01},
  journaltitle = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
  shortjournal = {IEEE Trans. Pattern Anal. Mach. Intell.},
  volume = {41},
  pages = {2251--2265},
  issn = {0162-8828, 2160-9292, 1939-3539},
  doi = {10.1109/TPAMI.2018.2857768},
  url = {https://ieeexplore.ieee.org/document/8413121/},
  urldate = {2021-06-04},
  abstract = {Due to the importance of zero-shot learning, i.e., classifying images where there is a lack of labeled training data, the number of proposed approaches has recently increased steadily. We argue that it is time to take a step back and to analyze the status quo of the area. The purpose of this paper is three-fold. First, given the fact that there is no agreed upon zero-shot learning benchmark, we first define a new benchmark by unifying both the evaluation protocols and data splits of publicly available datasets used for this task. This is an important contribution as published results are often not comparable and sometimes even flawed due to, e.g., pre-training on zero-shot test classes. Moreover, we propose a new zero-shot learning dataset, the Animals with Attributes 2 (AWA2) dataset which we make publicly available both in terms of image features and the images themselves. Second, we compare and analyze a significant number of the state-of-the-art methods in depth, both in the classic zero-shot setting but also in the more realistic generalized zero-shot setting. Finally, we discuss in detail the limitations of the current status of the area which can be taken as a basis for advancing it.},
  file = {/Users/hyan46/Dropbox (ASU)/ZoteroData/Xian et al_2019_Zero-Shot Learning—A Comprehensive Evaluation of the Good, the Bad and the Ugly.pdf},
  langid = {english},
  number = {9}
}

@article{xiaoOptimal2018,
  title = {Optimal {{Expert Knowledge Elicitation}} for {{Bayesian Network Structure Identification}}},
  author = {Xiao, Cao and Jin, Yan and Liu, Ji and Zeng, Bo and Huang, Shuai},
  date = {2018-07},
  journaltitle = {IEEE Transactions on Automation Science and Engineering},
  shortjournal = {IEEE Trans. Automat. Sci. Eng.},
  volume = {15},
  pages = {1163--1177},
  issn = {1545-5955, 1558-3783},
  doi = {10.1109/TASE.2017.2747130},
  url = {https://ieeexplore.ieee.org/document/8304661/},
  urldate = {2020-07-04},
  abstract = {Bayesian network (BN) has been a popular tool for gaining mechanistic understanding of variables by revealing how the variables influence each other. It has been found very effective in a few studies in quality control and process monitoring. However, for complex problems where the structure of a BN is unknown, a common approach is to learn the BN structure from observational data. A fundamental bottleneck of this approach is that observational data can only be used to discover part of the influential relationships among variables. To overcome this problem, we propose to combine observational data and expert knowledge. To the best of the author’s knowledge, our approach is the first of its kind that formulates an experimental design framework to automate the expert elicitation process and collect the most informative expert knowledge, optimally matched to the observational data, to learn the BN structure.},
  file = {/Users/hyan46/Dropbox (ASU)/ZoteroData/Xiao et al_2018_Optimal Expert Knowledge Elicitation for Bayesian Network Structure.pdf},
  keywords = {Application: Health,Method: Causal,People: Shuai Huang,Problem: Process Monitoring},
  langid = {english},
  number = {3}
}

@article{xuEM2013,
  title = {{{EM Estimation}} of {{Nanostructure Interactions With Incomplete Feature Measurement}} and {{Its Tailored Space Filling Designs}}},
  author = {Xu, Lijuan and Huang, Qiang},
  date = {2013-07},
  journaltitle = {IEEE Transactions on Automation Science and Engineering},
  shortjournal = {IEEE Trans. Automat. Sci. Eng.},
  volume = {10},
  pages = {579--587},
  issn = {1545-5955, 1558-3783},
  doi = {10.1109/TASE.2013.2245120},
  url = {http://ieeexplore.ieee.org/document/6471785/},
  urldate = {2020-07-04},
  abstract = {Automatic assessment of nanostructure quality is essential for scale-up nanomanufacturing. In our previous work, we have developed a method to quantify nanostructure growth quality and detect structural defects through interaction analysis. However, because the method builds on complete feature measurement, its direct application to nanomanufacturing systems is severely constrained by nanostructure metrology. For current inspection techniques such as scanning electron microscope (SEM), the major difficulties of measuring nanostructures lie in two aspects: (i) taking and calibrating images for seamless coverage and (ii) extracting and matching feature information from the images. In this paper, we develop a tailored sampling strategy to relax the metrology constraint. It not only explores the growth region with greatly reduced metrology efforts but maintains desired sampling resolution. In addition, we customize Expectation-Maximization algorithm to optimize interaction estimation with corresponding “incomplete” measurement. Our developed approach enables nanostructure characterization within manufacturing relevant time spans and thus provides a supporting tool for nanomanufacturing.},
  file = {/Users/hyan46/Dropbox (ASU)/ZoteroData/Xu_Huang_2013_EM Estimation of Nanostructure Interactions With Incomplete Feature Measurement.pdf},
  keywords = {Application: Manufacturing,Application: Nano,People: Qiang Huang},
  langid = {english},
  number = {3}
}

@article{xuGrowth2014,
  title = {Growth {{Process Modeling}} of {{III}}–{{V Nanowire Synthesis}} via {{Selective Area Metal}}–{{Organic Chemical Vapor Deposition}}},
  author = {Xu, Lijuan and Huang, Qiang},
  date = {2014-11},
  journaltitle = {IEEE Transactions on Nanotechnology},
  shortjournal = {IEEE Trans. Nanotechnology},
  volume = {13},
  pages = {1093--1101},
  issn = {1536-125X, 1941-0085},
  doi = {10.1109/TNANO.2014.2320454},
  url = {http://ieeexplore.ieee.org/document/6805652/},
  urldate = {2020-07-04},
  abstract = {While selective area metal–organic chemical vapor deposition has been widely recognized as a promising nanowire fabrication technique, its growth mechanism still remains indecisive in the literature. There are active debates on the effects of various process parameters on nanowire growth. In this paper, we attempt to establish a growth process model that coherently explains various growth patterns observed in experiments. By quantifying contributions from various diffusion sources, the model not only confirms the synthesis mechanism, but also explains the spatial and temporal patterns of nanowire growth. The model sets the basis for systematic process optimization and control.},
  file = {/Users/hyan46/Dropbox (ASU)/ZoteroData/Xu_Huang_2014_Growth Process Modeling of III–V Nanowire Synthesis via Selective Area.pdf},
  keywords = {Application: Manufacturing,Application: Nano,People: Qiang Huang},
  langid = {english},
  number = {6}
}

@article{xuModeling2012,
  title = {Modeling the {{Interactions Among Neighboring Nanostructures}} for {{Local Feature Characterization}} and {{Defect Detection}}},
  author = {Xu, Lijuan and Huang, Qiang},
  date = {2012-10},
  journaltitle = {IEEE Transactions on Automation Science and Engineering},
  shortjournal = {IEEE Trans. Automat. Sci. Eng.},
  volume = {9},
  pages = {745--754},
  issn = {1545-5955, 1558-3783},
  doi = {10.1109/TASE.2012.2209417},
  url = {http://ieeexplore.ieee.org/document/6269088/},
  urldate = {2020-07-04},
  abstract = {Since properties of nanomaterials are determined by their structures, characterizing nanostructure feature variability and diagnosing structure defects are of great importance for quality control in scale-up nanomanufacturing. It is known that nanostructure interactions such as competing for source materials during growth contribute strongly to nanostructure uniformity and defect formation. However, there is a lack of rigorous formulation to describe nanostructure interactions and their effects on nanostructure variability. In this work, we develop a method to relate local nanostructure variability (quality measure) to nanostructure interactions under the framework of Gaussian Markov random field. With the developed modeling and estimation approaches, we are able to extract nanostructure interactions for any local region with or without defects based on its feature measurement. The established connection between nanostructure variability and interactions not only provides a metric for assessing nanostructure quality, but also enables a method to automatically detect defects and identify their patterns based on the underlying interaction patterns. Both simulation and real case studies are conducted to demonstrate the developed methods. The insights obtained from real case study agree with physical understanding.},
  file = {/Users/hyan46/Dropbox (ASU)/ZoteroData/Xu_Huang_2012_Modeling the Interactions Among Neighboring Nanostructures for Local Feature.pdf},
  keywords = {Application: Manufacturing,Application: Nano,People: Qiang Huang},
  langid = {english},
  number = {4}
}

@inproceedings{xuOnline2018,
  title = {Online {{Continuous}}-{{Time Tensor Factorization Based}} on {{Pairwise Interactive Point Processes}}},
  booktitle = {Proceedings of the {{Twenty}}-{{Seventh International Joint Conference}} on {{Artificial Intelligence}}},
  author = {Xu, Hongteng and Luo, Dixin and Carin, Lawrence},
  date = {2018-07},
  pages = {2905--2911},
  publisher = {{International Joint Conferences on Artificial Intelligence Organization}},
  location = {{Stockholm, Sweden}},
  doi = {10.24963/ijcai.2018/403},
  url = {https://www.ijcai.org/proceedings/2018/403},
  urldate = {2020-08-08},
  abstract = {A continuous-time tensor factorization method is developed for event sequences containing multiple “modalities.” Each data element is a point in a tensor, whose dimensions are associated with the discrete alphabet of the modalities. Each tensor data element has an associated time of occurence and a feature vector. We model such data based on pairwise interactive point processes, and the proposed framework connects pairwise tensor factorization with a feature-embedded point process. The model accounts for interactions within each modality, interactions across different modalities, and continuous-time dynamics of the interactions. Model learning is formulated as a convex optimization problem, based on online alternating direction method of multipliers. Compared to existing stateof-the-art methods, our approach captures the latent structure of the tensor and its evolution over time, obtaining superior results on real-world datasets.},
  eventtitle = {Twenty-{{Seventh International Joint Conference}} on {{Artificial Intelligence}} \{\vphantom\}{{IJCAI}}-18\vphantom\{\}},
  file = {/Users/hyan46/Dropbox (ASU)/ZoteroData/Xu et al_2018_Online Continuous-Time Tensor Factorization Based on Pairwise Interactive Point.pdf},
  isbn = {978-0-9992411-2-7},
  langid = {english}
}

@article{xuOnline2020,
  title = {Online {{Structural Change}}-Point {{Detection}} of {{High}}-Dimensional {{Streaming Data}} via {{Dynamic Sparse Subspace Learning}}},
  author = {Xu, Ruiyu and Wu, Jianguo and Yue, Xiaowei and Li, Yongxiang},
  date = {2020},
  pages = {31},
  abstract = {High-dimensional streaming data are becoming increasingly ubiquitous in many fields. They often lie in multiple low-dimensional subspaces, and the manifold structures may change abruptly on the time scale due to pattern shift or occurrence of anomalies. However, the problem of detecting the structural changes in a real-time manner has not been well studied. To fill this gap, we propose a dynamic sparse subspace learning (DSSL) approach for online structural change-point detection of high-dimensional streaming data. A novel multiple structural change-point model is proposed and it is shown to be equivalent to maximizing a posterior under certain conditions. The asymptotic properties of the estimators are investigated. The penalty coefficients in our model can be selected by AMDL criterion based on some historical data. An efficient Pruned Exact Linear Time (PELT) based method is proposed for online optimization and change-point detection. The effectiveness of the proposed method is demonstrated through a simulation study and a real case study using gesture data for motion tracking.},
  file = {/Users/hyan46/Zotero/storage/ZYPYBAT8/Xu et al. - Online Structural Change-point Detection of High-d.pdf},
  langid = {english}
}

@article{yanAnomaly2017,
  title = {Anomaly {{Detection}} in {{Images With Smooth Background}} via {{Smooth}}-{{Sparse Decomposition}}},
  author = {Yan, Hao and Paynabar, Kamran and Shi, Jianjun},
  date = {2017-01},
  journaltitle = {Technometrics},
  volume = {59},
  pages = {102--114},
  publisher = {{American Statistical Association}},
  issn = {15372723},
  doi = {10.1080/00401706.2015.1102764},
  abstract = {In various manufacturing applications such as steel, composites, and textile production, anomaly detection in noisy images is of special importance. Although there are several methods for image denoising and anomaly detection, most of these perform denoising and detection sequentially, which affects detection accuracy and efficiency. Additionally, the low computational speed of some of these methods is a limitation for real-time inspection. In this article, we develop a novel methodology for anomaly detection in noisy images with smooth backgrounds. The proposed method, named smooth-sparse decomposition, exploits regularized high-dimensional regression to decompose an image and separate anomalous regions by solving a large-scale optimization problem. To enable the proposed method for real-time implementation, a fast algorithm for solving the optimization model is proposed. Using simulations and a case study, we evaluate the performance of the proposed method and compare it with existing methods. Numerical results demonstrate the superiority of the proposed method in terms of the detection accuracy as well as computation time. This article has supplementary materials that includes all the technical details, proofs, MATLAB codes, and simulated images used in the article.},
  file = {/Users/hyan46/Dropbox (ASU)/ZoteroData/Yan et al_2017_Anomaly Detection in Images With Smooth Background via Smooth-Sparse2.pdf},
  keywords = {Application: Manufacturing,Application: Nano,Data: Image,Method: Functional,Method: Sparse,Problem: Anomaly Detection},
  number = {1}
}

@inproceedings{yang-mitchell-2016-joint,
  title = {Joint Extraction of Events and Entities within a Document Context},
  booktitle = {Proceedings of the 2016 Conference of the North {{American}} Chapter of the Association for Computational Linguistics: {{Human}} Language Technologies},
  author = {Yang, Bishan and Mitchell, Tom M.},
  date = {2016-06},
  pages = {289--299},
  publisher = {{Association for Computational Linguistics}},
  location = {{San Diego, California}},
  doi = {10.18653/v1/N16-1033},
  url = {https://www.aclweb.org/anthology/N16-1033}
}

@article{yangDifferential2016,
  title = {Differential Evolution-Based Feature Selection and Parameter Optimisation for Extreme Learning Machine in Tool Wear Estimation},
  author = {Yang, Wen-An and Zhou, Qiang and Tsui, Kwok-Leung},
  date = {2016-08-02},
  journaltitle = {International Journal of Production Research},
  shortjournal = {International Journal of Production Research},
  volume = {54},
  pages = {4703--4721},
  issn = {0020-7543, 1366-588X},
  doi = {10.1080/00207543.2015.1111534},
  url = {http://www.tandfonline.com/doi/full/10.1080/00207543.2015.1111534},
  urldate = {2020-07-07},
  file = {/Users/hyan46/Dropbox (ASU)/ZoteroData/Yang et al_2016_Differential evolution-based feature selection and parameter optimisation for.pdf},
  keywords = {Application: Milling,Method: Deep Learning,Method: Feature Engineering,Method: Kernel},
  langid = {english},
  number = {15}
}

@article{yangFailure2012,
  title = {Failure {{Profile Analysis}} of {{Complex Repairable Systems With Multiple Failure Modes}}},
  author = {Yang, Qingyu and Hong, Yili and Chen, Yong and Shi, Jianjun},
  date = {2012-03},
  journaltitle = {IEEE Transactions on Reliability},
  shortjournal = {IEEE Trans. Rel.},
  volume = {61},
  pages = {180--191},
  issn = {0018-9529, 1558-1721},
  doi = {10.1109/TR.2011.2182225},
  url = {http://ieeexplore.ieee.org/document/6142137/},
  urldate = {2020-07-04},
  file = {/Users/hyan46/Dropbox (ASU)/ZoteroData/Yang et al_2012_Failure Profile Analysis of Complex Repairable Systems With Multiple Failure.pdf},
  keywords = {Application: Chemical,Application: Manufacturing,Data: Profiles,Method: Functional,People: Chen Yong,Problem: Reliability},
  langid = {english},
  number = {1}
}

@article{yangHeterogeneous2020,
  title = {Heterogeneous Recurrence Analysis of Spatial Data},
  author = {Yang, Hui and Chen, Cheng-Bang and Kumara, Soundar},
  date = {2020-01},
  journaltitle = {Chaos},
  shortjournal = {Chaos},
  volume = {30},
  pages = {013119},
  issn = {1054-1500, 1089-7682},
  doi = {10.1063/1.5129959},
  url = {http://aip.scitation.org/doi/10.1063/1.5129959},
  urldate = {2020-07-07},
  abstract = {Nonlinear dynamical systems often generate significant amounts of observational data such as time series, as well as high-dimensional spatial data. To delineate recurrence dynamics in the spatial data, prior efforts either extended the recurrence plot, which is a widely used tool for time series, to a four-dimensional hyperspace or utilized the network approach for recurrence analysis. However, very little has been done to differentiate heterogeneous types of recurrences in the spatial data (e.g., recurrence variations of state transitions in the spatial domain). Therefore, we propose a novel heterogeneous recurrence approach for spatial data analysis. First, spatial data are traversed with the Hilbert Space-Filling Curve to transform the variations of recurrence patterns from the spatial domain to the state-space domain. Second, we design an Iterated Function System to derive the fractal representation for the state-space trajectory of spatial data. Such a fractal representation effectively captures self-similar behaviors of recurrence variations and multi-state transitions in the spatial data. Third, we develop the Heterogeneous Recurrence Quantification Analysis of spatial data. Experimental results in both simulation and real-world case studies show that the proposed approach yields superior performance in the extraction of salient features to characterize and quantify heterogeneous recurrence dynamics in spatial data.},
  file = {/Users/hyan46/Dropbox (ASU)/ZoteroData/Yang et al_2020_Heterogeneous recurrence analysis of spatial data.pdf},
  langid = {english},
  number = {1}
}

@article{yangInternet2019,
  ids = {yanginternet2019a},
  title = {The Internet of Things for Smart Manufacturing: {{A}} Review},
  shorttitle = {The Internet of Things for Smart Manufacturing},
  author = {Yang, Hui and Kumara, Soundar and Bukkapatnam, Satish and Tsung, Fugee},
  date = {2019-11-02},
  journaltitle = {IISE Transactions},
  shortjournal = {IISE Transactions},
  volume = {51},
  pages = {1190--1216},
  issn = {2472-5854, 2472-5862},
  doi = {10.1080/24725854.2018.1555383},
  url = {https://www.tandfonline.com/doi/full/10.1080/24725854.2018.1555383},
  urldate = {2020-07-07},
  abstract = {The modern manufacturing industry is investing in new technologies such as the Internet of Things (IoT), big data analytics, cloud computing and cybersecurity to cope with system complexity, increase information visibility, improve production performance, and gain competitive advantages in the global market. These advances are rapidly enabling a new generation of smart manufacturing, i.e., a cyber-physical system tightly integrating manufacturing enterprises in the physical world with virtual enterprises in cyberspace. To a great extent, realizing the full potential of cyber-physical systems depends on the development of new methodologies on the Internet of Manufacturing Things (IoMT) for data-enabled engineering innovations. This article presents a review of the IoT technologies and systems that are the drivers and foundations of data-driven innovations in smart manufacturing. We discuss the evolution of internet from computer networks to human networks to the latest era of smart and connected networks of manufacturing things (e.g., materials, sensors, equipment, people, products, and supply chain). In addition, we present a new framework that leverages IoMT and cloud computing to develop a virtual machine network. We further extend our review to IoMT cybersecurity issues that are of paramount importance to businesses and operations, as well as IoT and smart manufacturing policies that are laid out by governments around the world for the future of smart factory. Finally, we present the challenges and opportunities arising from IoMT. We hope this work will help catalyze more in-depth investigations and multi-disciplinary research efforts to advance IoMT technologies.},
  file = {/Users/hyan46/Dropbox (ASU)/ZoteroData/Yang et al_2019_The internet of things for smart manufacturing.pdf;/Users/hyan46/Zotero/storage/LUD4NATT/Yang et al. - 2019 - The internet of things for smart manufacturing A .pdf},
  langid = {english},
  number = {11}
}

@article{yangLocal2011,
  title = {Local Recurrence Based Performance Prediction and Prognostics in the Nonlinear and Nonstationary Systems},
  author = {Yang, H. and Bukkapatnam, Satish and Barajas, L. G.},
  date = {2011-08},
  journaltitle = {Pattern Recognition},
  shortjournal = {Pattern Recogn Pattern Recogn},
  volume = {44},
  pages = {1834--1840},
  issn = {0031-3203},
  url = {://WOS:000290054200023},
  abstract = {This paper presents a local recurrence modeling approach for state and performance predictions in complex nonlinear and nonstationary systems. Nonstationarity is treated as the switching force between different stationary systems, which is shown as a series of finite time detours of system dynamics from the vicinity of a nonlinear attractor. Recurrence patterns are used to partition the system trajectory into multiple near-stationary segments. Consequently, piecewise eigen analysis of ensembles in each near-stationary segment can capture both nonlinear stochastic dynamics and nonstationarity. The experimental studies using simulated and real-world datasets demonstrate significant prediction performance improvements in comparison with other alternative methods. (C) 2011 Elsevier Ltd. All rights reserved.},
  keywords = {chaotic signals,dynamic-systems,model,noise,nonstationary,plots,predictability,prediction,recurrence plot,time series},
  langid = {english},
  number = {8}
}

@article{yangNonlinear2007,
  title = {Nonlinear Adaptive Wavelet Analysis of Electrocardiogram Signals},
  author = {Yang, H. and Bukkapatnam, Satish and Komanduri, R.},
  date = {2007-08},
  journaltitle = {Physical Review E},
  shortjournal = {Phys Rev E Phys Rev E},
  volume = {76},
  issn = {1539-3755},
  url = {://WOS:000249154700036},
  abstract = {Wavelet representation can provide an effective time-frequency analysis for nonstationary signals, such as the electrocardiogram (EKG) signals, which contain both steady and transient parts. In recent years, wavelet representation has been emerging as a powerful time-frequency tool for the analysis and measurement of EKG signals. The EKG signals contain recurring, near-periodic patterns of P, QRS, T, and U waveforms, each of which can have multiple manifestations. Identification and extraction of a compact set of features from these patterns is critical for effective detection and diagnosis of various disorders. This paper presents an approach to extract a fiducial pattern of EKG based on the consideration of the underlying nonlinear dynamics. The pattern, in a nutshell, is a combination of eigenfunctions of the ensembles created from a Poincare section of EKG dynamics. The adaptation of wavelet functions to the fiducial pattern thus extracted yields two orders of magnitude (some 95\%) more compact representation (measured in terms of Shannon signal entropy). Such a compact representation can facilitate in the extraction of features that are less sensitive to extraneous noise and other variations. The adaptive wavelet can also lead to more efficient algorithms for beat detection and QRS cancellation as well as for the extraction of multiple classical EKG signal events, such as widths of QRS complexes and QT intervals.},
  keywords = {dynamics,physics},
  langid = {english},
  number = {2}
}

@article{yangRecurrence,
  title = {Recurrence {{Based Performance Prediction}} and {{Prognostics}} in {{Complex Manufacturing Systems}}},
  author = {Yang, Hui and Bukkapatnam, Satish},
  pages = {6},
  abstract = {This paper presents a local recurrence modeling approach for state and performance predictions in complex nonlinear and nonstationary systems. Nonstationarity is treated as the switching force between different stationary systems, which is shown as a series of finite time detours of system dynamics from the vicinity of an attractor of a nonlinear process. Recurrence characteristics of the attractor are used to partition the system trajectory into multiple near-stationary segments. Consequently, piecewise eigen analysis of ensembles in each near-stationary segment can capture both nonlinear stochastic dynamics and nonstationarities. The simulation experiment study reveals significant prediction accuracy improvements over other alternative methods.},
  file = {/Users/hyan46/Dropbox (ASU)/ZoteroData/Yang_Bukkapatnam_Recurrence Based Performance Prediction and Prognostics in Complex.pdf},
  langid = {english}
}

@article{yangSeparation2012,
  title = {Separation of Individual Operation Signals from Mixed Sensor Measurements},
  author = {Yang, Qingyu and Jin, Jionghua},
  date = {2012-09},
  journaltitle = {IIE Transactions},
  shortjournal = {IIE Transactions},
  volume = {44},
  pages = {780--792},
  issn = {0740-817X, 1545-8830},
  doi = {10.1080/0740817X.2011.609873},
  url = {http://www.tandfonline.com/doi/abs/10.1080/0740817X.2011.609873},
  urldate = {2020-07-04},
  abstract = {Sensor system measurements are generally mixed signals measured from multiple independent/dependent operations embedded in a complex system. In this article, a novel method is developed to separate the source signals of individual operations from the mixed sensor measurements by integrating the independent component analysis method and the Sparse Component Analysis (SCA) method. The proposed method can efficiently estimate the source signals that include both independent signals and dependent signals that have some dominant components in the time or some linear transform domains (e.g., frequency domain, time/frequency domain, or wavelet domain). In addition, an SCA method is also developed in this article that can automatically identify the dominant components in multiple linear transform domains. A case study of a forging process is conducted to demonstrate the effectiveness of the proposed methods.},
  file = {/Users/hyan46/Dropbox (ASU)/ZoteroData/Yang_Jin_2012_Separation of individual operation signals from mixed sensor measurements.pdf},
  keywords = {People: Judy Jin},
  langid = {english},
  number = {9}
}

@report{yanHIGH2017,
  title = {{{HIGH DIMENSIONAL DATA ANALYSIS FOR ANOMALY DETECTION AND QUALITY IMPROVEMENT A Dissertation Presented}} to {{The Academic Faculty}}},
  author = {Yan, Hao},
  date = {2017-06},
  institution = {{Georgia Institute of Technology}},
  abstract = {Analysis of large-scale high-dimensional data with a complex heterogeneous data structure to extract information or useful features is vital for the purpose of data fusion for assessment of system performance, early detection of system anomalies, intelligent sampling and sensing for data collection and decision making to achieve optimal system performance. Chapter 3 focuses on detecting anomalies from high-dimensional data. Traditionally, most of the image-based anomaly detection methods perform denoising and detection sequentially, which affects detection accuracy and efficiency. In this chapter, A novel methodology, named smooth-sparse decomposition (SSD), is proposed to exploit regularized high-dimensional regression to decompose an image and separate anomalous regions simultaneously by solving a large-scale optimization problem. Chapter 4 extends this to spatial-temporal functional data by extending SSD to spatiotemporal smooth-sparse decomposition (ST-SSD), with a likelihood ratio test to detect the time of change accurately based on the detected anomaly. To enable real-time implementation of the proposed methodology, recursive estimation procedures for ST-SSD are also developed. The proposed methodology is also applied to tonnage signals, rolling inspection data and solar flare monitoring. Chapter 5 considers the adaptive sampling problem for high-dimensional data. A novel adaptive sampling framework, named Adaptive Kernelized Maximum-Minimum Distance is proposed to adaptively estimate the sparse anomalous region. The proposed method balances the sampling efforts between the space filling sampling (exploration) and focused sampling near the anomalous region (exploitation). The proposed methodology is also applied to a case study of anomaly detection in composite sheets using a guided wave test. Chapter 6 explores the penalized tensor regression to model the tensor response data with the process variables. Regularized Tucker decomposition and regularized tensor regression methods are developed, which model the structured point cloud data as tensors and link the point cloud data with the process variables. The performance of the proposed method is evaluated through simulation and a real case study of turning process optimization.},
  file = {/Users/hyan46/Dropbox (ASU)/ZoteroData/Yan_2017_HIGH DIMENSIONAL DATA ANALYSIS FOR ANOMALY DETECTION AND QUALITY IMPROVEMENT A2.pdf},
  keywords = {Method: Functional,Method: Tensor,Problem: Process Monitoring}
}

@article{yanImagebased2015,
  title = {Image-Based Process Monitoring Using Low-Rank Tensor Decomposition},
  author = {Yan, Hao and Paynabar, Kamran and Shi, Jianjun},
  date = {2015-01},
  journaltitle = {IEEE Transactions on Automation Science and Engineering},
  volume = {12},
  pages = {216--227},
  publisher = {{Institute of Electrical and Electronics Engineers Inc.}},
  issn = {15455955},
  doi = {10.1109/TASE.2014.2327029},
  abstract = {Image and video sensors are increasingly being deployed in complex systems due to the rich process information that these sensors can capture. As a result, image data play an important role in process monitoring and control in different application domains such as manufacturing processes, food industries, medical decision-making, and structural health monitoring. Existing process monitoring techniques fail to fully utilize the information of color images due to their complex data characteristics including the high-dimensionality and correlation structure (i.e., temporal, spatial and spectral correlation). This paper proposes a new image-based process monitoring approach that is capable of handling both grayscale and color images. The proposed approach models the high-dimensional structure of the image data with tensors and employs low-rank tensor decomposition techniques to extract important monitoring features monitored using multivariate control charts. In addition, this paper shows the analytical relationships between different low-rank tensor decomposition methods. The performance of the proposed method in quick detection of process changes is evaluated and compared with existing methods through extensive simulations and a case study in a steel tube manufacturing process. Note to Practitioners - This paper, motivated by the problem of combustion monitoring in steel tube manufacturing, focuses on the development of effective methods for process monitoring based on image data. Existing process monitoring techniques cannot fully utilize the information of color images due to the high-dimensionality and complex correlation structure of such data. This paper addresses this problem by extracting essential monitoring features, while considering the spatial and spectral correlation of color images. This is accomplished by using various low-rank tensor decomposition methods along with multivariate control charts. The proposed approach can lead to a computer-aided online monitoring system for automatic detection of out-of-control situations in a process. Using simulation, the performance of the developed methods is compared under various scenarios. This can provide practitioners with useful guidelines for selecting an appropriate method for image-based process monitoring. In future research, we will study the development of image-based fault diagnosis techniques that can be integrated with the process monitoring approaches proposed in this paper.},
  file = {/Users/hyan46/Dropbox (ASU)/ZoteroData/Yan et al_2015_Image-based process monitoring using low-rank tensor decomposition2.pdf},
  keywords = {Application: Rolling,Data: Image,Method: Tensor,Problem: Process Monitoring},
  number = {1}
}

@inproceedings{yanImagebased2019,
  title = {Image-Based Process Monitoring via Adversarial Autoencoder with Applications to Rolling Defect Detection},
  booktitle = {{{IEEE International Conference}} on {{Automation Science}} and {{Engineering}}},
  author = {Yan, Hao and Yeh, Huai Ming and Sergin, Nurettin},
  date = {2019-08},
  volume = {2019-Augus},
  pages = {311--316},
  publisher = {{IEEE Computer Society}},
  issn = {21618089},
  doi = {10.1109/COASE.2019.8843313},
  abstract = {Image-based process monitoring has recently attracted increasing attention due to the advancement of the sensing technologies. However, existing process monitoring methods fail to fully utilize the spatial information of images due to their complex characteristics including the high-dimensionality and complex spatial structures. Recent advancements in unsupervised deep models such as generative adversarial networks (GAN) and adversarial autoencoders (AAE) has enabled to learn the complex spatial structures automatically. Inspired by this advancement, we propose an anomaly detection framework based on the AAE for unsupervised anomaly detection for images. AAE combines the power of GAN with the variational autoencoder, which serves as a nonlinear dimension reduction technique. Based on this, we propose a monitoring statistic efficiently capturing the change of the data. The performance of the proposed AAE-based anomaly detection algorithm is validated through a simulation study and real case study for rolling defect detection.},
  file = {/Users/hyan46/Dropbox (ASU)/ZoteroData/Yan et al_2019_Image-based process monitoring via adversarial autoencoder with applications to2.pdf},
  isbn = {978-1-72810-355-6},
  keywords = {Application: Rolling,Data: Image,Method: Deep Learning,Problem: Process Monitoring}
}

@article{yanMultiple2016,
  title = {Multiple {{Sensor Data Fusion}} for {{Degradation Modeling}} and {{Prognostics}} under {{Multiple Operational Conditions}}},
  author = {Yan, Hao and Liu, Kaibo and Zhang, Xi and Shi, Jianjun},
  date = {2016-09},
  journaltitle = {IEEE Transactions on Reliability},
  volume = {65},
  pages = {1416--1426},
  publisher = {{Institute of Electrical and Electronics Engineers Inc.}},
  issn = {00189529},
  doi = {10.1109/TR.2016.2575449},
  abstract = {Due to the rapid advances in sensing and computing technology, multiple sensors have been widely used to simultaneously monitor the health status of an operation unit. This creates a data-rich environment, enabling an unprecedented opportunity to make better understanding and inference about the current and future behavior of the unit in real time. Depending on specific task requirements, a unit is often required to run under multiple operational conditions, each of which may affect the degradation path of the unit differently. Thus, two fundamental challenges remain to be solved for effective degradation modeling and prognostic analysis: 1) how to leverage the dependent information among multiple sensor signals to better understand the health condition of the unit; and 2) how to model the effects of multiple conditions on the degradation characteristics of the unit. To address these two issues, this paper develops a data fusion methodology that integrates the information from multiple sensors to construct a health index when the monitored unit runs under multiple operational conditions. Our goal is that the developed health index provides a much better characterization of the health condition of the degraded unit, and, thus, leads to a better prediction of the remaining lifetime. Unlike other existing approaches, the developed data fusion model combines the fusion procedure and the degradation modeling under different operational conditions in a unified manner. The effectiveness of the proposed method is demonstrated in a case study, which involves a degradation dataset of aircraft gas turbine engines collected from 21 sensors under six different operational conditions.},
  file = {/Users/hyan46/Dropbox (ASU)/ZoteroData/Yan et al_2016_Multiple Sensor Data Fusion for Degradation Modeling and Prognostics under3.pdf},
  keywords = {Data fusion,multiple operational conditions,multiple sensors,Problem: Prognostics},
  number = {3}
}

@inproceedings{yanPhysicsbased2019,
  title = {Physics-Based Deep Spatio-Temporal Metamodeling for Cardiac Electrical Conduction Simulation},
  booktitle = {{{IEEE International Conference}} on {{Automation Science}} and {{Engineering}}},
  author = {Yan, Hao and Zhao, Xinyu and Hu, Zhiyong and Du, Dongping},
  date = {2019-08},
  volume = {2019-Augus},
  pages = {152--157},
  publisher = {{IEEE Computer Society}},
  issn = {21618089},
  doi = {10.1109/COASE.2019.8842902},
  abstract = {Modeling and simulation have been widely used in both cardiac research and clinical study to investigate cardiac disease mechanism and develop new treatment design. Electrical conduction among cardiac tissue is commonly modeled with a partial differential equation, i.e., reaction-diffusion equation, where the reaction term describes cellular excitation and diffusion term describes electrical propagation. Cellular excitation can be modeled by either detailed human cellular models or simplified models such as the FitzHugh-Nagumo model; electrical propagation can be simulated using either biodomain or mono-domain tissue model. However, existing cardiac models have a great level of complexity, and the simulation is often time-consuming. This paper develops a new spatiotemporal model as a surrogate model of the timeconsuming cardiac model. Specifically, we propose to investigate the auto-regressive convolutional neural network (AR-CNN) and convolutional long short-term memory (Conv-LSTM) to model the spatial and temporal structure for the metamodeling. Model predictions are compared to the one-dimensional simulation data to validate the prediction accuracy. The metamodel can accurately capture the properties of the individual cardiac cell, as well as the electrical wave morphology in cardiac fiber at different simulation scenarios, which demonstrates its superior performance in modeling and the long-term prediction.},
  file = {/Users/hyan46/Dropbox (ASU)/ZoteroData/Yan et al_2019_Physics-based deep spatio-temporal metamodeling for cardiac electrical2.pdf},
  isbn = {978-1-72810-355-6},
  keywords = {Application: Cardiac,Method: Deep Learning,Method: Physics}
}

@article{yanRealTime2018,
  title = {Real-{{Time Monitoring}} of {{High}}-{{Dimensional Functional Data Streams}} via {{Spatio}}-{{Temporal Smooth Sparse Decomposition}}},
  author = {Yan, Hao and Paynabar, Kamran and Shi, Jianjun},
  date = {2018-04},
  journaltitle = {Technometrics},
  volume = {60},
  pages = {181--197},
  publisher = {{American Statistical Association}},
  issn = {15372723},
  doi = {10.1080/00401706.2017.1346522},
  abstract = {High-dimensional data monitoring and diagnosis has recently attracted increasing attention among researchers as well as practitioners. However, existing process monitoring methods fail to fully use the information of high-dimensional data streams due to their complex characteristics including the large dimensionality, spatio-temporal correlation structure, and nonstationarity. In this article, we propose a novel process monitoring methodology for high-dimensional data streams including profiles and images that can effectively address foregoing challenges. We introduce spatio-temporal smooth sparse decomposition (ST-SSD), which serves as a dimension reduction and denoising technique by decomposing the original tensor into the functional mean, sparse anomalies, and random noises. ST-SSD is followed by a sequential likelihood ratio test on extracted anomalies for process monitoring. To enable real-time implementation of the proposed methodology, recursive estimation procedures for ST-SSD are developed. ST-SSD also provides useful diagnostics information about the location of change in the functional mean. The proposed methodology is validated through various simulations and real case studies. Supplementary materials for this article are available online.},
  file = {/Users/hyan46/Dropbox (ASU)/ZoteroData/Yan et al_2018_Real-Time Monitoring of High-Dimensional Functional Data Streams via3.pdf},
  keywords = {Application: Nano,Data: Image,Method: Functional,Method: Spatio-temporal,Method: Tensor,Problem: Process Monitoring},
  number = {2}
}

@article{yanRealtime2021,
  title = {Real-Time {{Detection}} of {{Clustered Events}} in {{Video}}-Imaging Data with {{Applications}} to {{Additive Manufacturing}}},
  author = {Yan, Hao and Grasso, Marco and Paynabar, Kamran and Colosimo, Bianca Maria},
  date = {2021},
  journaltitle = {IISE Transactions},
  doi = {10.1080/24725854.2021.1882013},
  url = {http://arxiv.org/abs/2004.10977},
  abstract = {The use of video-imaging data for in-line process monitoring applications has become more and more popular in the industry. In this framework, spatio-temporal statistical process monitoring methods are needed to capture the relevant information content and signal possible out-of-control states. Video-imaging data are characterized by a spatio-temporal variability structure that depends on the underlying phenomenon, and typical out-of-control patterns are related to the events that are localized both in time and space. In this paper, we propose an integrated spatio-temporal decomposition and regression approach for anomaly detection in video-imaging data. Out-of-control events are typically sparse spatially clustered and temporally consistent. Therefore, the goal is to not only detect the anomaly as quickly as possible ("when") but also locate it ("where"). The proposed approach works by decomposing the original spatio-temporal data into random natural events, sparse spatially clustered and temporally consistent anomalous events, and random noise. Recursive estimation procedures for spatio-temporal regression are presented to enable the real-time implementation of the proposed methodology. Finally, a likelihood ratio test procedure is proposed to detect when and where the hotspot happens. The proposed approach was applied to the analysis of video-imaging data to detect and locate local over-heating phenomena ("hotspots") during the layer-wise process in a metal additive manufacturing process.},
  annotation = {\_eprint: 2004.10977},
  file = {/Users/hyan46/Dropbox (ASU)/ZoteroData/Yan et al_2021_Real-time Detection of Clustered Events in Video-imaging data with Applications.pdf},
  keywords = {Application: Additive Manufacturing,Application: Manufacturing,Data: Video,Problem: Process Monitoring}
}

@article{yanSemisupervised2014,
  title = {Semi-Supervised Mixture Discriminant Monitoring for Chemical Batch Processes},
  author = {Yan, Zhengbing and Huang, Chien-Ching and Yao, Yuan},
  date = {2014-05-15},
  journaltitle = {Chemometrics and Intelligent Laboratory Systems},
  shortjournal = {Chemometrics and Intelligent Laboratory Systems},
  volume = {134},
  pages = {10--22},
  issn = {0169-7439},
  doi = {10.1016/j.chemolab.2014.03.002},
  url = {http://www.sciencedirect.com/science/article/pii/S0169743914000434},
  urldate = {2020-05-25},
  abstract = {In order to ensure operation safety and consistent product quality, multivariate statistical methods have been widely adopted in chemical batch process monitoring. In this paper, a semi-supervised mixture discriminant monitoring (SMDM) scheme is proposed, which integrates the strengths of both supervised and unsupervised techniques. The semi-supervised characteristic enables SMDM to fully make use of both labeled and unlabeled data, leading to more reliable process models. In addition, SMDM is suited to handling non-Gaussian distributed data that are commonly observed in batch processes. Inheriting from supervised learning, SMDM has better online fault diagnosis capability of known faults compared to the unsupervised multivariate statistical process monitoring methods. Meanwhile, the utilization of control charts makes SMDM capable to detect unknown faults. After an unknown fault is detected, the process variables most contributing to the fault can be identified through missing variable analysis. Such information is valuable for process engineers to find out the root cause of the fault. The collected data of the new faults are then used to update the monitoring model. By doing so, the fault diagnosis performance of the monitoring model can be improved online. The proposed method is demonstrated through its application to an injection molding process.},
  file = {/Users/hyan46/Zotero/storage/MQJ69EIA/S0169743914000434.html},
  keywords = {Batch process,Mixture discriminant analysis,multimode,Multivariate statistical process monitoring,Non-Gaussian,Problem: Process Monitoring,Semi-supervised learning},
  langid = {english}
}

@article{yanStructured2019,
  title = {Structured {{Point Cloud Data Analysis Via Regularized Tensor Regression}} for {{Process Modeling}} and {{Optimization}}},
  author = {Yan, Hao and Paynabar, Kamran and Pacella, Massimo},
  date = {2019-07},
  journaltitle = {Technometrics},
  volume = {61},
  pages = {385--395},
  publisher = {{American Statistical Association}},
  issn = {15372723},
  doi = {10.1080/00401706.2018.1529628},
  abstract = {Advanced 3D metrology technologies such as coordinate measuring machine and laser 3D scanners have facilitated the collection of massive point cloud data, beneficial for process monitoring, control and optimization. However, due to their high dimensionality and structure complexity, modeling and analysis of point clouds are still a challenge. In this article, we use multilinear algebra techniques and propose a set of tensor regression approaches to model the variational patterns of point clouds and to link them to process variables. The performance of the proposed methods is evaluated through simulations and a real case study of turning process optimization.},
  annotation = {\_eprint: 1807.10278},
  file = {/Users/hyan46/Dropbox (ASU)/ZoteroData/Yan et al_2019_Structured Point Cloud Data Analysis Via Regularized Tensor Regression for3.pdf},
  keywords = {Application: Manufacturing,Application: Surface Scanning,Data: Point Cloud,Method: Tensor,Problem: Process Monitoring},
  number = {3}
}

@article{yaoConstrained2018,
  title = {Constrained {{Markov Decision Process Modeling}} for {{Sequential Optimization}} of {{Additive Manufacturing Build Quality}}},
  author = {Yao, Bing and Yang, Hui},
  date = {2018},
  journaltitle = {IEEE Access},
  shortjournal = {IEEE Access},
  volume = {6},
  pages = {54786--54794},
  issn = {2169-3536},
  doi = {10.1109/ACCESS.2018.2872391},
  url = {https://ieeexplore.ieee.org/document/8473690/},
  urldate = {2020-07-07},
  abstract = {Additive manufacturing (AM) provides a greater level of flexibility to produce a 3-D part with complex geometries directly from the design. However, the widespread application of AM is currently hampered by technical challenges in process repeatability and quality control. To enhance the in-process information visibility, advanced sensing is increasingly invested for real-time AM process monitoring. The proliferation of in situ sensing data calls for the development of analytical methods for the extraction of features sensitive to layer-wise defects, and the exploitation of pertinent knowledge about defects for in-process quality control of AM builds. As a result, there are increasing interests and rapid development of sensor-based models for the characterization and estimation of layer-wise defects in the past few years. However, very little has been done to go from sensor-based modeling of defects to the suggestion of in situ corrective actions for quality control of AM builds. In this paper, we propose a new sequential decision-making framework for in situ control of AM processes through the constrained Markov decision process (CMDP), which jointly considers the conflicting objectives of both total cost (i.e., energy or time) and build quality. Experimental results show that the CMDP formulation provides an effective policy for executing corrective actions to repair and counteract incipient defects in AM before completion of the build.},
  file = {/Users/hyan46/Dropbox (ASU)/ZoteroData/Yao_Yang_2018_Constrained Markov Decision Process Modeling for Sequential Optimization of.pdf},
  keywords = {Application: Additive Manufacturing,Method: Active Learning},
  langid = {english}
}

@article{yaoMarkov2018,
  title = {Markov {{Decision Process}} for {{Image}}-{{Guided Additive Manufacturing}}},
  author = {Yao, Bing and Imani, Farhad and Yang, Hui},
  date = {2018-10},
  journaltitle = {IEEE Robotics and Automation Letters},
  shortjournal = {IEEE Robot. Autom. Lett.},
  volume = {3},
  pages = {2792--2798},
  issn = {2377-3766, 2377-3774},
  doi = {10.1109/LRA.2018.2839973},
  url = {https://ieeexplore.ieee.org/document/8362941/},
  urldate = {2020-07-07},
  abstract = {Additive manufacturing (AM) is a process to produce three-dimensional parts with complex and free-form geometries layer by layer from computer-aided-design models. However, realtime quality control is the main challenge that hampers the wide adoption of AM. Advancements in sensing systems facilitate AM monitoring and control. Realizing full potentials of sensing data for AM quality control depends to a great extent on effective analytical methods and tools that will handle complicated imaging data, and extract pertinent information about defect conditions and process dynamics. This letter considers the optimal control problem for AM parts whose layerwise defect states can be monitored using advanced sensing systems. Specifically, we formulate the in situ AM control problem as a Markov decision process and utilize the layerwise imaging data to find an optimal control policy. We take into account the stochastic uncertainty in the variations of layerwise defects and aim at mitigating the defects before they reach the nonrecoverable stage. Finally, the model is used to derive an optimal control policy by utilizing the defect-state signals estimated from layerwise images in a metal AM application.},
  file = {/Users/hyan46/Dropbox (ASU)/ZoteroData/Yao et al_2018_Markov Decision Process for Image-Guided Additive Manufacturing.pdf},
  keywords = {Method: Active Learning},
  langid = {english},
  number = {4}
}

@inproceedings{yaoMesh2016,
  title = {Mesh Resolution Impacts the Accuracy of Inverse and Forward {{ECG}} Problems},
  booktitle = {2016 38th {{Annual International Conference}} of the {{IEEE Engineering}} in {{Medicine}} and {{Biology Society}} ({{EMBC}})},
  author = {Yao, Bing and Pei, Shenli and Yang, Hui},
  date = {2016-08},
  pages = {4047--4050},
  publisher = {{IEEE}},
  location = {{Orlando, FL, USA}},
  doi = {10.1109/EMBC.2016.7591615},
  url = {http://ieeexplore.ieee.org/document/7591615/},
  urldate = {2020-09-09},
  abstract = {Electrocardiographic imaging (ECGI) has become an important medical diagnosis tool that assists scientists to noninvasively investigate cardiac electric activity. Many previous works have studied the inverse and forward ECG problems to understand how to reconstruct the cardiac electric activity from the body potential distribution. However, the inverse ECG problem is highly ill-conditioned and very sensitive to errors and noises. Thus, there is a need to study the sensitivity of inverse and forward ECG problems. In this paper, we investigated effects of mesh resolution on the accuracy of inverse and forward ECG problems. First, we employed the boundary element method to calculate the relationship between potential distributions on the body and heart surfaces and developed an algorithm to solve inverse and forward ECG problems. Second, we implemented the algorithm to solve the ECG problems in both a concentric spherical geometry and a realistic torso-heart geometry. Third, we evaluated the relative error between our solution and the analytical solution under the condition of different mesh resolutions. Experimental results explicitly show that the relative error in the inverse solution decreased from 30\% to 17\% when the mesh elements triangulating the two spheres increased from 24 to 400 in the concentric spherical geometry, and that decreased from 26\% to 16\% when the mesh elements triangulating the heart surface increased from 136 to 546 in the realistic torso-heart geometry.},
  eventtitle = {2016 38th {{Annual International Conference}} of the {{IEEE Engineering}} in {{Medicine}} and {{Biology Society}} ({{EMBC}})},
  file = {/Users/hyan46/Dropbox (ASU)/ZoteroData/Yao et al_2016_Mesh resolution impacts the accuracy of inverse and forward ECG problems.pdf},
  isbn = {978-1-4577-0220-4},
  keywords = {_tablet_modified},
  langid = {english}
}

@article{yaoMultifractal2018,
  title = {Multifractal {{Analysis}} of {{Image Profiles}} for the {{Characterization}} and {{Detection}} of {{Defects}} in {{Additive Manufacturing}}},
  author = {Yao, Bing and Imani, Farhad and Sakpal, Aniket S. and Reutzel, E. W. and Yang, Hui},
  date = {2018-03-01},
  journaltitle = {Journal of Manufacturing Science and Engineering},
  volume = {140},
  pages = {031014},
  issn = {1087-1357, 1528-8935},
  doi = {10.1115/1.4037891},
  url = {https://asmedigitalcollection.asme.org/manufacturingscience/article/doi/10.1115/1.4037891/366671/Multifractal-Analysis-of-Image-Profiles-for-the},
  urldate = {2020-07-07},
  abstract = {Metal-based powder-bed-fusion additive manufacturing (PBF-AM) is gaining increasing attention in modern industries, and is a promising direct manufacturing technology. Additive manufacturing (AM) does not require the tooling cost of conventional subtractive manufacturing processes, and is flexible to produce parts with complex geometries. Quality and repeatability of AM parts remain a challenging issue that persistently hampers wide applications of AM technology. Rapid advancements in sensing technology, especially imaging sensing systems, provide an opportunity to overcome such challenges. However, little has been done to fully utilize the image profiles acquired in the AM process and study the fractal patterns for the purpose of process monitoring, quality assessment, and control. This paper presents a new multifractal methodology for the characterization and detection of defects in PBF-AM parts. Both simulation and real-world case studies show that the proposed approach effectively detects and characterizes various defect patterns in AM images and has strong potential for quality control of AM processes.},
  file = {/Users/hyan46/Dropbox (ASU)/ZoteroData/Yao et al_2018_Multifractal Analysis of Image Profiles for the Characterization and Detection.pdf},
  langid = {english},
  number = {3}
}

@article{yaoPhysicsdriven2016,
  title = {Physics-Driven {{Spatiotemporal Regularization}} for {{High}}-Dimensional {{Predictive Modeling}}: {{A Novel Approach}} to {{Solve}} the {{Inverse ECG Problem}}},
  shorttitle = {Physics-Driven {{Spatiotemporal Regularization}} for {{High}}-Dimensional {{Predictive Modeling}}},
  author = {Yao, Bing and Yang, Hui},
  date = {2016-12-14},
  journaltitle = {Scientific Reports},
  volume = {6},
  pages = {39012},
  publisher = {{Nature Publishing Group}},
  issn = {2045-2322},
  doi = {10.1038/srep39012},
  url = {https://www.nature.com/articles/srep39012},
  urldate = {2020-05-24},
  abstract = {This paper presents a novel physics-driven spatiotemporal regularization (STRE) method for high-dimensional predictive modeling in complex healthcare systems. This model not only captures the physics-based interrelationship between time-varying explanatory and response variables that are distributed in the space, but also addresses the spatial and temporal regularizations to improve the prediction performance. The STRE model is implemented to predict the time-varying distribution of electric potentials on the heart surface based on the electrocardiogram (ECG) data from the distributed sensor network placed on the body surface. The model performance is evaluated and validated in both a simulated two-sphere geometry and a realistic torso-heart geometry. Experimental results show that the STRE model significantly outperforms other regularization models that are widely used in current practice such as Tikhonov zero-order, Tikhonov first-order and L1 first-order regularization methods.},
  file = {/Users/hyan46/Dropbox (ASU)/ZoteroData/Yao_Yang_2016_Physics-driven Spatiotemporal Regularization for High-dimensional Predictive.pdf;/Users/hyan46/Zotero/storage/PR5JAHY2/srep39012.html},
  issue = {1},
  keywords = {Application: Manufacturing,Application: Surface Scanning,cardiac},
  langid = {english},
  number = {1}
}

@article{yaoSpatiotemporalInReview,
  title = {Spatiotemporal {{Modeling}} and {{Optimization}} for {{Personalized Cardiac Simulation}}},
  author = {Yao, Bieng},
  year = {In Review},
  journaltitle = {IEEE Transactions on Automation Science and Engineering},
  abstract = {Computational modeling of the heart has con- tributed tremendously in quantitatively understanding the car- diac functions and shows great potential to assist medical doctors in disease diagnosis and treatment planning. However, cardiac simulation is generally subject to uncertainties and variabilities among different individuals. Traditional “one size fits all” simu- lation is limited to provide individualized optimal diagnosis and treatment for heart patients. Realizing the full potential of cardiac computational modeling in clinical practice requires effective model personalization. In this paper, we develop a spatiotem- poral modeling and optimization framework for personalized cardiac simulation. The proposed framework not only captures the spatiotemporal correlation in the cardiac electrodynamics, but also improves the computational efficiency for personalized modeling in cardiac electrophysiology. The model performance is validated and evaluated in both 2D and 3D cardiac simulation. Experimental results demonstrate the effectiveness and efficiency of the proposed calibration framework in estimating model parameters for personalized cardiac simulation.},
  file = {/Users/hyan46/Dropbox (ASU)/ZoteroData/Yao_In Review_Spatiotemporal Modeling and Optimization for Personalized Cardiac Simulation.pdf}
}

@article{yeAdaptive2020,
  title = {Adaptive {{Preventive Maintenance}} for {{Flow Shop Scheduling With Resumable Processing}}},
  author = {Ye, Honghan and Wang, Xi and Liu, Kaibo},
  date = {2020},
  journaltitle = {IEEE Transactions on Automation Science and Engineering},
  shortjournal = {IEEE Trans. Automat. Sci. Eng.},
  pages = {1--8},
  issn = {1545-5955, 1558-3783},
  doi = {10.1109/TASE.2020.2978890},
  url = {https://ieeexplore.ieee.org/document/9040876/},
  urldate = {2020-07-04},
  abstract = {In this article, we focus on a joint scheduling problem that considers the corrective maintenance (CM) due to unexpected breakdowns and the scheduled preventive maintenance (PM) in a generic M-machine flow shop. The objective is to find the optimal job sequence and PM schedule such that the total of the tardiness cost, PM cost, and CM cost is minimized. Currently, most existing studies on the PM schedules are based on a fixed PM interval, which is rigid and may lead to poor performance, as the fixed strategy fails to effectively balance the trade-offs between the production scheduling and maintenance. To address this critical research issue, our novel idea is to dynamically update the PM interval based on the real-time machine age, such that the maintenance activity coordinates with the job scheduling to the maximum extent, which results in an overall cost saving. Specifically, a correction factor is introduced to dynamically update the PM interval and to help evaluate whether it is worthwhile to process the job first at the risk of the CM before performing the PM action. To demonstrate the effectiveness of the adaptive strategy, simulations and a case study on mining operations are conducted to show that the adaptive strategy outperforms the existing methods with a less total cost.},
  file = {/Users/hyan46/Dropbox (ASU)/ZoteroData/Ye et al_2020_Adaptive Preventive Maintenance for Flow Shop Scheduling With Resumable.pdf},
  keywords = {Application: Mining,Data: Profiles,People: Kaibo Liu,Problem: Prognostics},
  langid = {english}
}

@article{yinanCPACConv2020,
  title = {{{CPAC}}-{{Conv}}: {{CP}}-Decomposition to {{Approximately Compress Convolutional Layers}} in {{Deep Learning}}},
  author = {Yinan, Wang and Weihong, Guo and Xiaowei, Yue},
  date = {2020},
  abstract = {Feature extraction for tensor data serves as an important step in many tasks such as anomaly detection, process monitoring, image classification, and quality control. Although many methods have been proposed for tensor feature extraction, there are still two challenges that need to be addressed: 1) how to reduce the computation cost for high dimensional and large volume tensor data; 2) how to interpret the output features and evaluate their significance. Although the most recent methods in deep learning, such as Convolutional Neural Network (CNN), have shown outstanding performance in analyzing tensor data, their wide adoption is still hindered by model complexity and lack of interpretability. To fill this research gap, we propose to use CP-decomposition to approximately compress the convolutional layer (CPAC-Conv layer) in deep learning. The contributions of our work could be summarized into three aspects: 1) we adapt CP-decomposition to compress convolutional kernels and derive the expressions of both forward and backward propagations for our proposed CPAC-Conv layer; 2) compared with the original convolutional layer, the proposed CPAC-Conv layer can reduce the number of parameters without decaying prediction performance. It can combine with other layers to build novel Neural Networks; 3) the value of decomposed kernels indicates the significance of the corresponding feature map, which increases model interpretability and provides us insights to guide feature selection.},
  file = {/Users/hyan46/Zotero/storage/F7TALFNS/UIIE-6291.R1_Proof_hi.pdf}
}

@inproceedings{yoon2018bayesian,
  title = {Bayesian Model-Agnostic Meta-Learning},
  booktitle = {Proceedings of the 32nd International Conference on Neural Information Processing Systems},
  author = {Yoon, Jaesik and Kim, Taesup and Dia, Ousmane and Kim, Sungwoong and Bengio, Yoshua and Ahn, Sungjin},
  date = {2018},
  pages = {7343--7353},
  file = {/Users/hyan46/Dropbox (ASU)/ZoteroData/Yoon et al_2018_Bayesian model-agnostic meta-learning.pdf}
}

@article{yoonNovel2019,
  ids = {yoonNovel2019a},
  title = {A {{Novel Positive Transfer Learning Approach}} for {{Telemonitoring}} of {{Parkinson}}’s {{Disease}}},
  author = {Yoon, Hyunsoo and Li, Jing},
  date = {2019-01},
  journaltitle = {IEEE Transactions on Automation Science and Engineering},
  shortjournal = {IEEE Trans. Automat. Sci. Eng.},
  volume = {16},
  pages = {180--191},
  issn = {1545-5955, 1558-3783},
  doi = {10.1109/TASE.2018.2874233},
  url = {https://ieeexplore.ieee.org/document/8520887/},
  urldate = {2020-07-04},
  abstract = {Telemonitoring is the use of electronic devices to remotely monitor patients. Taking the Parkinson’s disease (PD) as an example, the use of at-home testing device (AHTD) enables remote, internet-based measurement of PD vocal symptoms. Translating AHTD measurement into a unified PD rating scale (UPDRS) through predictive analytics enables cost-effective, convenient, and close tracking of PD progression. Building a predictive model between AHTD measurement and UPDRS is not straightforward because PD patients are highly heterogeneous, which requires patient-specific models. Learning a patientspecific model faces the challenge of limited data. Transfer learning (TL) tackles this challenge by leveraging other patients’ information to make up the data shortage when modeling a target patient. Among different TL methods, the category of parameter transfer methods is more appropriate for the telemonitoring application because it transfers patient-specific model parameters but not patients’ data. However, existing parameter transfer methods fall short because not every other patient’s information is helpful and blind transfer causes the problem of negative transfer. To tackle this limitation, we propose a positive TL (PTL) method. We provide an in-depth theoretical study on the risk and condition for negative transfer to happen, which further drive the development of novel PTL algorithms that are robust to negative transfer. We apply PTL to predict UPDRS of 42 PD patients using their AHTD vocal measurement. PTL achieves significantly better accuracy compared with single learning and one-model-fits-all approaches.},
  file = {/Users/hyan46/Dropbox (ASU)/ZoteroData/Yoon_Li_2019_A Novel Positive Transfer Learning Approach for Telemonitoring of Parkinson’s.pdf},
  keywords = {Application: Health,Method: Transfer Learning,People: Jing Li},
  langid = {english},
  number = {1}
}

@online{yuanDeep2020,
  title = {Deep {{Learning}} for {{Insider Threat Detection}}: {{Review}}, {{Challenges}} and {{Opportunities}}},
  shorttitle = {Deep {{Learning}} for {{Insider Threat Detection}}},
  author = {Yuan, Shuhan and Wu, Xintao},
  date = {2020-05-25},
  url = {http://arxiv.org/abs/2005.12433},
  urldate = {2020-05-27},
  abstract = {Insider threats, as one type of the most challenging threats in cyberspace, usually cause significant loss to organizations. While the problem of insider threat detection has been studied for a long time in both security and data mining communities, the traditional machine learning based detection approaches, which heavily rely on feature engineering, are hard to accurately capture the behavior difference between insiders and normal users due to various challenges related to the characteristics of underlying data, such as high-dimensionality, complexity, heterogeneity, sparsity, lack of labeled insider threats, and the subtle and adaptive nature of insider threats. Advanced deep learning techniques provide a new paradigm to learn end-to-end models from complex data. In this brief survey, we first introduce one commonly-used dataset for insider threat detection and review the recent literature about deep learning for such research. The existing studies show that compared with traditional machine learning algorithms, deep learning models can improve the performance of insider threat detection. However, applying deep learning to further advance the insider threat detection task still faces several limitations, such as lack of labeled data, adaptive attacks. We then discuss such challenges and suggest future research directions that have the potential to address challenges and further boost the performance of deep learning for insider threat detection.},
  archiveprefix = {arXiv},
  eprint = {2005.12433},
  eprinttype = {arxiv},
  file = {/Users/hyan46/Dropbox (ASU)/ZoteroData/Yuan_Wu_2020_Deep Learning for Insider Threat Detection2.pdf},
  keywords = {Computer Science - Cryptography and Security,Computer Science - Machine Learning},
  primaryclass = {cs}
}

@online{yuanMultivariate2018,
  title = {Multivariate {{Spatiotemporal Hawkes Processes}} and {{Network Reconstruction}}},
  author = {Yuan, Baichuan and Li, Hao and Bertozzi, Andrea L. and Brantingham, P. Jeffrey and Porter, Mason A.},
  date = {2018-11-15},
  url = {http://arxiv.org/abs/1811.06321},
  urldate = {2021-02-26},
  abstract = {There is often latent network structure in spatial and temporal data and the tools of network analysis can yield fascinating insights into such data. In this paper, we develop a nonparametric method for network reconstruction from spatiotemporal data sets using multivariate Hawkes processes. In contrast to prior work on network reconstruction with point-process models, which has often focused on exclusively temporal information, our approach uses both temporal and spatial information and does not assume a specific parametric form of network dynamics. This leads to an effective way of recovering an underlying network. We illustrate our approach using both synthetic networks and networks constructed from real-world data sets (a location-based social media network, a narrative of crime events, and violent gang crimes). Our results demonstrate that, in comparison to using only temporal data, our spatiotemporal approach yields improved network reconstruction, providing a basis for meaningful subsequent analysis --- such as community structure and motif analysis --- of the reconstructed networks.},
  archiveprefix = {arXiv},
  eprint = {1811.06321},
  eprinttype = {arxiv},
  file = {/Users/hyan46/Dropbox (ASU)/ZoteroData/Yuan et al_2018_Multivariate Spatiotemporal Hawkes Processes and Network Reconstruction.pdf;/Users/hyan46/Zotero/storage/6SJDI7LE/1811.html},
  keywords = {Computer Science - Social and Information Networks,Electrical Engineering and Systems Science - Signal Processing,Nonlinear Sciences - Adaptation and Self-Organizing Systems,Physics - Physics and Society,Statistics - Machine Learning},
  primaryclass = {nlin, physics:physics, stat}
}

@article{yuDynamic2021,
  title = {Dynamic {{Sampling Policy}} for {{In Situ}} and {{Online Measurements Data Fusion}} in a {{Policy Network}}},
  author = {Yu, Hongtao and Hua, Zhongsheng},
  date = {2021},
  journaltitle = {IEEE Transactions on Automation Science and Engineering},
  shortjournal = {IEEE Trans. Automat. Sci. Eng.},
  pages = {1--14},
  issn = {1545-5955, 1558-3783},
  doi = {10.1109/TASE.2021.3073808},
  url = {https://ieeexplore.ieee.org/document/9423982/},
  urldate = {2021-06-11},
  abstract = {The rapid development of sensing technologies has enabled sensors embedded into systems and generated continuous online data for anomaly monitoring and protection of the system. However, due to transmission errors and environmental noises, the online measurements collected by sensors are usually inaccurate and cannot be applied directly. A small amount of precise in situ measurements, which are accurate but costly to acquire, are usually fused with online measurements for accuracy improvement. Over the past years, there are many studies concerning such data fusion approaches for obtaining reliable fused data. However, most existing works assume the availability of in situ measurements, without providing a strategy for sampling the expensive in situ measurements. As a result, they may undersample or oversample the in situ measurements that result in large fusion errors or unnecessary costs. To address this problem, this article proposes a dynamic policy for sampling the in situ measurements adaptively using the information that the online measurements provide. Specifically, the proposed policy models the dependence between in situ sampling decisions and influencing factors using a policy network, predicts the probability of recommending in situ samplings with the policy network, and guides the sampling of in situ measurements dynamically. Theoretical and experimental results both verify the effectiveness of the proposed approach.},
  file = {/Users/hyan46/Zotero/storage/RXQB5VHB/Yu and Hua - 2021 - Dynamic Sampling Policy for In Situ and Online Mea.pdf},
  langid = {english}
}

@article{yueActive2020,
  title = {Active {{Learning}} for {{Gaussian Process Considering Uncertainties With Application}} to {{Shape Control}} of {{Composite Fuselage}}},
  author = {Yue, Xiaowei and Wen, Yuchen and Hunt, Jeffrey H. and Shi, Jianjun},
  date = {2020},
  journaltitle = {IEEE Transactions on Automation Science and Engineering},
  shortjournal = {IEEE Trans. Automat. Sci. Eng.},
  pages = {1--11},
  issn = {1545-5955, 1558-3783},
  doi = {10.1109/TASE.2020.2990401},
  url = {https://ieeexplore.ieee.org/document/9091123/},
  urldate = {2020-07-21},
  abstract = {In the machine learning domain, active learning is an iterative data selection algorithm for maximizing information acquisition and improving model performance with limited training samples. It is very useful, especially for the industrial applications where training samples are expensive, time-consuming, or difficult to obtain. Existing methods mainly focus on active learning for classification, and a few methods are designed for regression such as linear regression or Gaussian process. Uncertainties from measurement errors and intrinsic input noise inevitably exist in the experimental data, which further affects the modeling performance. The existing active learning methods do not incorporate these uncertainties for Gaussian process. In this paper, we propose two new active learning algorithms for the Gaussian process with uncertainties, which are variance-based weighted active learning algorithm and D-optimal weighted active learning algorithm. Through numerical study, we show that the proposed approach can incorporate the impact from uncertainties, and realize better prediction performance. This approach has been applied to improving the predictive modeling for automatic shape control of composite fuselage.},
  file = {/Users/hyan46/Dropbox (ASU)/ZoteroData/Yue et al_2020_Active Learning for Gaussian Process Considering Uncertainties With Application.pdf},
  keywords = {Method: Active Learning},
  langid = {english}
}

@article{yueGeneralized2017,
  title = {Generalized {{Wavelet Shrinkage}} of {{Inline Raman Spectroscopy}} for {{Quality Monitoring}} of {{Continuous Manufacturing}} of {{Carbon Nanotube Buckypaper}}},
  author = {Yue, Xiaowei and Wang, Kan and Yan, Hao and Park, Jin Gyu and Liang, Zhiyong and Zhang, Chuck and Wang, Ben and Shi, Jianjun},
  date = {2017-01},
  journaltitle = {IEEE Transactions on Automation Science and Engineering},
  volume = {14},
  pages = {196--207},
  publisher = {{Institute of Electrical and Electronics Engineers Inc.}},
  issn = {15455955},
  doi = {10.1109/TASE.2016.2599023},
  abstract = {Process monitoring and quality control is essential for continuous manufacturing processes of carbon nano- tube (CNT) thin sheets or buckypaper. Raman spectroscopy is an attractive inline quality characterization and quantification tool for nanomanufacturing because of its nondestructive nature, fast data acquisition speed, and ability to provide detailed material information. However, there is signal-dependent noise buried in the Raman spectra, which reduces the signal-to-noise (S/N) ratio and affects the accuracy, efficiency, and sensitivity for Raman spectrum-based quality control approaches. In this paper, a signal analysis model with signal-dependent noise for Raman spectroscopy is developed and validated based on experimental data. The wavelet shrinkage method is used for denoising and improving the S/N ratio of raw Raman spectra. Based on the validated signal-noise relationship, a novel generalized wavelet shrinkage approach is introduced to remove noise in all wavelet coefficients by applying individual adaptive wavelet thresholds. The effectiveness of this method is demonstrated using both simulation and experimental case studies of inline Raman monitoring of continuous buckypaper manufacturing. The proposed method allows for a significant reduction of Raman data acquisition time without much loss of S/N ratio, which inherently enables Raman spectroscopy for inline monitoring and control for continuous nanomanufacturing processes.},
  file = {/Users/hyan46/Dropbox (ASU)/ZoteroData/Yue et al_2017_Generalized Wavelet Shrinkage of Inline Raman Spectroscopy for Quality2.pdf},
  keywords = {Application: Manufacturing,Application: Nano,Method: Functional,Method: Sparse,Problem: Process Monitoring},
  number = {1}
}

@article{yueTensor2020,
  ids = {yueTensor2020a},
  title = {Tensor {{Mixed Effects Model With Application}} to {{Nanomanufacturing Inspection}}},
  author = {Yue, Xiaowei and Park, Jin Gyu and Liang, Zhiyong and Shi, Jianjun},
  date = {2020-01-02},
  journaltitle = {Technometrics},
  shortjournal = {Technometrics},
  volume = {62},
  pages = {116--129},
  issn = {0040-1706, 1537-2723},
  doi = {10.1080/00401706.2019.1592783},
  url = {https://www.tandfonline.com/doi/full/10.1080/00401706.2019.1592783},
  urldate = {2020-07-15},
  abstract = {Raman mapping technique has been used to perform in-line quality inspections of nanomanufacturing processes. In such an application, massive high-dimensional Raman mapping data with mixed effects is generated. In general, fixed effects and random effects in the multi-array Raman data are associated with different quality characteristics such as fabrication consistency, uniformity, defects, et al. The existing tensor decomposition methods cannot separate mixed effects, and existing mixed effects model can only handle matrix data but not high-dimensional multi-array data. In this paper, we propose a tensor mixed effects (TME) model to analyze massive high-dimensional Raman mapping data with complex structure. The proposed TME model can (i) separate fixed effects and random effects in a tensor domain; (ii) explore the correlations along different dimensions; and (iii) realize efficient parameter estimation by a proposed iterative double Flip-Flop algorithm. We also investigate the properties of the TME model, existence and identifiability of parameter estimation. The numerical analysis demonstrates the efficiency and accuracy of the parameter estimation in the TME model. Convergence and asymptotic properties are discussed in the simulation and surrogate data analysis. The case study shows an application of the TME model in quantifying the influence of alignment on carbon nanotubes buckypaper. Moreover, the TME model can be applied to provide potential solutions for a family of tensor data analytics problems with mixed effects.},
  file = {/Users/hyan46/Dropbox (ASU)/ZoteroData/Yue et al_2020_Tensor Mixed Effects Model With Application to Nanomanufacturing Inspection.pdf},
  keywords = {Method: Tensor},
  langid = {english},
  number = {1}
}

@article{yueWaveletBased2018,
  title = {A {{Wavelet}}-{{Based Penalized Mixed}}-{{Effects Decomposition}} for {{Multichannel Profile Detection}} of {{In}}-{{Line Raman Spectroscopy}}},
  author = {Yue, Xiaowei and Yan, Hao and Park, Jin Gyu and Liang, Zhiyong and Shi, Jianjun},
  date = {2018-07},
  journaltitle = {IEEE Transactions on Automation Science and Engineering},
  volume = {15},
  pages = {1258--1271},
  publisher = {{Institute of Electrical and Electronics Engineers Inc.}},
  issn = {15455955},
  doi = {10.1109/TASE.2017.2772218},
  abstract = {Modeling and analysis of profiles, especially high-dimensional nonlinear profiles, is an important and challenging topic in statistical process control. Conventional mixed-effects models have several limitations in solving the multichannel profile detection problems for in-line Raman spectroscopy, such as the inability to separate defective information from random effects, computational inefficiency, and inability to handle high-dimensional extracted coefficients. In this paper, a new wavelet-based penalized mixed-effects decomposition (PMD) method is proposed to solve the multichannel profile detection problem in Raman spectroscopy. The proposed PMD exploits a regularized high-dimensional regression with linear constraints to decompose the profiles into four parts: fixed effects, normal effects, defective effects, and signal-dependent noise. An optimization algorithm based on the accelerated proximal gradient (APG) is developed to do parameter estimation efficiently for the proposed model. Finally, the separated fixed effects coefficients, normal effects coefficients, and defective effects coefficients can be used to extract the quality features of fabrication consistency, within-sample uniformity, and defect information, respectively. Using a surrogated data analysis and a case study, we evaluated the performance of the proposed PMD method and demonstrated a better detection power with less computational time. Note to Practitioners - This paper was motivated by the need of implementing multichannel profile detection for Raman spectra to realize in-line process monitoring and quality control of continuous manufacturing of carbon nanotube (CNT) buckypaper. Existing approaches, such as the mixed-effects model or the smooth-sparse decomposition method, cannot separate defective information in random effects effectively. This paper develops a penalized mixed-effects decomposition which decomposes Raman spectra into four components: fixed effects, normal effects, defective effects, and signal-dependent noise, respectively. The first three components can be applied to monitor the fabrication consistency, degree of uniformity, and defect information of buckypaper, respectively. With this new approach, several quality features can be monitored simultaneously and the algorithm based on the accelerated proximal gradient (APG) method can satisfy the computation speed requirement of in-line monitoring. This paper provides a solid foundation for in-line process monitoring and quality control for scalable nanomanufacturing of CNT buckypaper. Furthermore, the developed methodology can be applied in the decomposition of other signal systems with fixed, normal, and defective effects.},
  file = {/Users/hyan46/Dropbox (ASU)/ZoteroData/Yue et al_2018_A Wavelet-Based Penalized Mixed-Effects Decomposition for Multichannel Profile2.pdf},
  keywords = {Application: Manufacturing,Application: Nano,Data: Profiles,Method: Functional,Problem: Process Monitoring},
  number = {3}
}

@article{yuMonitoring2019,
  title = {Monitoring the Data Quality of Data Streams Using a Two-Step Control Scheme},
  author = {Yu, Miaomiao and Wu, Chunjie and Tsung, Fugee},
  date = {2019-09-02},
  journaltitle = {IISE Transactions},
  shortjournal = {IISE Transactions},
  volume = {51},
  pages = {985--998},
  issn = {2472-5854, 2472-5862},
  doi = {10.1080/24725854.2018.1530487},
  url = {https://www.tandfonline.com/doi/full/10.1080/24725854.2018.1530487},
  urldate = {2020-07-20},
  abstract = {Data-rich environments provide unprecedented opportunities for monitoring data quality. This article focuses on the quality of data streams. We use indicator variables to measure the six dimensions of data quality and a glitch index to indicate the poor level of quality. A two-step control scheme is proposed considering two relationships: the inter- and intra-correlation. In the first step, the Mahalanobis distance is applied to an v2-type control chart to monitor the quality of a data stream. In the second step, a Shewhart control chart is built based on a weighted-sum statistic, which measures the quality of the whole process. The feasibility and effectiveness of the control scheme are illustrated through detailed simulation studies and one landslide example. The simulated results, considering the three cases of no correlation, low correlation, and high correlation, show that the proposed approach can detect the mean shift in multi-attribute data sensitively and robustly. The example, in which sensors are used to collect data on accelerations in Taiwan, demonstrates the superiority of our design over four traditional control charts, producing the closest type-I error to the given level and the highest power under the same type-I error.},
  file = {/Users/hyan46/Dropbox (ASU)/ZoteroData/Yu et al_2019_Monitoring the data quality of data streams using a two-step control scheme.pdf},
  keywords = {Application: Manufacturing,Problem: Process Monitoring},
  langid = {english},
  number = {9}
}

@article{yuMultimode2008,
  title = {Multimode Process Monitoring with {{Bayesian}} Inference-Based Finite {{Gaussian}} Mixture Models},
  author = {Yu, Jie and Qin, S. Joe},
  date = {2008},
  journaltitle = {AIChE Journal},
  volume = {54},
  pages = {1811--1829},
  issn = {1547-5905},
  doi = {10.1002/aic.11515},
  url = {https://aiche.onlinelibrary.wiley.com/doi/abs/10.1002/aic.11515},
  urldate = {2020-05-25},
  abstract = {For complex industrial processes with multiple operating conditions, the traditional multivariate process monitoring techniques such as principal component analysis (PCA) and partial least squares (PLS) are ill-suited because the fundamental assumption that the operating data follow a unimodal Gaussian distribution usually becomes invalid. In this article, a novel multimode process monitoring approach based on finite Gaussian mixture model (FGMM) and Bayesian inference strategy is proposed. First, the process data are assumed to be from a number of different clusters, each of which corresponds to an operating mode and can be characterized by a Gaussian component. In the absence of a priori process knowledge, the Figueiredo–Jain (F–J) algorithm is then adopted to automatically optimize the number of Gaussian components and estimate their statistical distribution parameters. With the obtained FGMM, a Bayesian inference strategy is further utilized to compute the posterior probabilities of each monitored sample belonging to the multiple components and derive an integrated global probabilistic index for fault detection of multimode processes. The validity and effectiveness of the proposed monitoring approach are illustrated through three examples: (1) a simple multivariate linear system, (2) a simulated continuous stirred tank heater (CSTH) process, and (3) the Tennessee Eastman challenge problem. The comparison of monitoring results demonstrates that the proposed approach is superior to the conventional PCA method and can achieve accurate and early detection of various types of faults in multimode processes. © 2008 American Institute of Chemical Engineers AIChE J, 2008},
  annotation = {\_eprint: https://aiche.onlinelibrary.wiley.com/doi/pdf/10.1002/aic.11515},
  file = {/Users/hyan46/Zotero/storage/PL6PMWGS/aic.html},
  keywords = {Bayesian inference,fault detection,finite Gaussian mixture model,global probabilistic index,Mahalanobis distance,Method: Bayesian,multimode,multimode process monitoring,Problem: Process Monitoring,Tennessee Eastman chemical process},
  langid = {english},
  number = {7}
}

@article{yuRobust2018,
  title = {A Robust {{CUSUM}} Scheme with a Weighted Likelihood Ratio to Monitor an Overdispersed Counting Process},
  author = {Yu, Miaomiao and Wu, Chunjie and Wang, Zhijun and Tsung, Fugee},
  date = {2018-12},
  journaltitle = {Computers \& Industrial Engineering},
  shortjournal = {Computers \& Industrial Engineering},
  volume = {126},
  pages = {165--174},
  issn = {03608352},
  doi = {10.1016/j.cie.2018.09.029},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0360835218304455},
  urldate = {2020-07-20},
  abstract = {The Poisson cumulative sum (CUSUM) control chart is a method to monitor count data, which are commonly modeled by a Poisson distribution. However, the assumption of a Poisson distribution may not be valid in practice and the robustness of the Poisson CUSUM chart is shown to be poor when the volatility is greater than expected, a phenomenon known as overdispersion. Motivated by this, we propose an improved weighted Poisson CUSUM control chart based on the weighted log-likelihood ratio. For the purpose of discounting the unexplained volatility, smaller weights are assigned to the larger shifts. The continuity, monotonicity and convergence of the cumulative statistic proved in this paper make the design more practical. Compared with the conventional Poisson CUSUM and the Winsorized Poisson CUSUM control charts, the new weighted Poisson CUSUM scheme performs most robustly under overdispersion. In addition, the fast initial response (FIR) feature makes the chart more sensitive to start-up cases. A real-data example of monitoring daily orders on a start-up E-commerce company illustrates the superiorities of the proposed scheme.},
  file = {/Users/hyan46/Dropbox (ASU)/ZoteroData/Yu et al_2018_A robust CUSUM scheme with a weighted likelihood ratio to monitor an.pdf},
  langid = {english}
}

@article{zerehsazTool2019,
  title = {Tool Wear Monitoring in Ultrasonic Welding Using High-Order Decomposition},
  author = {Zerehsaz, Yaser and Shao, Chenhui and Jin, Jionghua},
  date = {2019-02},
  journaltitle = {Journal of Intelligent Manufacturing},
  shortjournal = {J Intell Manuf},
  volume = {30},
  pages = {657--669},
  issn = {0956-5515, 1572-8145},
  doi = {10.1007/s10845-016-1272-4},
  url = {http://link.springer.com/10.1007/s10845-016-1272-4},
  urldate = {2020-07-04},
  abstract = {Ultrasonic welding has been used for joining lithium-ion battery cells in electric vehicle manufacturing. The geometric profile change of tool shape significantly affects the weld quality and should be monitored during production. In this paper, a high-order decomposition method is suggested for tool wear monitoring. In the proposed monitoring scheme, a low dimensional set of monitoring features is extracted from the high dimensional tool profile measurement data for detecting tool wear at an early stage. Furthermore, the proposed method can be effectively used to analyze the data cross-correlation structure in order to help identify the unusual wear pattern and find the associated assignable cause. The effectiveness of the proposed monitoring method was demonstrated using a simulation and a real-world case study.},
  file = {/Users/hyan46/Dropbox (ASU)/ZoteroData/Zerehsaz et al_2019_Tool wear monitoring in ultrasonic welding using high-order decomposition.pdf},
  keywords = {Method: Tensor,People: Judy Jin},
  langid = {english},
  number = {2}
}

@article{zhangDynamic2020,
  title = {Dynamic {{Multivariate Functional Data Modeling}} via {{Sparse Subspace Learning}}},
  author = {Zhang, Chen and Yan, Hao and Lee, Seungho and Shi, Jianjun},
  date = {2020},
  journaltitle = {Technometrics},
  doi = {10.1080/00401706.2020.1800516},
  url = {http://arxiv.org/abs/1804.03797},
  abstract = {Multivariate functional data from a complex system are naturally high-dimensional and have complex cross-correlation structure. The complexity of data structure can be observed as that (1) some functions are strongly correlated with similar features, while some others may have almost no cross-correlations with quite diverse features; and (2) the cross-correlation structure may also change over time due to the system evolution. With this regard, this paper presents a dynamic subspace learning method for multivariate functional data modeling. In particular, we consider different functions come from different subspaces, and only functions of the same subspace have cross-correlations with each other. The subspaces can be automatically formulated and learned by reformatting the problem as a sparse regression. By allowing but regularizing the regression change over time, we can describe the cross-correlation dynamics. The model can be efficiently estimated by the fast iterative shrinkage-thresholding algorithm (FISTA), and the features of every subspace can be extracted using the smooth multi-channel functional PCA. Numerical studies together with case studies demonstrate the efficiency and applicability of the proposed methodology.},
  annotation = {\_eprint: 1804.03797},
  file = {/Users/hyan46/Dropbox (ASU)/ZoteroData/Zhang et al_2020_Dynamic Multivariate Functional Data Modeling via Sparse Subspace Learning2.pdf},
  keywords = {Application: Human Motion,Application: Semiconductor,Data: Profiles,Method: Functional,Method: Sparse}
}

@article{zhangMultiArmedSubmitted,
  title = {A {{Multi}}-{{Armed Bandit Approach}} for {{Online Monitoring High}}-{{Dimensional Data}} in {{Resource}}-{{Constrained Environments}}},
  author = {Zhang, Wanrong and Mei, Yajun},
  year = {Submitted},
  journaltitle = {Technometrics},
  pages = {35},
  abstract = {We investigate the problem of online monitoring of high-dimensional streaming data in resource-constrained environments where one is only able to observe a limited number of local components of data per time step. It is assumed that an undesired event might occur and change the distributions of some unknown components of data at some unknown time. The objective is to decide how to choose the observed local data components smartly and how to raise a correct global-level alarm to detect the undesired event quickly. We propose to combine multi-armed bandit approaches with sequential change-point detection to develop an efficient algorithm, termed ThompsonSampling-Shiryaev-Roberts-Pollak (TSSRP) algorithm that consists of two policies per time step. The adaptive sampling policy is based on the Thompson Sampling algorithm that balances between exploration for acquiring long-term knowledge and exploitation for immediate reward gain. The statistical decision policy fuses the local ShiryaevRoberts-Pollak statistics to determine whether to raise a global alarm by sum shrinkage technique. Extensive numerical simulations and two case studies demonstrate the statistical and computational efficiency of our proposed TSSRP algorithm.},
  file = {/Users/hyan46/Dropbox (ASU)/ZoteroData/Zhang_Mei_Submitted_A Multi-Armed Bandit Approach for Online Monitoring High-Dimensional Data in.pdf},
  langid = {english}
}

@article{zhangMultiple2018,
  title = {Multiple Profiles Sensor-Based Monitoring and Anomaly Detection},
  author = {Zhang, Chen and Yan, Hao and Lee, Seungho and Shi, Jianjun},
  date = {2018},
  journaltitle = {Journal of Quality Technology},
  volume = {50},
  pages = {344--362},
  publisher = {{American Society for Quality}},
  issn = {00224065},
  doi = {10.1080/00224065.2018.1508275},
  abstract = {Generally, in an advanced manufacturing system hundreds of sensors are deployed to measure key process variables in real time. Thus it is desirable to develop methodologies to use real-time sensor data for on-line system condition monitoring and anomaly detection. However, there are several challenges in developing an effective process monitoring system: (i) data streams generated by multiple sensors are high-dimensional profiles; (ii) sensor signals are affected by noise due to system-inherent variations; (iii) signals of different sensors have cluster-wise features; and (iv) an anomaly may cause only sparse changes of sensor signals. To address these challenges, this article presents a real-time multiple profiles sensor-based process monitoring system, which includes the following modules: (i) preprocessing sensor signals to remove inherent variations and conduct profile alignments, (ii) using multichannel functional principal component analysis (MFPCA)–based methods to extract sensor features by considering cluster-wise between-sensor correlations, and (iii) constructing a monitoring scheme with the top-R strategy based on the extracted features, which has scalable detection power for different fault patterns. Finally, we implement and demonstrate the proposed framework using data from a real manufacturing system.},
  file = {/Users/hyan46/Dropbox (ASU)/ZoteroData/Zhang et al_2018_Multiple profiles sensor-based monitoring and anomaly detection2.pdf},
  keywords = {Application: Semiconductor,Data: Profiles,Problem: Process Monitoring},
  number = {4}
}

@article{zhangOptimization2014,
  title = {Optimization of {{Wind Power}} and {{Its Variability With}} a {{Computational Intelligence Approach}}},
  author = {Zhang, Zijun and Zhou, Qiang and Kusiak, Andrew},
  date = {2014-01},
  journaltitle = {IEEE Transactions on Sustainable Energy},
  shortjournal = {IEEE Trans. Sustain. Energy},
  volume = {5},
  pages = {228--236},
  issn = {1949-3029, 1949-3037},
  doi = {10.1109/TSTE.2013.2281354},
  url = {http://ieeexplore.ieee.org/document/6626554/},
  urldate = {2020-07-07},
  abstract = {An optimization model is presented for maximizing the generation of wind power while minimizing its variability. In the optimization model, data-driven approaches are used to model the wind-power generation process based on industrial data. A new constraint is developed for governing the data-driven wind-power generation model based on physics and statistical process control theory. Since the wind-power model is nonparametric, computational intelligence algorithms are utilized to solve the optimization model. Computer experiments are designed to compare the performance of computational intelligence algorithms. The improvement in the generated wind power and its variability is demonstrated with the computational results.},
  file = {/Users/hyan46/Dropbox (ASU)/ZoteroData/Zhang et al_2014_Optimization of Wind Power and Its Variability With a Computational.pdf},
  keywords = {Application: Wind Turbine,Method: Deep Learning},
  langid = {english},
  number = {1}
}

@article{zhangWeakly2018,
  title = {Weakly Correlated Profile Monitoring Based on Sparse Multi-Channel Functional Principal Component Analysis},
  author = {Zhang, Chen and Yan, Hao and Lee, Seungho and Shi, Jianjun},
  date = {2018-10},
  journaltitle = {IISE Transactions},
  volume = {50},
  pages = {878--891},
  publisher = {{Taylor and Francis Ltd.}},
  issn = {24725862},
  doi = {10.1080/24725854.2018.1451012},
  abstract = {Although several works have been proposed for multi-channel profile monitoring, two additional challenges are yet to be addressed: (i) how to model complex correlations of multi-channel profiles when different profiles have different features (i.e., weakly or sparsely correlated); (ii) how to efficiently detect sparse changes occurring in only a small segment of a few profiles. To fill this research gap, our contributions are twofold. First, we propose a novel Sparse Multi-channel Functional Principal Component Analysis (SMFPCA) to model multi-channel profiles. SMFPCA can not only flexibly describe the correlation structure of multiple, or even high-dimensional, profiles with distinct features, but also achieve sparse PCA scores which are easily interpretable. Second, we propose an efficient convergence-guaranteed optimization algorithm to solve SMFPCA in real time based on the block coordinate descent algorithm. Third, as the SMFPCA scores can naturally identify sparse out-of-control (OC) patterns, we use the scores to construct a monitoring scheme which provides increased sensitivity to sparse OC changes. Numerical studies together with a real case study in a manufacturing system demonstrate the effectiveness of the developed methodology.},
  file = {/Users/hyan46/Dropbox (ASU)/ZoteroData/Zhang et al_2018_Weakly correlated profile monitoring based on sparse multi-channel functional2.pdf},
  keywords = {Application: Semiconductor,Data: Profiles,Method: Functional,Method: Sparse,Problem: Process Monitoring},
  number = {10}
}

@article{zhaoDeepInReview,
  title = {Deep {{Spatio}}-Temporal {{Sparse Decomposition}} for {{Trend Prediction}} and {{Anomaly Detection}} in {{Cardiac Electrical Conduction}}},
  author = {Zhao, Xinyu and Yan, Hao and Hu, Zhiyong and Du, Dongping},
  year = {In Review},
  journaltitle = {IISE Transactions on Healthcare Systems Engineering},
  abstract = {Electrical conduction among cardiac tissue is commonly modeled with partial differential equations, i.e., reaction-diffusion equation, where the reaction term describes cellular stimulation and diffusion term describes electrical propagation. Detecting and identification of cardiac cells that produce abnormal electrical impulses in such nonlinear dynamic systems are important for efficient treatment and planning. To model the nonlinear dynamics, simulation has been widely used in both cardiac research and clinical study to investigate cardiac disease mechanisms and develop new treatment design. However, existing cardiac models have a great level of complexity, and the simulation is often time-consuming. We propose a deep spatio-temporal sparse decomposition (DSTSD) approach to bypass the time-consuming cardiac partial differential equations with the deep spatio-temporal model and to detect the time and location of the anomaly (i.e., malfunctioning cardiac cells). This approach is validated from the data set generated from the Courtemanche-Ramirez-Nattel (CRN) model, which is widely used to model the propagation of the transmembrane potential across the cross the neuron membrane. The proposed DSTSD achieved the best accuracy in terms of spatio-temporal mean trend prediction and anomaly detection.},
  keywords = {Application: Cardiac,Data: Signal,Method: Deep Learning,Problem: Anomaly Detection}
}

@inproceedings{zhaoHierarchical2021,
  title = {Hierarchical {{Tree}}-Based {{Sequential Event Prediction}} with {{Application}} in the {{Aviation Accident Report}}},
  booktitle = {Proceedings 37th {{IEEE}} International Conference on Data Engineering},
  author = {Zhao, Xinyu and Yan, Hao and Liu, Yongming},
  date = {2021},
  doi = {10.1109/ICDE51399.2021.00178},
  abstract = {Sequential event prediction is a well-studied area and has been widely used in proactive management, recommender systems and healthcare. One major assumption of the existing sequential event prediction methods is that similar event sequence patterns in the historical record will repeat themselves, enabling us to predict future events. However, in reality, the assumption becomes less convincing when we are trying to predict rare or unique sequences. Furthermore, the representation of the event may be complex with hierarchical structures. In this paper, we aim to solve this issue by taking advantage of the multi-level or hierarchical representation of these rare events. We proposed to build a sequential Encoder-Decoder framework to predict the event sequences. More specifically, in the encoding layer, we built a hierarchical embedding representation for the events. In the decoding layer, we first predict the high-level events and the low-level events are generated according to a hierarchical graphical structure. We propose to link the encoding decoding layers with the temporal models for future event prediction. In this article, we further discussed applying the proposed model into the failure event prediction according to the aviation accident reports and have shown improved accuracy and model interpretability.},
  eventtitle = {{{IEEE}} International Conference on Data Engineering},
  keywords = {Application: Traffic,Data: Text,Method: Deep Learning,Problem: Classification}
}

@inproceedings{zhaoRapid2019,
  title = {Rapid {{Detection}} of {{Hot}}-Spot by {{Tensor Decomposition}} with {{Application}} to {{Weekly Gonorrhea Data}}},
  booktitle = {The {{XIIIth International Workshop}} on {{Intelligent Statistical Quality Control}},},
  author = {Zhao, Yujie and Yan, Hao and Holte, Sarah E. and Kerani, Roxanne P. and Mei, Yajun},
  date = {2019-01},
  pages = {289--310},
  location = {{Hong Kong}},
  doi = {10.1080/00224065.2021.1903822},
  url = {http://arxiv.org/abs/2001.11685},
  abstract = {In many bio-surveillance and healthcare applications, data sources are measured from many spatial locations repeatedly over time, say, daily/weekly/monthly. In these applications, we are typically interested in detecting hot-spots, which are defined as some structured outliers that are sparse over the spatial domain but persistent over time. In this paper, we propose a tensor decomposition method to detect when and where the hot-spots occur. Our proposed methods represent the observed raw data as a three-dimensional tensor including a circular time dimension for daily/weekly/monthly patterns, and then decompose the tensor into three components: smooth global trend, local hot-spots, and residuals. A combination of LASSO and fused LASSO is used to estimate the model parameters, and a CUSUM procedure is applied to detect when and where the hot-spots might occur. The usefulness of our proposed methodology is validated through numerical simulation and a real-world dataset in the weekly number of gonorrhea cases from \$2006\$ to \$2018\$ for \$50\$ states in the United States.},
  annotation = {\_eprint: 2001.11685},
  file = {/Users/hyan46/Dropbox (ASU)/ZoteroData/Zhao et al_2019_Rapid Detection of Hot-spot by Tensor Decomposition with Application to Weekly2.pdf},
  keywords = {Appplication: Health,Data: Time Series,Method: Tensor,Problem: Anomaly Detection}
}

@article{zhaoRapid2021,
  title = {Rapid {{Detection}} of {{Hot}}-Spots via {{Tensor Decomposition}} with Applications to {{Crime Rate Data}}},
  author = {Zhao, Yujie and Yan, Hao and Holte, Sarah and Mei, Yajun},
  date = {2021},
  journaltitle = {Journal of Applied Statistics},
  doi = {10.1080/02664763.2021.1874892},
  url = {http://arxiv.org/abs/2004.11710},
  abstract = {We propose an efficient statistical method (denoted as SSR-Tensor) to robustly and quickly detect hot-spots that are sparse and temporal-consistent in a spatial-temporal dataset through the tensor decomposition. Our main idea is to first build an SSR model to decompose the tensor data into a Smooth global trend mean, Sparse local hot-spots and Residuals. Next, tensor decomposition is utilized as follows: basis are introduced to describe within-dimension correlation and tensor products are used for between-dimension interaction. Then, a combination of LASSO and fused LASSO is used to estimate the model parameters, where an efficient recursive estimation procedure is developed based on the large-scale convex optimization, where we first transform the general LASSO optimization into regular LASSO optimization and apply FISTA to solve it with the fastest convergence rate. Finally, a CUSUM procedure is applied to detect when and where the hot-spot event occurs. We compare the performance of the proposed method in a numerical simulation and a real-world dataset, which is a collection of three types of crime rates for U.S. mainland states during the year 1965-2014. In both cases, the proposed SSR-Tensor is able to achieve the fast detection and accurate localization of the hot-spots.},
  annotation = {\_eprint: 2004.11710},
  file = {/Users/hyan46/Dropbox (ASU)/ZoteroData/Zhao et al_2021_Rapid Detection of Hot-spots via Tensor Decomposition with applications to.pdf},
  keywords = {Application: Social,Data: Video,Method: Tensor,Problem: Anomaly Detection}
}

@inproceedings{zhaoSimultaneous2021,
  title = {Simultaneous {{Material Microstructure Classification}} and {{Discovery}} via {{Hidden Markov Modeling}} of {{Acoustic Emission Signals}}},
  author = {Zhao, Xinyu and Iquebal, Ashif and Sun, Huifeng and Yan, Hao},
  date = {2021-01-15},
  publisher = {{American Society of Mechanical Engineers Digital Collection}},
  doi = {10.1115/MSEC2020-8454},
  url = {https://asmedigitalcollection.asme.org/MSEC/proceedings/MSEC2020/84263/V002T07A035/1095794},
  urldate = {2021-01-27},
  abstract = {Acoustic emission (AE) signals have been widely employed for tracking material properties and structural characteristics. In this study, we aim to analyze the AE signals gathered during a scanning probe lithography process to classify the known microstructure types and discover unknown surface microstructures/anomalies. To achieve this, we developed a Hidden Markov Model to consider the temporal dependency of the high-resolution AE data. Furthermore, we compute the posterior classification probability and the negative likelihood score for microstructure classification and discovery. Subsequently, we present a diagnostic procedure to identify the dominant AE frequencies that allow us to track the microstructural characteristics. Finally, we apply the proposed approach to identify the surface microstructures of additively manufactured Ti-6Al-4V and show that it not only achieved a high classification accuracy (e.g., more than 90\%) but also correctly identified the microstructural anomalies that may be subjected further investigation to discover new material phases/properties.},
  eventtitle = {{{ASME}} 2020 15th {{International Manufacturing Science}} and {{Engineering Conference}}},
  keywords = {Application: Additive Manufacturing,Data: Time Series,Method: Temporal,Problem: Classification},
  langid = {english}
}

@article{zhaoSpatiotemporal2019,
  title = {Spatio-Temporal {{Anomaly Detection}}, {{Diagnostics}}, and {{Prediction}} of the {{Air}}-Traffic {{Trajectory Deviation}} Using the {{Convective Weather}}},
  author = {Zhao, Xinyu and Yan, Hao and Li, Jing and Pang, Yutian and Liu, Yongming},
  date = {2019-09-22},
  journaltitle = {Annual Conference of the PHM Society},
  volume = {11},
  issn = {2325-0178},
  doi = {10.36001/phmconf.2019.v11i1.854},
  url = {http://www.phmpapers.org/index.php/phmconf/article/view/854},
  urldate = {2020-06-04},
  abstract = {With ahead-of-time aircraft management, we are able to re- duce aircraft collision and improve air traffic capacity. How- ever, there are various impact factors which will cause a large deviation between the actual flight and the original flight plan. Such uncertainty will result in an inappropriate decision for flight management. In order to solve this problem, most of the existing research attempt to build up a stochastic trajec- tory prediction model to capture the influence of the weather. However, the complexity of the weather information and vari- ous human factors make it hard to build up an accurate trajec- tory prediction framework. Our approach considers the prob- lem of trajectory deviation as the ”anomaly” and builds up an analytics pipeline for anomaly detection, anomaly diagnos- tics, and anomaly prediction. For anomaly detection, we pro- pose to apply the CUSUM chart to detect the abnormal tra- jectory point which differs from the flight plan. For anomaly diagnostics, we would like to link the entire anomalous trajec- tory sequences with the convective weather data and extract important features based on time-series feature engineering. Furthermore, XGBoost was applied to detect the anomalous trajectory sequences based on the time-series features. For anomaly prediction, we will build up a point-wise prediction framework based on the Hidden Markov Model and Convectional LSTM to predict the probability that the pilot would deviate from the flight plan. Finally, we demonstrate the sig- nificance of the proposed method using real flight data from JFK to LAX.},
  file = {/Users/hyan46/Zotero/storage/NH8KLL4K/854.html},
  issue = {1},
  keywords = {Application: Traffic,Problem: Anomaly Detection,Problem: Classification},
  langid = {english},
  number = {1}
}

@article{zhaoSystem2015,
  title = {System {{Informatics}}: {{From Methodology}} to {{Applications}}},
  shorttitle = {System {{Informatics}}},
  author = {Zhao, Kang and Xie, Yao and Tsui, Kwok-Leung and Wei, Qingming and Huang, Wenpo and Jiang, Wei and Li, Yanting and Cho, Sugon and Kim, Seoung Bum and Liu, Kaibo and Shi, Jianjun and Jeong, Young-Seon and Kim, Byunghoon and Tong, Seung Hoon and Chang, In-Kap and Jeong, Myong K. and Charruaud, Florent and Li, Lishuai},
  date = {2015-11},
  journaltitle = {IEEE Intelligent Systems},
  shortjournal = {IEEE Intell. Syst.},
  volume = {30},
  pages = {12--29},
  issn = {1541-1672},
  doi = {10.1109/MIS.2015.111},
  url = {http://ieeexplore.ieee.org/document/7320917/},
  urldate = {2020-07-04},
  file = {/Users/hyan46/Dropbox (ASU)/ZoteroData/Zhao et al_2015_System Informatics.pdf},
  keywords = {People: Wei Jiang},
  langid = {english},
  number = {6}
}

@article{zhengAnatomicallyconstrained2020,
  title = {Anatomically-Constrained {{Deep Learning}} for {{Automating Dental CBCT Segmentation}} and {{Lesion Detection}}},
  author = {Zheng, Zhiyang and Yan, Hao and Setzer, Frank and Shi, Katherine and Mupparapu, Mel and Li, Jing},
  date = {2020},
  journaltitle = {IEEE Transactions on Automation Science and Engineering},
  volume = {18},
  pages = {603--614},
  doi = {10.1109/TASE.2020.3025871},
  abstract = {Compared with the rapidly growing artificial intelligence (AI) research in other branches of healthcare, the pace of developing AI capacities in dental care is relatively slow. Dental care automation, especially the automated capability for dental cone beam computed tomography (CBCT) segmentation and lesion detection, is highly needed. CBCT is an important imaging modality that is experiencing ever-growing utilization in various dental specialties. However, little research has been done for segmenting different structures, restorative materials, and lesions using deep learning. This is due to multifold challenges such as content-rich oral cavity and significant within-label variation on each CBCT image as well as the inherent difficulty of obtaining many high-quality labeled images for training. On the other hand, oral-anatomical knowledge exists in dentistry, which shall be leveraged and integrated into the deep learning design. In this article, we propose a novel anatomically constrained Dense U-Net for integrating oral-anatomical knowledge with data-driven Dense U-Net. The proposed algorithm is formulated as a regularized or constrained optimization and solved using mean-field variational approximation to achieve computational efficiency. Mathematical encoding for transforming descriptive knowledge into a quantitative form is also proposed. Our experiment demonstrates that the proposed algorithm outperforms the standard Dense U-Net in both lesion detection accuracy and dice coefficient (DICE) indices in multilabel segmentation. Benefited from the integration with anatomical domain knowledge, our algorithm performs well with data from a small number of patients included in the training. Note to Practitioners —This article proposes a novel deep learning algorithm to enable the automated capability for cone beam computed tomography (CBCT) segmentation and lesion detection. Despite the growing adoption of CBCT in various dental specialties, such capability is curren...},
  file = {/Users/hyan46/Dropbox (ASU)/ZoteroData/Zheng et al_2020_Anatomically-constrained Deep Learning for Automating Dental CBCT Segmentation.pdf},
  keywords = {Application: Dental,Application: Health,Data: Image,Method: Deep Learning,Method: Physics},
  number = {2}
}

@article{zhengTopic2016,
  title = {Topic Tensor Factorization for Recommender System},
  author = {Zheng, Xiaolin and Ding, Weifeng and Lin, Zhen and Chen, Chaochao},
  date = {2016-12-01},
  journaltitle = {Information Sciences},
  shortjournal = {Information Sciences},
  volume = {372},
  pages = {276--293},
  issn = {0020-0255},
  doi = {10.1016/j.ins.2016.08.042},
  url = {http://www.sciencedirect.com/science/article/pii/S0020025516306144},
  urldate = {2020-05-31},
  abstract = {Reviews are collaboratively generated by users on items and generally contain rich information than ratings in a recommender system scenario. Ratings are modeled successfully with latent space models by capturing interaction between users and items. However, only a few models collaboratively deal with documents such as reviews. In this study, by modeling reviews as a three-order tensor, we propose a refined tensor topic model (TTM) for text tensors inspired by Tucker decomposition. User and item dimensions are co-reduced with vocabulary space, and interactions between users and items are captured using a core tensor in dimension-reduced form. TTM is proposed to obtain low-rank representations of words as well as of users and items. Furthermore, general rules are developed to transform a decomposition model into a probabilistic model. TTM is augmented further to predict ratings with the assistance of a low-dimensional representation of users and items obtained by TTM. This augmented model is called matrix factorization by learning a bilinear map. A core regularized version is further developed to incorporate additional information from the TTM. Encouraging experimental results not only show that the TTM outperforms existing topic models in modeling texts with a user-item-word structure, but also show that our proposed rating prediction models outperform state-of-the-art approaches.},
  file = {/Users/hyan46/Dropbox (ASU)/ZoteroData/Zheng et al_2016_Topic tensor factorization for recommender system2.pdf},
  keywords = {Dimension reduction,Method: Tensor,Recommender system,Tensor decomposition,Text modeling,Topic model},
  langid = {english}
}

@article{zhouAutomatic2016,
  title = {An {{Automatic Process Monitoring Method Using Recurrence Plot}} in {{Progressive Stamping Processes}}},
  author = {Zhou, Cheng and Liu, Kaibo and Zhang, Xi and Zhang, Weidong and Shi, Jianjun},
  date = {2016-04},
  journaltitle = {IEEE Transactions on Automation Science and Engineering},
  shortjournal = {IEEE Trans. Automat. Sci. Eng.},
  volume = {13},
  pages = {1102--1111},
  issn = {1545-5955, 1558-3783},
  doi = {10.1109/TASE.2015.2468058},
  url = {http://ieeexplore.ieee.org/document/7239651/},
  urldate = {2020-07-04},
  abstract = {In progressive stamping processes, condition monitoring based on tonnage signals is of great practical significance. One typical fault in progressive stamping processes is a missing part in one of the die stations due to malfunction of part transfer in the press. One challenging question is how to detect the fault due to the missing part in certain die stations as such a fault often results in die or press damage, but only provides a small change in the tonnage signals. To address this issue, this article proposes a novel automatic process monitoring method using the recurrence plot (RP) method. Along with the developed method, we also provide a detailed interpretation of the representative patterns in the recurrence plot. Then, the corresponding relationship between the RPs and the tonnage signals under different process conditions is fully investigated. To differentiate the tonnage signals under normal and faulty conditions, we adopt the recurrence quantification analysis (RQA) to characterize the critical patterns in the RPs. A parameter learning algorithm is developed to set up the appropriate parameter of the RP method for progressive stamping processes. A real case study is provided to validate our approach, and the results are compared with the existing literature to demonstrate the outperformance of this proposed monitoring method.},
  file = {/Users/hyan46/Dropbox (ASU)/ZoteroData/Zhou et al_2016_An Automatic Process Monitoring Method Using Recurrence Plot in Progressive.pdf},
  keywords = {Application: Stamping,People: Kaibo Liu,Problem: Process Monitoring},
  langid = {english},
  number = {2}
}

@article{zhouLearning,
  title = {Learning {{Social Infectivity}} in {{Sparse Low}}-Rank {{Networks Using Multi}}-Dimensional {{Hawkes Processes}}},
  author = {Zhou, Ke and Zha, Hongyuan and Song, Le},
  pages = {9},
  file = {/Users/hyan46/Dropbox (ASU)/ZoteroData/Zhou et al_Learning Social Infectivity in Sparse Low-rank Networks Using Multi-dimensional.pdf},
  langid = {english}
}

@inproceedings{zhouLearning2013,
  title = {Learning {{Triggering Kernels}} for {{Multi}}-Dimensional {{Hawkes Processes}}},
  booktitle = {International {{Conference}} on {{Machine Learning}}},
  author = {Zhou, Ke and Zha, Hongyuan and Song, Le},
  date = {2013-05-26},
  pages = {1301--1309},
  publisher = {{PMLR}},
  issn = {1938-7228},
  url = {http://proceedings.mlr.press/v28/zhou13.html},
  urldate = {2021-02-26},
  abstract = {How does the activity of one person affect that of another person? Does the strength of influence remain periodic or decay exponentially over time? In this paper, we study these critical questions ...},
  eventtitle = {International {{Conference}} on {{Machine Learning}}},
  file = {/Users/hyan46/Zotero/storage/R7PQ226W/Zhou et al. - 2013 - Learning Triggering Kernels for Multi-dimensional .pdf;/Users/hyan46/Zotero/storage/8BZIHW5E/zhou13.html},
  langid = {english}
}

@article{zhouTensor2013,
  title = {Tensor {{Regression}} with {{Applications}} in {{Neuroimaging Data Analysis}}},
  author = {Zhou, Hua and Li, Lexin and Zhu, Hongtu},
  date = {2013-06},
  journaltitle = {Journal of the American Statistical Association},
  shortjournal = {Journal of the American Statistical Association},
  volume = {108},
  pages = {540--552},
  issn = {0162-1459, 1537-274X},
  doi = {10.1080/01621459.2013.776499},
  url = {http://www.tandfonline.com/doi/abs/10.1080/01621459.2013.776499},
  urldate = {2020-08-11},
  file = {/Users/hyan46/Dropbox (ASU)/ZoteroData/Zhou et al_2013_Tensor Regression with Applications in Neuroimaging Data Analysis.pdf},
  langid = {english},
  number = {502}
}

@article{zhuBayesian2014,
  title = {Bayesian {{Inference}} with {{Posterior Regularization}} and {{Applications}} to {{Inﬁnite Latent SVMs}}},
  author = {Zhu, Jun and Chen, Ning and Xing, Eric P},
  date = {2014},
  journaltitle = {Journal of Machine Learning Research},
  volume = {15},
  pages = {1799--1847},
  abstract = {Existing Bayesian models, especially nonparametric Bayesian methods, rely on specially conceived priors to incorporate domain knowledge for discovering improved latent representations. While priors affect posterior distributions through Bayes’ rule, imposing posterior regularization is arguably more direct and in some cases more natural and general. In this paper, we present regularized Bayesian inference (RegBayes), a novel computational framework that performs posterior inference with a regularization term on the desired post-data posterior distribution under an information theoretical formulation. RegBayes is more flexible than the procedure that elicits expert knowledge via priors, and it covers both directed Bayesian networks and undirected Markov networks. When the regularization is induced from a linear operator on the posterior distributions, such as the expectation operator, we present a general convex-analysis theorem to characterize the solution of RegBayes. Furthermore, we present two concrete examples of RegBayes, infinite latent support vector machines (iLSVM) and multi-task infinite latent support vector machines (MT-iLSVM), which explore the large-margin idea in combination with a nonparametric Bayesian model for discovering predictive latent features for classification and multi-task learning, respectively. We present efficient inference methods and report empirical studies on several benchmark data sets, which appear to demonstrate the merits inherited from both large-margin learning and Bayesian nonparametrics. Such results contribute to push forward the interface between these two important subfields, which have been largely treated as isolated in the community.},
  file = {/Users/hyan46/Dropbox (ASU)/ZoteroData/Zhu et al_2014_Bayesian Inference with Posterior Regularization and Applications to Inﬁnite.pdf},
  langid = {english},
  number = {1}
}

@article{zhuDOptimal2014,
  title = {A {{D}}-{{Optimal Design}} for {{Estimation}} of {{Parameters}} of an {{Exponential}}-{{Linear Growth Curve}} of {{Nanostructures}}},
  author = {Zhu, Li and Dasgupta, Tirthankar and Huang, Qiang},
  date = {2014-10-02},
  journaltitle = {Technometrics},
  shortjournal = {Technometrics},
  volume = {56},
  pages = {432--442},
  issn = {0040-1706, 1537-2723},
  doi = {10.1080/00401706.2013.866600},
  url = {http://www.tandfonline.com/doi/full/10.1080/00401706.2013.866600},
  urldate = {2020-07-04},
  file = {/Users/hyan46/Dropbox (ASU)/ZoteroData/Zhu et al_2014_A D-Optimal Design for Estimation of Parameters of an Exponential-Linear Growth.pdf},
  keywords = {Application: Manufacturing,Application: Nano,People: Qiang Huang},
  langid = {english},
  number = {4}
}

@article{zhuEstimation2019,
  title = {Estimation of {{Bearing Remaining Useful Life Based}} on {{Multiscale Convolutional Neural Network}}},
  author = {Zhu, Jun and Chen, Nan and Peng, Weiwen},
  date = {2019-04},
  journaltitle = {IEEE Transactions on Industrial Electronics},
  volume = {66},
  pages = {3208--3216},
  issn = {1557-9948},
  doi = {10.1109/TIE.2018.2844856},
  abstract = {Bearing remaining useful life (RUL) prediction plays a crucial role in guaranteeing safe operation of machinery and reducing maintenance loss. In this paper, we present a new deep feature learning method for RUL estimation approach through time frequency representation (TFR) and multiscale convolutional neural network (MSCNN). TFR can reveal nonstationary property of a bearing degradation signal effectively. After acquiring time-series degradation signals, we get TFRs, which contain plenty of useful information using wavelet transform. Owing to high dimensionality, the size of these TFRs is reduced by bilinear interpolation, which are further regarded as inputs for deep learning models. Here, we introduce an MSCNN model structure, which keeps the global and local information synchronously compared to a traditional convolutional neural network (CNN). The salient features, which contribute for RUL estimation, can be learned automatically by MSCNN. The effectiveness of the presented method is validated by the experiment data. Compared to traditional data-driven and different CNN-based feature extraction methods, the proposed method shows enhanced performance in the prediction accuracy.},
  eventtitle = {{{IEEE Transactions}} on {{Industrial Electronics}}},
  file = {/Users/hyan46/Dropbox (ASU)/ZoteroData/Zhu et al_2019_Estimation of Bearing Remaining Useful Life Based on Multiscale Convolutional2.pdf;/Users/hyan46/Zotero/storage/3H9A27KC/8384285.html},
  keywords = {Application: Bearing,Application: Manufacturing,Method: Deep Learning,People: Chen Nan,Problem: Prognostics},
  number = {4}
}

@article{zhuMultisource2019,
  title = {Multi-Source {{Unsupervised Domain Adaptation}} for {{Machinery Fault Diagnosis}} under {{Different Working Conditions}}},
  author = {Zhu, Jun and Chen, Nan and Shen, Changqing and Wang, Dong},
  date = {2019},
  journaltitle = {IEEE Sensors Journal},
  pages = {8},
  abstract = {Owing to distribution discrepancy between source training and target testing data, the performance of fault diagnosis by traditional supervised learning models will degenerate. Though domain adaptation methods for diagnosis have been actively investigated recently, most of them are devoted to learning from a single source. However, in reality, the supervised samples can be collected from different sources such as various working conditions. These sources are not only different from target but also from each other. The way of effectively fusing these sources to contribute the prediction of target remains a challenge. In this work, a new framework of multi-source domain adaptation is proposed for cross-domain fault diagnosis under different working conditions. Specially, this framework is realized by two alignment stages. At the first stage, multiple specific feature spaces are obtained, then the distributions of each pair of source and target domain are aligned since it is difficult to extract the common domain-invariant features for all domains. At the second stage, by considering the domain specific decision boundaries, the probabilistic outputs of classifiers are also aligned. Various experimental analysis on four different bearing working conditions is conducted to show the effectiveness of the proposed method. The performance of the proposed method is superior to state-the-art cross-domain fault diagnosis methods.},
  file = {/Users/hyan46/Dropbox (ASU)/ZoteroData/Zhu et al_2019_Multi-source Unsupervised Domain Adaptation for Machinery Fault Diagnosis under.pdf},
  keywords = {Application: Bearing,Application: Manufacturing,Method: Classification,People: Chen Nan,Problem: Classification},
  langid = {english}
}

@article{zhuNew2020,
  title = {A New Data-Driven Transferable Remaining Useful Life Prediction Approach for Bearing under Different Working Conditions},
  author = {Zhu, Jun and Chen, Nan and Shen, Changqing},
  date = {2020-05-01},
  journaltitle = {Mechanical Systems and Signal Processing},
  shortjournal = {Mechanical Systems and Signal Processing},
  volume = {139},
  pages = {106602},
  issn = {0888-3270},
  doi = {10.1016/j.ymssp.2019.106602},
  url = {http://www.sciencedirect.com/science/article/pii/S0888327019308234},
  urldate = {2020-07-04},
  abstract = {Remaining useful life (RUL) estimation plays a pivotal role in ensuring the safety of a machine, which can further reduce the cost by unwanted downtime or failures. A variety of data-driven methods based on artificial intelligence have been proposed to predict RUL of key component such as bearing. However, many existing approaches have the following two shortcomings: 1) the fault occurrence time (FOT) is ignored or selected subjectively; 2) the training and testing data follow the same data distribution. Inappropriate FOT will either include unrelated information such as noise or reduce critical degradation information. The prognostic model trained with dataset in one working condition can not generalize well on dataset from another different working condition owing to distribution discrepancy. In this paper, to handle these two shortcomings, hidden Markov model (HMM) is first employed to automatically detect state change so that FOT can be located. Then a novel transfer learning method based on multiple layer perceptron (MLP) is presented to solve distribution discrepancy problem. Experiment study on RUL estimation of bearing is analyzed to illustrate the effectiveness of the proposed method. The results demonstrate that the proposed framework can detect FOT adaptively, at the same time provide reliable transferable prognostics performance under different working conditions.},
  file = {/Users/hyan46/Dropbox (ASU)/ZoteroData/Zhu et al_2020_A new data-driven transferable remaining useful life prediction approach for2.pdf},
  keywords = {Application: Bearing,Application: Manufacturing,Method: Deep Learning,Method: Transfer Learning,People: Chen Nan,Problem: Prognostics},
  langid = {english}
}

@article{zhuProcess2012,
  title = {Process Pattern Construction and Multi-Mode Monitoring},
  author = {Zhu, Zhibo and Song, Zhihuan and Palazoglu, Ahmet},
  date = {2012-01-01},
  journaltitle = {Journal of Process Control},
  shortjournal = {Journal of Process Control},
  volume = {22},
  pages = {247--262},
  issn = {0959-1524},
  doi = {10.1016/j.jprocont.2011.08.002},
  url = {http://www.sciencedirect.com/science/article/pii/S0959152411001727},
  urldate = {2020-05-25},
  abstract = {A novel framework for process pattern construction and multi-mode monitoring is proposed. To identify process patterns, the framework utilizes a clustering method that consists of an ensemble moving window strategy along with an ensemble clustering solutions strategy. A new k-independent component analysis–principal component analysis (k-ICA–PCA) modeling method captures the relevant process patterns in corresponding clusters and facilitates the validation of ensemble solutions. Following pattern construction, the proposed framework offers an adjoined multi-ICA–PCA model for detection of faults under multiple operating modes. The Tennessee Eastman (TE) benchmark process is used as a case study to demonstrate the salient features of the method. Specifically, the proposed method is shown to have superior performance compared to the previously reported k-PCA models clustering approach.},
  file = {/Users/hyan46/Zotero/storage/IG26HXBM/S0959152411001727.html},
  keywords = {Application: Wind Turbine,multimode,Problem: Process Monitoring},
  langid = {english},
  number = {1}
}

@incollection{zimmermannForecasting2012,
  title = {Forecasting with {{Recurrent Neural Networks}}: 12 {{Tricks}}},
  shorttitle = {Forecasting with {{Recurrent Neural Networks}}},
  booktitle = {Neural {{Networks}}: {{Tricks}} of the {{Trade}}},
  author = {Zimmermann, Hans-Georg and Tietz, Christoph and Grothmann, Ralph},
  editor = {Montavon, Grégoire and Orr, Geneviève B. and Müller, Klaus-Robert},
  date = {2012},
  volume = {7700},
  pages = {687--707},
  publisher = {{Springer Berlin Heidelberg}},
  location = {{Berlin, Heidelberg}},
  doi = {10.1007/978-3-642-35289-8_37},
  url = {http://link.springer.com/10.1007/978-3-642-35289-8_37},
  urldate = {2020-09-02},
  abstract = {Recurrent neural networks (RNNs) are typically considered as relatively simple architectures, which come along with complicated learning algorithms. This paper has a different view: We start from the fact that RNNs can model any high dimensional, nonlinear dynamical system. Rather than focusing on learning algorithms, we concentrate on the design of network architectures. Unfolding in time is a well-known example of this modeling philosophy. Here a temporal algorithm is transferred into an architectural framework such that the learning can be performed by an extension of standard error backpropagation.},
  file = {/Users/hyan46/Zotero/storage/ZCTJSH5Q/Zimmermann et al. - 2012 - Forecasting with Recurrent Neural Networks 12 Tri.pdf},
  isbn = {978-3-642-35288-1 978-3-642-35289-8},
  langid = {english},
  series = {Lecture {{Notes}} in {{Computer Science}}}
}

@article{zouModeling2017,
  title = {Modeling and Change Detection of Dynamic Network Data by a Network State Space Model},
  author = {Zou, Na and Li, Jing},
  date = {2017-01-02},
  journaltitle = {IISE Transactions},
  shortjournal = {IISE Transactions},
  volume = {49},
  pages = {45--57},
  issn = {2472-5854, 2472-5862},
  doi = {10.1080/0740817X.2016.1198065},
  url = {https://www.tandfonline.com/doi/full/10.1080/0740817X.2016.1198065},
  urldate = {2020-07-20},
  abstract = {Dynamic network data are often encountered in social, biological, and engineering domains. There are two types of variability in dynamic network data: variability of natural evolution and variability due to assignable causes. The latter is the “change” referred to in this article. Accurate and timely change detection from dynamic network data is important. However, it has been infrequently studied, with most of the existing research having focused on community detection, prediction, and visualization. Change detection is a classic research area in Statistical Process Control (SPC), and various approaches have been developed for dynamic data in the form of univariate or multivariate time series but not in the form of networks. We propose a Network State Space Model (NSSM) to characterize the natural evolution of dynamic networks. For tractable parameter estimation of the NSSM, we develop an Expectation Propagation algorithm to produce an approximation for the observation equation of the NSSM and then use Expectation–Maximization integrated with Bayesian Optimal Smoothing to estimate the parameters. For change detection, we further propose a Singular Value Decomposition (SVD)-based method that integrates the NSSM with SPC. A realworld application on Enron dynamic email networks is presented, in which our method successfully detects two known changes.},
  file = {/Users/hyan46/Zotero/storage/4YGL58F7/Zou and Li - 2017 - Modeling and change detection of dynamic network d.pdf},
  langid = {english},
  number = {1}
}

@article{zouTransfer2015,
  title = {A {{Transfer Learning Approach}} for {{Predictive Modeling}} of {{Degenerate Biological Systems}}},
  author = {Zou, Na and Zhu, Yun and Zhu, Ji and Baydogan, Mustafa and Wang, Wei and Li, Jing},
  date = {2015-07-03},
  journaltitle = {Technometrics},
  shortjournal = {Technometrics},
  volume = {57},
  pages = {362--373},
  issn = {0040-1706, 1537-2723},
  doi = {10.1080/00401706.2015.1044117},
  url = {http://www.tandfonline.com/doi/full/10.1080/00401706.2015.1044117},
  urldate = {2020-07-20},
  file = {/Users/hyan46/Dropbox (ASU)/ZoteroData/Zou et al_2015_A Transfer Learning Approach for Predictive Modeling of Degenerate Biological.pdf},
  keywords = {Application: Health,Method: Transfer Learning,Problem: Supervised Learning},
  langid = {english},
  number = {3}
}

@inproceedings{zubairTensor2013,
  title = {Tensor Dictionary Learning with Sparse {{TUCKER}} Decomposition},
  booktitle = {2013 18th {{International Conference}} on {{Digital Signal Processing}} ({{DSP}})},
  author = {Zubair, Syed and {Wenwu Wang}},
  date = {2013-07},
  pages = {1--6},
  publisher = {{IEEE}},
  location = {{Fira, Santorini, Greece}},
  doi = {10.1109/ICDSP.2013.6622725},
  url = {http://ieeexplore.ieee.org/document/6622725/},
  urldate = {2021-07-02},
  abstract = {Dictionary learning algorithms are typically derived for dealing with one or two dimensional signals using vector-matrix operations. Little attention has been paid to the problem of dictionary learning over high dimensional tensor data. We propose a new algorithm for dictionary learning based on tensor factorization using a TUCKER model. In this algorithm, sparseness constraints are applied to the core tensor, of which the n-mode factors are learned from the input data in an alternate minimization manner using gradient descent. Simulations are provided to show the convergence and the reconstruction performance of the proposed algorithm. We also apply our algorithm to the speaker identification problem and compare the discriminative ability of the dictionaries learned with those of TUCKER and K-SVD algorithms. The results show that the classification performance of the dictionaries learned by our proposed algorithm is considerably better as compared to the two state of the art algorithms.},
  eventtitle = {2013 18th {{International Conference}} on {{Digital Signal Processing}} ({{DSP}})},
  file = {/Users/hyan46/Dropbox (ASU)/ZoteroData/Zubair_Wenwu Wang_2013_Tensor dictionary learning with sparse TUCKER decomposition.pdf},
  isbn = {978-1-4673-5807-1},
  langid = {english}
}


